  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2024-09-27T18:00:09.541+0200] {_client.py:1038} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.11&platform=Linux&arch=x86_64&database=sqlite&db_version=3.41&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2024-09-27T18:00:09.640+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-27 18:00:09 +0200] [320848] [INFO] Starting gunicorn 23.0.0
[2024-09-27 18:00:09 +0200] [320848] [INFO] Listening at: http://[::]:8793 (320848)
[2024-09-27 18:00:09 +0200] [320848] [INFO] Using worker: sync
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-27 18:00:09 +0200] [320849] [INFO] Booting worker with pid: 320849
[2024-09-27T18:00:09.673+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 320850
[2024-09-27T18:00:09.674+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:00:09.678+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T18:00:09.704+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27 18:00:09 +0200] [320851] [INFO] Booting worker with pid: 320851
[2024-09-27T18:00:10.054+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:10.090+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:36:00+00:00: scheduled__2023-09-27T16:36:00+00:00, state:running, queued_at: 2024-09-27 15:59:26.801901+00:00. externally triggered: False> successful
[2024-09-27T18:00:10.091+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:36:00+00:00, run_id=scheduled__2023-09-27T16:36:00+00:00, run_start_date=2024-09-27 15:59:26.811433+00:00, run_end_date=2024-09-27 16:00:10.091194+00:00, run_duration=43.279761, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:36:00+00:00, data_interval_end=2023-09-27 16:37:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:10.093+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:37:00+00:00, run_after=2023-09-27 16:38:00+00:00
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:10.108+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.109+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.113+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:11.049+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:11.133+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:24.302+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:25.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:25.283+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [queued]> on host jf-hp
%3|1727452839.445|FAIL|rdkafka#producer-1| [thrd:jf-hp:9092/0]: jf-hp:9092/0: Failed to connect to broker at [jf-hp]:9092: Invalid argument (after 1ms in state CONNECT)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.828+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:11.169956+00:00, run_end_date=2024-09-27 16:00:23.909924+00:00, run_duration=12.739968, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1231, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320854
[2024-09-27T18:00:40.829+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:25.321124+00:00, run_end_date=2024-09-27 16:00:40.464493+00:00, run_duration=15.143369, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320958
[2024-09-27T18:00:40.858+0200] {job.py:229} INFO - Heartbeat recovered after 31.22 seconds
[2024-09-27T18:00:41.108+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:41.150+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:37:00+00:00: scheduled__2023-09-27T16:37:00+00:00, state:running, queued_at: 2024-09-27 15:59:33.056378+00:00. externally triggered: False> successful
[2024-09-27T18:00:41.151+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:37:00+00:00, run_id=scheduled__2023-09-27T16:37:00+00:00, run_start_date=2024-09-27 15:59:33.074914+00:00, run_end_date=2024-09-27 16:00:41.151364+00:00, run_duration=68.07645, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:37:00+00:00, data_interval_end=2023-09-27 16:38:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:41.156+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:38:00+00:00, run_after=2023-09-27 16:39:00+00:00
[2024-09-27T18:00:41.171+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:41.176+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.176+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:41.177+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.180+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:42.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:42.222+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:43.789+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:44.731+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:44.815+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.375+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:42.258022+00:00, run_end_date=2024-09-27 16:00:43.367019+00:00, run_duration=1.108997, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1233, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320989
[2024-09-27T18:00:46.376+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:44.853399+00:00, run_end_date=2024-09-27 16:00:45.984008+00:00, run_duration=1.130609, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1234, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320996
[2024-09-27T18:00:46.415+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:46.450+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.456+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:47.393+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:47.481+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:49.021+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:49.936+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:50.023+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:51.013+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.014+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.017+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:47.519919+00:00, run_end_date=2024-09-27 16:00:48.638144+00:00, run_duration=1.118225, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1235, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321004
[2024-09-27T18:00:51.018+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:50.059503+00:00, run_end_date=2024-09-27 16:00:50.598692+00:00, run_duration=0.539189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321012
[2024-09-27T18:00:51.041+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:51.068+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:52.009+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:52.097+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:53.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:54.114+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:54.200+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:52.130572+00:00, run_end_date=2024-09-27 16:00:52.775268+00:00, run_duration=0.644696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1237, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321020
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:54.231509+00:00, run_end_date=2024-09-27 16:00:54.696955+00:00, run_duration=0.465446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321028
[2024-09-27T18:00:55.119+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:00:55.138+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:38:00+00:00: scheduled__2023-09-27T16:38:00+00:00, state:running, queued_at: 2024-09-27 16:00:09.963038+00:00. externally triggered: False> successful
[2024-09-27T18:00:55.139+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:38:00+00:00, run_id=scheduled__2023-09-27T16:38:00+00:00, run_start_date=2024-09-27 16:00:10.069389+00:00, run_end_date=2024-09-27 16:00:55.139032+00:00, run_duration=45.069643, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:38:00+00:00, data_interval_end=2023-09-27 16:39:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:55.140+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.149+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:56.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:56.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:56.952+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:57.865+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:57.951+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.994+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:56.223021+00:00, run_end_date=2024-09-27 16:00:56.539323+00:00, run_duration=0.316302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1239, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321035
[2024-09-27T18:00:58.995+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:57.988241+00:00, run_end_date=2024-09-27 16:00:58.590852+00:00, run_duration=0.602611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321043
[2024-09-27T18:00:59.026+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.056+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:39:00+00:00: scheduled__2023-09-27T16:39:00+00:00, state:running, queued_at: 2024-09-27 16:00:41.102400+00:00. externally triggered: False> successful
[2024-09-27T18:00:59.057+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:39:00+00:00, run_id=scheduled__2023-09-27T16:39:00+00:00, run_start_date=2024-09-27 16:00:41.120307+00:00, run_end_date=2024-09-27 16:00:59.057380+00:00, run_duration=17.937073, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:39:00+00:00, data_interval_end=2023-09-27 16:40:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:59.062+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.075+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:59.080+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:59.083+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:00.023+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:00.108+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:01.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:01.089+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:00.144130+00:00, run_end_date=2024-09-27 16:01:00.695583+00:00, run_duration=0.551453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1241, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:59.077213+00:00, queued_by_job_id=1230, pid=321050
[2024-09-27T18:01:01.136+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:01.168+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.171+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:01.172+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:01.172+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:01.177+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:02.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:02.195+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:03.237+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:03.242+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:02.231116+00:00, run_end_date=2024-09-27 16:01:02.810062+00:00, run_duration=0.578946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1242, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:01.170506+00:00, queued_by_job_id=1230, pid=321057
[2024-09-27T18:01:03.275+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:03.334+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.334+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:03.335+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.338+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:04.288+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:04.375+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:05.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:06.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:06.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:07.125+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.126+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:04.412683+00:00, run_end_date=2024-09-27 16:01:04.782143+00:00, run_duration=0.36946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1243, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321064
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:06.206428+00:00, run_end_date=2024-09-27 16:01:06.729709+00:00, run_duration=0.523281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321071
[2024-09-27T18:01:07.181+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:07.207+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:40:00+00:00: scheduled__2023-09-27T16:40:00+00:00, state:running, queued_at: 2024-09-27 16:00:55.116762+00:00. externally triggered: False> successful
[2024-09-27T18:01:07.207+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:40:00+00:00, run_id=scheduled__2023-09-27T16:40:00+00:00, run_start_date=2024-09-27 16:00:55.126133+00:00, run_end_date=2024-09-27 16:01:07.207457+00:00, run_duration=12.081324, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:40:00+00:00, data_interval_end=2023-09-27 16:41:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:07.209+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:07.217+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.221+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:08.160+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:08.245+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:09.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:10.115+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:10.205+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:11.416+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.417+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:10.242243+00:00, run_end_date=2024-09-27 16:01:11.033357+00:00, run_duration=0.791114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1246, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321085
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:08.281207+00:00, run_end_date=2024-09-27 16:01:08.747214+00:00, run_duration=0.466007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1245, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321078
[2024-09-27T18:01:11.684+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.717+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.721+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:12.641+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:12.726+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:14.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:15.028+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:15.116+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:16.371+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:17.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:17.423+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:18.279+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.284+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:17.459928+00:00, run_end_date=2024-09-27 16:01:17.889774+00:00, run_duration=0.429846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1249, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321112
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:15.152411+00:00, run_end_date=2024-09-27 16:01:15.950537+00:00, run_duration=0.798126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1248, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321105
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:12.763874+00:00, run_end_date=2024-09-27 16:01:13.715515+00:00, run_duration=0.951641, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1247, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321094
[2024-09-27T18:01:18.324+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:18.353+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:18.356+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.360+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:19.296+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:19.380+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:20.331+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:21.271+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:21.356+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:22.287+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:23.219+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:23.307+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:24.317+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:25.247+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:25.332+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:25.368857+00:00, run_end_date=2024-09-27 16:01:25.798744+00:00, run_duration=0.429887, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1253, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321142
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:23.343595+00:00, run_end_date=2024-09-27 16:01:23.949111+00:00, run_duration=0.605516, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1252, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321135
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:21.388362+00:00, run_end_date=2024-09-27 16:01:21.845540+00:00, run_duration=0.457178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1251, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321127
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:19.416874+00:00, run_end_date=2024-09-27 16:01:19.929931+00:00, run_duration=0.513057, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1250, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321120
[2024-09-27T18:01:26.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:26.236+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:41:00+00:00: scheduled__2023-09-27T16:41:00+00:00, state:running, queued_at: 2024-09-27 16:01:03.269464+00:00. externally triggered: False> successful
[2024-09-27T18:01:26.236+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:41:00+00:00, run_id=scheduled__2023-09-27T16:41:00+00:00, run_start_date=2024-09-27 16:01:03.293633+00:00, run_end_date=2024-09-27 16:01:26.236543+00:00, run_duration=22.94291, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:41:00+00:00, data_interval_end=2023-09-27 16:42:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:26.238+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.249+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.252+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:27.191+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:27.276+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:28.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:29.004+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:29.091+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:30.474+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:31.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:31.488+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:32.947+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:33.880+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:33.964+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:35.500+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.502+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.508+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:34.000142+00:00, run_end_date=2024-09-27 16:01:35.112254+00:00, run_duration=1.112112, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321171
[2024-09-27T18:01:35.509+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:31.524617+00:00, run_end_date=2024-09-27 16:01:32.552106+00:00, run_duration=1.027489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1256, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321163
[2024-09-27T18:01:35.510+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:29.129724+00:00, run_end_date=2024-09-27 16:01:30.091220+00:00, run_duration=0.961496, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1255, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321156
[2024-09-27T18:01:35.511+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:27.312630+00:00, run_end_date=2024-09-27 16:01:27.667440+00:00, run_duration=0.35481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1254, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321149
[2024-09-27T18:01:35.558+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.596+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:42:00+00:00: scheduled__2023-09-27T16:42:00+00:00, state:running, queued_at: 2024-09-27 16:01:07.174802+00:00. externally triggered: False> successful
[2024-09-27T18:01:35.596+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:42:00+00:00, run_id=scheduled__2023-09-27T16:42:00+00:00, run_start_date=2024-09-27 16:01:07.192486+00:00, run_end_date=2024-09-27 16:01:35.596636+00:00, run_duration=28.40415, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:42:00+00:00, data_interval_end=2023-09-27 16:43:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:35.601+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.615+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.619+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:35.620+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.625+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:36.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:36.660+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:38.191+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:39.130+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:39.216+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:40.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:41.146+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:41.232+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:42.150+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:41.270050+00:00, run_end_date=2024-09-27 16:01:41.768499+00:00, run_duration=0.498449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321193
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:39.252792+00:00, run_end_date=2024-09-27 16:01:39.790672+00:00, run_duration=0.53788, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1259, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321186
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:36.696688+00:00, run_end_date=2024-09-27 16:01:37.776911+00:00, run_duration=1.080223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1258, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321179
[2024-09-27T18:01:42.409+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:42.433+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:43:00+00:00: scheduled__2023-09-27T16:43:00+00:00, state:running, queued_at: 2024-09-27 16:01:11.678717+00:00. externally triggered: False> successful
[2024-09-27T18:01:42.434+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:43:00+00:00, run_id=scheduled__2023-09-27T16:43:00+00:00, run_start_date=2024-09-27 16:01:11.692882+00:00, run_end_date=2024-09-27 16:01:42.434151+00:00, run_duration=30.741269, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:43:00+00:00, data_interval_end=2023-09-27 16:44:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:42.436+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:42.448+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:42.450+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.454+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:42.454+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.458+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:43.389+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:43.473+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:44.960+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:45.899+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:45.983+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:47.400+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:48.351+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:48.436+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:49.445+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.452+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:43.508593+00:00, run_end_date=2024-09-27 16:01:44.541181+00:00, run_duration=1.032588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1261, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321201
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:48.471694+00:00, run_end_date=2024-09-27 16:01:49.059436+00:00, run_duration=0.587742, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321218
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:46.019008+00:00, run_end_date=2024-09-27 16:01:46.997770+00:00, run_duration=0.978762, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1262, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321208
[2024-09-27T18:01:49.500+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.530+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:44:00+00:00: scheduled__2023-09-27T16:44:00+00:00, state:running, queued_at: 2024-09-27 16:01:18.321308+00:00. externally triggered: False> successful
[2024-09-27T18:01:49.531+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:44:00+00:00, run_id=scheduled__2023-09-27T16:44:00+00:00, run_start_date=2024-09-27 16:01:18.330859+00:00, run_end_date=2024-09-27 16:01:49.531464+00:00, run_duration=31.200605, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:44:00+00:00, data_interval_end=2023-09-27 16:45:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:49.536+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.548+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:49.550+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.552+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:49.553+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:49.553+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.554+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:49.554+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.558+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:50.489+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:50.574+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:52.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:52.980+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:53.067+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:54.449+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.450+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.455+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:50.611511+00:00, run_end_date=2024-09-27 16:01:51.610045+00:00, run_duration=0.998534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1264, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321226
[2024-09-27T18:01:54.456+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:53.104035+00:00, run_end_date=2024-09-27 16:01:54.070098+00:00, run_duration=0.966063, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321233
[2024-09-27T18:01:54.481+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.500+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:45:00+00:00: scheduled__2023-09-27T16:45:00+00:00, state:running, queued_at: 2024-09-27 16:01:26.207749+00:00. externally triggered: False> successful
[2024-09-27T18:01:54.500+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:45:00+00:00, run_id=scheduled__2023-09-27T16:45:00+00:00, run_start_date=2024-09-27 16:01:26.217400+00:00, run_end_date=2024-09-27 16:01:54.500299+00:00, run_duration=28.282899, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:45:00+00:00, data_interval_end=2023-09-27 16:46:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:54.502+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.508+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:54.510+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:54.513+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:55.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:55.536+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:56.939+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:56.944+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:55.573830+00:00, run_end_date=2024-09-27 16:01:56.527711+00:00, run_duration=0.953881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1266, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:54.509734+00:00, queued_by_job_id=1230, pid=321240
[2024-09-27T18:01:56.988+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:57.022+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.025+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:57.026+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:57.026+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.030+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.974+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:58.060+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:58.984+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:58.986+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:58.096844+00:00, run_end_date=2024-09-27 16:01:58.620934+00:00, run_duration=0.52409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1267, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:57.024486+00:00, queued_by_job_id=1230, pid=321248
[2024-09-27T18:01:59.009+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:01:59.031+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:46:00+00:00: scheduled__2023-09-27T16:46:00+00:00, state:running, queued_at: 2024-09-27 16:01:42.403863+00:00. externally triggered: False> successful
[2024-09-27T18:01:59.032+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:46:00+00:00, run_id=scheduled__2023-09-27T16:46:00+00:00, run_start_date=2024-09-27 16:01:42.418716+00:00, run_end_date=2024-09-27 16:01:59.032147+00:00, run_duration=16.613431, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:46:00+00:00, data_interval_end=2023-09-27 16:47:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:59.034+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:59.043+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:59.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:00.001+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:00.088+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:00.973+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:00.976+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:00.127374+00:00, run_end_date=2024-09-27 16:02:00.574092+00:00, run_duration=0.446718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1268, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:59.041965+00:00, queued_by_job_id=1230, pid=321255
[2024-09-27T18:02:00.997+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:01.036+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.039+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:01.040+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:01.040+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.044+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:02.063+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:03.024+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:03.026+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:02.099888+00:00, run_end_date=2024-09-27 16:02:02.600638+00:00, run_duration=0.50075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1269, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:01.038262+00:00, queued_by_job_id=1230, pid=321262
[2024-09-27T18:02:03.061+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:03.093+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.098+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:04.037+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:04.120+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:05.127+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:06.077+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:06.164+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:07.042+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.043+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:06.200887+00:00, run_end_date=2024-09-27 16:02:06.635161+00:00, run_duration=0.434274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321276
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:04.156748+00:00, run_end_date=2024-09-27 16:02:04.738813+00:00, run_duration=0.582065, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1270, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321269
[2024-09-27T18:02:07.089+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:07.149+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:07.151+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:07.154+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.155+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:07.155+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:07.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.160+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:08.099+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:08.183+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:09.023+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:09.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:10.073+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:10.997+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:11.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:12.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.222+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.228+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:12.062263+00:00, run_end_date=2024-09-27 16:02:12.819921+00:00, run_duration=0.757658, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1274, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321311
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:08.219782+00:00, run_end_date=2024-09-27 16:02:08.603725+00:00, run_duration=0.383943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1272, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321283
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:10.110512+00:00, run_end_date=2024-09-27 16:02:10.589705+00:00, run_duration=0.479193, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1273, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321304
[2024-09-27T18:02:13.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:13.555+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:47:00+00:00: scheduled__2023-09-27T16:47:00+00:00, state:running, queued_at: 2024-09-27 16:01:59.006507+00:00. externally triggered: False> successful
[2024-09-27T18:02:13.555+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:47:00+00:00, run_id=scheduled__2023-09-27T16:47:00+00:00, run_start_date=2024-09-27 16:01:59.020753+00:00, run_end_date=2024-09-27 16:02:13.555749+00:00, run_duration=14.534996, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:47:00+00:00, data_interval_end=2023-09-27 16:48:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:13.560+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.570+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.574+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:14.507+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:14.592+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:15.711+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:16.671+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:16.758+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:17.734+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:18.650+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:18.735+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.214+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.219+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:16.796629+00:00, run_end_date=2024-09-27 16:02:17.337980+00:00, run_duration=0.541351, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1276, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321332
[2024-09-27T18:02:20.220+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:14.627720+00:00, run_end_date=2024-09-27 16:02:15.304761+00:00, run_duration=0.677041, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1275, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321324
[2024-09-27T18:02:20.221+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:18.771494+00:00, run_end_date=2024-09-27 16:02:19.860212+00:00, run_duration=1.088718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321340
[2024-09-27T18:02:20.260+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:20.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.291+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:21.229+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:21.315+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:22.763+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:23.726+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:23.814+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:25.142+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:26.078+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:26.163+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.362+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.364+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:23.851804+00:00, run_end_date=2024-09-27 16:02:24.767089+00:00, run_duration=0.915285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1279, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321354
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:21.352057+00:00, run_end_date=2024-09-27 16:02:22.348460+00:00, run_duration=0.996403, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1278, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321347
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:26.198707+00:00, run_end_date=2024-09-27 16:02:26.953479+00:00, run_duration=0.754772, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1280, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321361
[2024-09-27T18:02:27.398+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:27.412+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:48:00+00:00: scheduled__2023-09-27T16:48:00+00:00, state:running, queued_at: 2024-09-27 16:02:03.059191+00:00. externally triggered: False> successful
[2024-09-27T18:02:27.412+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:48:00+00:00, run_id=scheduled__2023-09-27T16:48:00+00:00, run_start_date=2024-09-27 16:02:03.069597+00:00, run_end_date=2024-09-27 16:02:27.412540+00:00, run_duration=24.342943, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:48:00+00:00, data_interval_end=2023-09-27 16:49:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:27.414+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:27.421+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:27.423+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:27.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.427+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:28.363+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:28.452+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:29.508+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:30.464+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:30.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:30.584070+00:00, run_end_date=2024-09-27 16:02:31.021926+00:00, run_duration=0.437856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321375
[2024-09-27T18:02:31.424+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:28.490216+00:00, run_end_date=2024-09-27 16:02:29.118875+00:00, run_duration=0.628659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1281, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321368
[2024-09-27T18:02:31.448+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.475+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:49:00+00:00: scheduled__2023-09-27T16:49:00+00:00, state:running, queued_at: 2024-09-27 16:02:07.082712+00:00. externally triggered: False> successful
[2024-09-27T18:02:31.476+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:49:00+00:00, run_id=scheduled__2023-09-27T16:49:00+00:00, run_start_date=2024-09-27 16:02:07.106532+00:00, run_end_date=2024-09-27 16:02:31.476405+00:00, run_duration=24.369873, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:49:00+00:00, data_interval_end=2023-09-27 16:50:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:31.480+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:31.494+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:31.497+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:31.500+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:32.434+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:32.518+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:33.595+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:33.600+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:32.553934+00:00, run_end_date=2024-09-27 16:02:33.167498+00:00, run_duration=0.613564, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1283, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:31.494879+00:00, queued_by_job_id=1230, pid=321382
[2024-09-27T18:02:33.643+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:33.661+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:50:00+00:00: scheduled__2023-09-27T16:50:00+00:00, state:running, queued_at: 2024-09-27 16:02:13.501328+00:00. externally triggered: False> successful
[2024-09-27T18:02:33.662+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:50:00+00:00, run_id=scheduled__2023-09-27T16:50:00+00:00, run_start_date=2024-09-27 16:02:13.520492+00:00, run_end_date=2024-09-27 16:02:33.662059+00:00, run_duration=20.141567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:50:00+00:00, data_interval_end=2023-09-27 16:51:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:33.666+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:34.709+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:34.740+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:34.742+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:35.675+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:35.764+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:36.640+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:36.645+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:35.802059+00:00, run_end_date=2024-09-27 16:02:36.255413+00:00, run_duration=0.453354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1284, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:34.739061+00:00, queued_by_job_id=1230, pid=321391
[2024-09-27T18:02:36.678+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:02:36.727+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:36.729+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.730+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:36.730+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.732+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:37.672+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:37.757+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:38.560+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:39.501+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:39.590+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.578+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:39.626476+00:00, run_end_date=2024-09-27 16:02:40.176226+00:00, run_duration=0.54975, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1286, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321406
[2024-09-27T18:02:40.579+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:37.793102+00:00, run_end_date=2024-09-27 16:02:38.146000+00:00, run_duration=0.352898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1285, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321398
[2024-09-27T18:02:40.616+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:40.648+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.650+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:41.591+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:41.677+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:42.921+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:43.875+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:43.961+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:45.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:46.147+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:46.231+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.352+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.359+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:46.267060+00:00, run_end_date=2024-09-27 16:02:46.939523+00:00, run_duration=0.672463, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1289, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321427
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:41.713006+00:00, run_end_date=2024-09-27 16:02:42.503726+00:00, run_duration=0.79072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1287, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321413
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:43.997504+00:00, run_end_date=2024-09-27 16:02:44.789012+00:00, run_duration=0.791508, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1288, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321420
[2024-09-27T18:02:47.618+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:02:47.680+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.685+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:47.686+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:47.686+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:47.687+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.688+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:48.631+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:48.715+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:50.123+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:51.068+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:51.152+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:52.561+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:53.502+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:53.588+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:55.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:56.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:56.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:57.094+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.096+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.102+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:56.206081+00:00, run_end_date=2024-09-27 16:02:56.671887+00:00, run_duration=0.465806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1293, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321464
[2024-09-27T18:02:57.103+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:51.190075+00:00, run_end_date=2024-09-27 16:02:52.129239+00:00, run_duration=0.939164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1291, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321444
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:48.751318+00:00, run_end_date=2024-09-27 16:02:49.704840+00:00, run_duration=0.953522, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1290, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321437
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:53.624750+00:00, run_end_date=2024-09-27 16:02:54.724797+00:00, run_duration=1.100047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1292, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321457
[2024-09-27T18:02:57.150+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:56:00+00:00, run_after=2023-09-27 16:57:00+00:00
[2024-09-27T18:02:57.202+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:51:00+00:00: scheduled__2023-09-27T16:51:00+00:00, state:running, queued_at: 2024-09-27 16:02:34.703538+00:00. externally triggered: False> successful
[2024-09-27T18:02:57.203+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:51:00+00:00, run_id=scheduled__2023-09-27T16:51:00+00:00, run_start_date=2024-09-27 16:02:34.722773+00:00, run_end_date=2024-09-27 16:02:57.203321+00:00, run_duration=22.480548, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:51:00+00:00, data_interval_end=2023-09-27 16:52:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:57.206+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:57.214+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:57.215+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.219+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:58.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:58.235+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:59.235+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:00.180+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:00.264+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:01.510+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:02.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:02.535+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:03.536+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:04.468+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:04.553+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:05.665+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.673+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:00.300429+00:00, run_end_date=2024-09-27 16:03:01.077587+00:00, run_duration=0.777158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1295, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321484
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:02.571693+00:00, run_end_date=2024-09-27 16:03:03.127994+00:00, run_duration=0.556301, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1296, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321496
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:58.270824+00:00, run_end_date=2024-09-27 16:02:58.823393+00:00, run_duration=0.552569, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1294, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321472
[2024-09-27T18:03:05.675+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:04.591123+00:00, run_end_date=2024-09-27 16:03:05.281462+00:00, run_duration=0.690339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321503
[2024-09-27T18:03:05.725+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.761+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:52:00+00:00: scheduled__2023-09-27T16:52:00+00:00, state:running, queued_at: 2024-09-27 16:02:36.672415+00:00. externally triggered: False> successful
[2024-09-27T18:03:05.762+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:52:00+00:00, run_id=scheduled__2023-09-27T16:52:00+00:00, run_start_date=2024-09-27 16:02:36.695113+00:00, run_end_date=2024-09-27 16:03:05.762096+00:00, run_duration=29.066983, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:52:00+00:00, data_interval_end=2023-09-27 16:53:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:05.766+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.780+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:05.782+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.786+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.787+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:05.787+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.791+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:06.729+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:06.813+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:08.983+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:09.925+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:10.009+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:10.968+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:11.903+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:11.987+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:12.857+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.858+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.858+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.864+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:10.044368+00:00, run_end_date=2024-09-27 16:03:10.569530+00:00, run_duration=0.525162, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1299, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321527
[2024-09-27T18:03:12.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:12.023313+00:00, run_end_date=2024-09-27 16:03:12.461247+00:00, run_duration=0.437934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1300, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321535
[2024-09-27T18:03:12.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:06.849119+00:00, run_end_date=2024-09-27 16:03:08.566063+00:00, run_duration=1.716944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1298, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321510
[2024-09-27T18:03:12.900+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:03:12.914+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:53:00+00:00: scheduled__2023-09-27T16:53:00+00:00, state:running, queued_at: 2024-09-27 16:02:40.613989+00:00. externally triggered: False> successful
[2024-09-27T18:03:12.914+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:53:00+00:00, run_id=scheduled__2023-09-27T16:53:00+00:00, run_start_date=2024-09-27 16:02:40.623530+00:00, run_end_date=2024-09-27 16:03:12.914637+00:00, run_duration=32.291107, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:53:00+00:00, data_interval_end=2023-09-27 16:54:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:12.916+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
[2024-09-27T18:03:12.924+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:12.925+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:12.925+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:12.925+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:12.925+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:12.928+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:13.873+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:13.958+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:14.877+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:15.818+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:15.903+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:16.893+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:16.894+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:16.899+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:15.940298+00:00, run_end_date=2024-09-27 16:03:16.478366+00:00, run_duration=0.538068, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1302, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:12.924048+00:00, queued_by_job_id=1230, pid=321557
[2024-09-27T18:03:16.900+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:13.996214+00:00, run_end_date=2024-09-27 16:03:14.480859+00:00, run_duration=0.484645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1301, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:12.924048+00:00, queued_by_job_id=1230, pid=321547
[2024-09-27T18:03:16.929+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:03:16.957+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:54:00+00:00: scheduled__2023-09-27T16:54:00+00:00, state:running, queued_at: 2024-09-27 16:02:47.611960+00:00. externally triggered: False> successful
[2024-09-27T18:03:16.958+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:54:00+00:00, run_id=scheduled__2023-09-27T16:54:00+00:00, run_start_date=2024-09-27 16:02:47.630690+00:00, run_end_date=2024-09-27 16:03:16.957983+00:00, run_duration=29.327293, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:54:00+00:00, data_interval_end=2023-09-27 16:55:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:16.962+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
[2024-09-27T18:03:16.971+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:16.971+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:16.971+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:16.976+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:17.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:17.997+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:18.903+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:18.909+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:18.033561+00:00, run_end_date=2024-09-27 16:03:18.520742+00:00, run_duration=0.487181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1303, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:16.970905+00:00, queued_by_job_id=1230, pid=321564
[2024-09-27T18:03:19.157+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:19.174+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:55:00+00:00: scheduled__2023-09-27T16:55:00+00:00, state:running, queued_at: 2024-09-27 16:02:57.144473+00:00. externally triggered: False> successful
[2024-09-27T18:03:19.174+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:55:00+00:00, run_id=scheduled__2023-09-27T16:55:00+00:00, run_start_date=2024-09-27 16:02:57.163032+00:00, run_end_date=2024-09-27 16:03:19.174770+00:00, run_duration=22.011738, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:55:00+00:00, data_interval_end=2023-09-27 16:56:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:19.176+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:56:00+00:00, run_after=2023-09-27 16:57:00+00:00
[2024-09-27T18:03:19.183+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:19.183+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:19.184+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:19.184+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:19.185+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:19.185+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:19.187+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:20.124+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:20.210+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:21.064+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:21.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:20.245595+00:00, run_end_date=2024-09-27 16:03:20.666926+00:00, run_duration=0.421331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1304, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:19.184311+00:00, queued_by_job_id=1230, pid=321573
[2024-09-27T18:03:21.092+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:21.114+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:21.115+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:21.115+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:21.116+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:21.116+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:21.116+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:21.119+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:22.055+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:22.142+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:23.145+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:23.149+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:22.178762+00:00, run_end_date=2024-09-27 16:03:22.745310+00:00, run_duration=0.566548, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1305, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:21.115742+00:00, queued_by_job_id=1230, pid=321580
[2024-09-27T18:03:23.172+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:23.205+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:23.206+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:23.206+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:23.206+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:23.206+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:23.209+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:24.142+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:24.226+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:25.228+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:26.159+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:26.244+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:27.156+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:27.157+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:27.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:26.280605+00:00, run_end_date=2024-09-27 16:03:26.751778+00:00, run_duration=0.471173, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1307, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:23.205169+00:00, queued_by_job_id=1230, pid=321595
[2024-09-27T18:03:27.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:24.261713+00:00, run_end_date=2024-09-27 16:03:24.816252+00:00, run_duration=0.554539, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1306, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:23.205169+00:00, queued_by_job_id=1230, pid=321587
[2024-09-27T18:03:27.197+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:27.229+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:27.231+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:27.231+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.232+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.232+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.235+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:28.165+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:28.249+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:29.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:30.179+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:30.270+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:31.749+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:32.716+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:32.802+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:33.673+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.673+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.674+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.679+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:32.842362+00:00, run_end_date=2024-09-27 16:03:33.279610+00:00, run_duration=0.437248, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1310, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321630
[2024-09-27T18:03:33.680+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:30.305539+00:00, run_end_date=2024-09-27 16:03:31.346864+00:00, run_duration=1.041325, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1309, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321623
[2024-09-27T18:03:33.681+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:28.285408+00:00, run_end_date=2024-09-27 16:03:28.855428+00:00, run_duration=0.57002, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1308, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321602
[2024-09-27T18:03:33.728+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:33.775+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:56:00+00:00: scheduled__2023-09-27T16:56:00+00:00, state:running, queued_at: 2024-09-27 16:03:19.154884+00:00. externally triggered: False> successful
[2024-09-27T18:03:33.775+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:56:00+00:00, run_id=scheduled__2023-09-27T16:56:00+00:00, run_start_date=2024-09-27 16:03:19.163872+00:00, run_end_date=2024-09-27 16:03:33.775825+00:00, run_duration=14.611953, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:56:00+00:00, data_interval_end=2023-09-27 16:57:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:33.780+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:33.791+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.795+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:34.732+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:34.817+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:35.728+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:36.661+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:36.746+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:38.051+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:38.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:39.072+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:40.065+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.065+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.066+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.072+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:34.852581+00:00, run_end_date=2024-09-27 16:03:35.343143+00:00, run_duration=0.490562, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1311, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321638
[2024-09-27T18:03:40.073+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:39.109605+00:00, run_end_date=2024-09-27 16:03:39.664335+00:00, run_duration=0.55473, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1313, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321654
[2024-09-27T18:03:40.073+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:36.782625+00:00, run_end_date=2024-09-27 16:03:37.655222+00:00, run_duration=0.872597, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1312, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321645
[2024-09-27T18:03:40.122+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:40.164+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:40.165+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:40.165+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:40.166+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:41.106+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:41.191+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:42.232+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:43.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:43.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:44.817+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:45.748+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:45.832+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:47.191+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.192+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.192+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.198+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:41.226772+00:00, run_end_date=2024-09-27 16:03:41.832417+00:00, run_duration=0.605645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1314, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321661
[2024-09-27T18:03:47.199+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:45.870655+00:00, run_end_date=2024-09-27 16:03:46.773385+00:00, run_duration=0.90273, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1316, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321676
[2024-09-27T18:03:47.200+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:43.293026+00:00, run_end_date=2024-09-27 16:03:44.417799+00:00, run_duration=1.124773, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1315, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321668
[2024-09-27T18:03:47.242+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:47.273+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:57:00+00:00: scheduled__2023-09-27T16:57:00+00:00, state:running, queued_at: 2024-09-27 16:03:23.170016+00:00. externally triggered: False> successful
[2024-09-27T18:03:47.274+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:57:00+00:00, run_id=scheduled__2023-09-27T16:57:00+00:00, run_start_date=2024-09-27 16:03:23.185504+00:00, run_end_date=2024-09-27 16:03:47.274334+00:00, run_duration=24.08883, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:57:00+00:00, data_interval_end=2023-09-27 16:58:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:47.279+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:47.293+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
[2024-09-27T18:03:47.293+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:47.294+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:47.294+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
[2024-09-27T18:03:47.297+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:47.298+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:47.298+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:47.299+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:47.299+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:47.304+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:48.242+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:48.330+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:49.375+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:50.307+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:50.391+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:51.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:51.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:51.271+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:48.367343+00:00, run_end_date=2024-09-27 16:03:48.971999+00:00, run_duration=0.604656, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1317, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:47.295692+00:00, queued_by_job_id=1230, pid=321684
[2024-09-27T18:03:51.272+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:50.427638+00:00, run_end_date=2024-09-27 16:03:50.871079+00:00, run_duration=0.443441, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1318, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:47.295692+00:00, queued_by_job_id=1230, pid=321692
[2024-09-27T18:03:51.528+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:03:51.566+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:58:00+00:00: scheduled__2023-09-27T16:58:00+00:00, state:running, queued_at: 2024-09-27 16:03:27.194821+00:00. externally triggered: False> successful
[2024-09-27T18:03:51.567+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:58:00+00:00, run_id=scheduled__2023-09-27T16:58:00+00:00, run_start_date=2024-09-27 16:03:27.205174+00:00, run_end_date=2024-09-27 16:03:51.567295+00:00, run_duration=24.362121, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:58:00+00:00, data_interval_end=2023-09-27 16:59:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:51.571+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
[2024-09-27T18:03:51.582+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:51.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:51.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:51.583+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:51.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:51.587+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:52.529+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:52.614+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:54.058+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:54.997+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:55.081+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:56.523+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:56.524+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:56.530+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:52.650083+00:00, run_end_date=2024-09-27 16:03:53.637710+00:00, run_duration=0.987627, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1319, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:51.582032+00:00, queued_by_job_id=1230, pid=321700
[2024-09-27T18:03:56.530+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:55.117764+00:00, run_end_date=2024-09-27 16:03:56.096587+00:00, run_duration=0.978823, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1320, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:51.582032+00:00, queued_by_job_id=1230, pid=321707
[2024-09-27T18:03:56.579+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:56.605+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:59:00+00:00: scheduled__2023-09-27T16:59:00+00:00, state:running, queued_at: 2024-09-27 16:03:33.722171+00:00. externally triggered: False> successful
[2024-09-27T18:03:56.605+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:59:00+00:00, run_id=scheduled__2023-09-27T16:59:00+00:00, run_start_date=2024-09-27 16:03:33.740652+00:00, run_end_date=2024-09-27 16:03:56.605781+00:00, run_duration=22.865129, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:59:00+00:00, data_interval_end=2023-09-27 17:00:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:56.610+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:56.625+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:56.626+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:56.626+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:56.630+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:57.566+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:57.650+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:59.054+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:59.059+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:57.687170+00:00, run_end_date=2024-09-27 16:03:58.655177+00:00, run_duration=0.968007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1321, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:56.624633+00:00, queued_by_job_id=1230, pid=321714
[2024-09-27T18:03:59.086+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:03:59.126+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:59.126+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:59.127+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:59.129+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:59.129+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:59.129+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:59.132+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:00.075+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:00.161+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:01.084+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:01.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:00.198572+00:00, run_end_date=2024-09-27 16:04:00.684453+00:00, run_duration=0.485881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1322, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:59.127975+00:00, queued_by_job_id=1230, pid=321722
[2024-09-27T18:04:01.111+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:01.161+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:04:01.162+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:01.162+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:01.163+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:04:01.165+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:01.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:01.166+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:01.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:01.167+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:01.170+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:02.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:02.195+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:03.238+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:04.181+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:04.267+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:05.169+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:05.169+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:05.172+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:04.304658+00:00, run_end_date=2024-09-27 16:04:04.768478+00:00, run_duration=0.46382, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1324, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:01.163971+00:00, queued_by_job_id=1230, pid=321736
[2024-09-27T18:04:05.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:02.230774+00:00, run_end_date=2024-09-27 16:04:02.819570+00:00, run_duration=0.588796, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1323, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:01.163971+00:00, queued_by_job_id=1230, pid=321729
[2024-09-27T18:04:05.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:05.230+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:00:00+00:00: scheduled__2023-09-27T17:00:00+00:00, state:running, queued_at: 2024-09-27 16:03:51.522468+00:00. externally triggered: False> successful
[2024-09-27T18:04:05.231+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:00:00+00:00, run_id=scheduled__2023-09-27T17:00:00+00:00, run_start_date=2024-09-27 16:03:51.539903+00:00, run_end_date=2024-09-27 16:04:05.231061+00:00, run_duration=13.691158, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:00:00+00:00, data_interval_end=2023-09-27 17:01:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:05.232+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:05.241+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:05.242+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:05.242+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:05.242+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:05.242+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:05.245+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:06.182+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:06.267+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:07.185+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:08.126+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:08.211+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:09.130+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:09.131+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:09.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:06.302517+00:00, run_end_date=2024-09-27 16:04:06.768876+00:00, run_duration=0.466359, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1325, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:05.241066+00:00, queued_by_job_id=1230, pid=321743
[2024-09-27T18:04:09.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:08.246976+00:00, run_end_date=2024-09-27 16:04:08.731690+00:00, run_duration=0.484714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1326, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:05.241066+00:00, queued_by_job_id=1230, pid=321750
[2024-09-27T18:04:09.165+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:09.211+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:09.212+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:09.212+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:09.213+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:09.215+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:09.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:09.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:09.217+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:09.217+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:09.221+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:10.158+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:10.242+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:11.544+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:12.476+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:12.560+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:14.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:14.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:14.250+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:10.278284+00:00, run_end_date=2024-09-27 16:04:11.158800+00:00, run_duration=0.880516, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1327, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:09.214316+00:00, queued_by_job_id=1230, pid=321757
[2024-09-27T18:04:14.251+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:12.596437+00:00, run_end_date=2024-09-27 16:04:13.821377+00:00, run_duration=1.22494, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1328, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:09.214316+00:00, queued_by_job_id=1230, pid=321764
[2024-09-27T18:04:14.286+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:14.310+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:14.311+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:14.311+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:14.312+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:14.314+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:14.315+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:14.315+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:14.315+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:14.316+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:14.319+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:15.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:15.336+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:16.405+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:17.312+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:17.396+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:19.238+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:19.238+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:19.244+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:15.372293+00:00, run_end_date=2024-09-27 16:04:15.997514+00:00, run_duration=0.625221, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1329, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:14.313113+00:00, queued_by_job_id=1230, pid=321777
[2024-09-27T18:04:19.245+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:17.433254+00:00, run_end_date=2024-09-27 16:04:18.843764+00:00, run_duration=1.41051, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:14.313113+00:00, queued_by_job_id=1230, pid=321784
[2024-09-27T18:04:19.291+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:19.335+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:01:00+00:00: scheduled__2023-09-27T17:01:00+00:00, state:running, queued_at: 2024-09-27 16:04:01.108435+00:00. externally triggered: False> successful
[2024-09-27T18:04:19.336+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:01:00+00:00, run_id=scheduled__2023-09-27T17:01:00+00:00, run_start_date=2024-09-27 16:04:01.126953+00:00, run_end_date=2024-09-27 16:04:19.336053+00:00, run_duration=18.2091, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:01:00+00:00, data_interval_end=2023-09-27 17:02:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:19.340+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:19.355+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
[2024-09-27T18:04:19.356+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:19.356+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:19.357+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
[2024-09-27T18:04:19.359+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:19.360+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:19.360+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:19.361+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:19.361+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:19.365+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:20.302+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:20.386+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:21.716+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:22.649+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:22.735+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:24.147+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:24.147+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:24.153+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:20.422176+00:00, run_end_date=2024-09-27 16:04:21.303718+00:00, run_duration=0.881542, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1331, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:19.358220+00:00, queued_by_job_id=1230, pid=321792
[2024-09-27T18:04:24.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:22.772458+00:00, run_end_date=2024-09-27 16:04:23.760327+00:00, run_duration=0.987869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1332, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:19.358220+00:00, queued_by_job_id=1230, pid=321799
[2024-09-27T18:04:24.311+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:24.352+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:02:00+00:00: scheduled__2023-09-27T17:02:00+00:00, state:running, queued_at: 2024-09-27 16:04:05.207406+00:00. externally triggered: False> successful
[2024-09-27T18:04:24.353+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:02:00+00:00, run_id=scheduled__2023-09-27T17:02:00+00:00, run_start_date=2024-09-27 16:04:05.217062+00:00, run_end_date=2024-09-27 16:04:24.353364+00:00, run_duration=19.136302, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:02:00+00:00, data_interval_end=2023-09-27 17:03:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:24.358+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:24.369+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:24.369+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:24.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:24.370+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:24.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:24.373+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:25.306+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:25.390+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:26.310+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:27.243+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:27.329+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:28.371+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:28.372+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:28.377+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:27.365508+00:00, run_end_date=2024-09-27 16:04:27.990839+00:00, run_duration=0.625331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1334, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:24.369049+00:00, queued_by_job_id=1230, pid=321814
[2024-09-27T18:04:28.378+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:25.426667+00:00, run_end_date=2024-09-27 16:04:25.910489+00:00, run_duration=0.483822, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1333, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:24.369049+00:00, queued_by_job_id=1230, pid=321807
[2024-09-27T18:04:28.408+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:28.455+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:28.456+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:28.456+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:28.457+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:28.459+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:28.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:28.460+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:28.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:28.461+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:28.464+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:29.426+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:29.516+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:30.526+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:31.423+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:31.512+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:32.428+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:32.429+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:32.435+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:31.550071+00:00, run_end_date=2024-09-27 16:04:32.042463+00:00, run_duration=0.492392, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1336, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:28.458064+00:00, queued_by_job_id=1230, pid=321842
[2024-09-27T18:04:32.435+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:29.552508+00:00, run_end_date=2024-09-27 16:04:30.081959+00:00, run_duration=0.529451, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1335, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:28.458064+00:00, queued_by_job_id=1230, pid=321835
[2024-09-27T18:04:32.486+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:32.528+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:32.532+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:32.532+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:32.533+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:32.533+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:32.534+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:32.538+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:33.470+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:33.556+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:34.491+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:35.407+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:35.491+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:37.092+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:37.093+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:37.098+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:35.528701+00:00, run_end_date=2024-09-27 16:04:36.668061+00:00, run_duration=1.13936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1338, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:32.530863+00:00, queued_by_job_id=1230, pid=321857
[2024-09-27T18:04:37.099+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:33.592474+00:00, run_end_date=2024-09-27 16:04:34.067912+00:00, run_duration=0.475438, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1337, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:32.530863+00:00, queued_by_job_id=1230, pid=321850
[2024-09-27T18:04:37.132+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:37.176+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:03:00+00:00: scheduled__2023-09-27T17:03:00+00:00, state:running, queued_at: 2024-09-27 16:04:19.285092+00:00. externally triggered: False> successful
[2024-09-27T18:04:37.177+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:03:00+00:00, run_id=scheduled__2023-09-27T17:03:00+00:00, run_start_date=2024-09-27 16:04:19.307910+00:00, run_end_date=2024-09-27 16:04:37.177283+00:00, run_duration=17.869373, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:03:00+00:00, data_interval_end=2023-09-27 17:04:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:37.181+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:37.191+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:37.192+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:37.192+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:37.195+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:38.130+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:38.214+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:39.103+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:40.052+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:40.137+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:41.187+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:41.188+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:41.193+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:38.249890+00:00, run_end_date=2024-09-27 16:04:38.704003+00:00, run_duration=0.454113, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1339, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:37.191355+00:00, queued_by_job_id=1230, pid=321864
[2024-09-27T18:04:41.194+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:40.175117+00:00, run_end_date=2024-09-27 16:04:40.799953+00:00, run_duration=0.624836, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1340, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:37.191355+00:00, queued_by_job_id=1230, pid=321871
[2024-09-27T18:04:41.234+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:41.261+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:04:00+00:00: scheduled__2023-09-27T17:04:00+00:00, state:running, queued_at: 2024-09-27 16:04:24.305586+00:00. externally triggered: False> successful
[2024-09-27T18:04:41.261+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:04:00+00:00, run_id=scheduled__2023-09-27T17:04:00+00:00, run_start_date=2024-09-27 16:04:24.323633+00:00, run_end_date=2024-09-27 16:04:41.261482+00:00, run_duration=16.937849, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:04:00+00:00, data_interval_end=2023-09-27 17:05:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:41.266+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:41.279+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:41.279+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:41.280+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:41.282+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:41.282+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:41.282+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:41.286+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:42.236+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:42.333+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:43.410+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:43.415+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:42.372853+00:00, run_end_date=2024-09-27 16:04:43.018405+00:00, run_duration=0.645552, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1341, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:41.280746+00:00, queued_by_job_id=1230, pid=321878
[2024-09-27T18:04:43.443+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:43.481+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:43.482+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:43.482+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:43.484+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:43.484+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:43.485+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:43.488+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:44.426+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:44.511+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:45.556+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:45.561+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:44.549376+00:00, run_end_date=2024-09-27 16:04:45.136261+00:00, run_duration=0.586885, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1342, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:43.483168+00:00, queued_by_job_id=1230, pid=321885
[2024-09-27T18:04:45.589+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:07:00+00:00, run_after=2023-09-27 17:08:00+00:00
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:45.636+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:45.637+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:45.637+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:45.637+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:45.637+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:45.640+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:46.579+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:46.664+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:47.503+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:48.441+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:48.535+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:49.331+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:49.332+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:49.337+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:48.574115+00:00, run_end_date=2024-09-27 16:04:48.922514+00:00, run_duration=0.348399, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1344, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:45.636110+00:00, queued_by_job_id=1230, pid=321899
[2024-09-27T18:04:49.338+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:46.700094+00:00, run_end_date=2024-09-27 16:04:47.073994+00:00, run_duration=0.3739, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1343, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:45.636110+00:00, queued_by_job_id=1230, pid=321892
[2024-09-27T18:04:49.390+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:04:49.432+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:05:00+00:00: scheduled__2023-09-27T17:05:00+00:00, state:running, queued_at: 2024-09-27 16:04:37.125729+00:00. externally triggered: False> successful
[2024-09-27T18:04:49.432+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:05:00+00:00, run_id=scheduled__2023-09-27T17:05:00+00:00, run_start_date=2024-09-27 16:04:37.149710+00:00, run_end_date=2024-09-27 16:04:49.432688+00:00, run_duration=12.282978, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:05:00+00:00, data_interval_end=2023-09-27 17:06:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:49.437+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:49.451+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:49.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:49.452+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:49.452+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:49.455+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:49.455+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:49.456+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:49.456+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:49.456+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:49.460+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:50.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:50.479+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:52.125+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:53.065+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:53.149+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:54.438+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:54.439+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:54.445+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:50.516047+00:00, run_end_date=2024-09-27 16:04:51.728345+00:00, run_duration=1.212298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1345, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:49.453601+00:00, queued_by_job_id=1230, pid=321909
[2024-09-27T18:04:54.446+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:53.186177+00:00, run_end_date=2024-09-27 16:04:54.015282+00:00, run_duration=0.829105, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1346, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:49.453601+00:00, queued_by_job_id=1230, pid=321916
[2024-09-27T18:04:54.605+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:09:00+00:00, run_after=2023-09-27 17:10:00+00:00
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:04:54.640+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:54.641+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:54.641+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.642+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:54.642+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.645+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:55.577+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:55.662+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:56.700+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:57.637+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:57.722+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:59.017+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:59.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:00.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:01.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.347+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.347+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.353+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:55.696855+00:00, run_end_date=2024-09-27 16:04:56.283883+00:00, run_duration=0.587028, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1347, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321924
[2024-09-27T18:05:01.354+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:57.752404+00:00, run_end_date=2024-09-27 16:04:58.622689+00:00, run_duration=0.870285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1348, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321932
[2024-09-27T18:05:01.355+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:00.082315+00:00, run_end_date=2024-09-27 16:05:00.938541+00:00, run_duration=0.856226, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1349, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321939
[2024-09-27T18:05:01.401+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:01.465+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:01.467+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:05:01.467+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:05:01.470+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:01.471+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:01.471+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.472+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:01.472+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.472+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:01.473+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.473+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:01.473+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.476+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:02.416+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:02.500+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:03.827+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:04.767+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:04.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:06.238+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:07.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:07.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:09.945+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:10.893+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:10.978+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:12.419+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.421+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.427+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:04.887291+00:00, run_end_date=2024-09-27 16:05:05.848649+00:00, run_duration=0.961358, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1351, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321953
[2024-09-27T18:05:12.428+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:07.290743+00:00, run_end_date=2024-09-27 16:05:09.554486+00:00, run_duration=2.263743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1352, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321960
[2024-09-27T18:05:12.429+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:02.535970+00:00, run_end_date=2024-09-27 16:05:03.408084+00:00, run_duration=0.872114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1350, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321946
[2024-09-27T18:05:12.429+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:11.014989+00:00, run_end_date=2024-09-27 16:05:12.014439+00:00, run_duration=0.99945, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1353, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321967
[2024-09-27T18:05:12.465+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:05:12.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:12.560+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:06:00+00:00: scheduled__2023-09-27T17:06:00+00:00, state:running, queued_at: 2024-09-27 16:04:45.583421+00:00. externally triggered: False> successful
[2024-09-27T18:05:12.561+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:06:00+00:00, run_id=scheduled__2023-09-27T17:06:00+00:00, run_start_date=2024-09-27 16:04:45.605678+00:00, run_end_date=2024-09-27 16:05:12.561253+00:00, run_duration=26.955575, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:06:00+00:00, data_interval_end=2023-09-27 17:07:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:12.566+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:07:00+00:00, run_after=2023-09-27 17:08:00+00:00
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:12.575+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:05:12.575+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
[2024-09-27T18:05:12.576+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:12.576+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:12.576+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.581+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:13.513+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:13.600+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:14.891+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:15.821+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:15.905+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:17.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:18.088+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:18.171+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:19.329+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:20.269+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:20.354+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:21.263+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.267+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:18.207836+00:00, run_end_date=2024-09-27 16:05:18.928262+00:00, run_duration=0.720426, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1356, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321993
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:20.389734+00:00, run_end_date=2024-09-27 16:05:20.872924+00:00, run_duration=0.48319, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1357, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=322001
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:15.941664+00:00, run_end_date=2024-09-27 16:05:16.725295+00:00, run_duration=0.783631, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1355, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321986
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:13.635432+00:00, run_end_date=2024-09-27 16:05:14.473137+00:00, run_duration=0.837705, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1354, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321976
[2024-09-27T18:05:21.307+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:05:21.324+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:07:00+00:00: scheduled__2023-09-27T17:07:00+00:00, state:running, queued_at: 2024-09-27 16:04:49.384750+00:00. externally triggered: False> successful
[2024-09-27T18:05:21.325+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:07:00+00:00, run_id=scheduled__2023-09-27T17:07:00+00:00, run_start_date=2024-09-27 16:04:49.403385+00:00, run_end_date=2024-09-27 16:05:21.325097+00:00, run_duration=31.921712, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:07:00+00:00, data_interval_end=2023-09-27 17:08:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:21.327+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:05:21.335+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
[2024-09-27T18:05:21.335+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
[2024-09-27T18:05:21.337+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:21.337+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:21.337+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.338+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:21.338+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.338+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:21.338+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.342+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:22.276+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:22.361+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:23.364+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:24.298+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:24.383+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:25.274+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:26.212+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:26.297+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:27.289+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.290+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.290+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.296+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:26.333351+00:00, run_end_date=2024-09-27 16:05:26.898391+00:00, run_duration=0.56504, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1360, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322022
[2024-09-27T18:05:27.297+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:24.419408+00:00, run_end_date=2024-09-27 16:05:24.908390+00:00, run_duration=0.488982, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1359, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322015
[2024-09-27T18:05:27.297+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:22.396334+00:00, run_end_date=2024-09-27 16:05:22.939666+00:00, run_duration=0.543332, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1358, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322008
[2024-09-27T18:05:27.444+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:27.487+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:08:00+00:00: scheduled__2023-09-27T17:08:00+00:00, state:running, queued_at: 2024-09-27 16:04:54.599257+00:00. externally triggered: False> successful
[2024-09-27T18:05:27.488+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:08:00+00:00, run_id=scheduled__2023-09-27T17:08:00+00:00, run_start_date=2024-09-27 16:04:54.617561+00:00, run_end_date=2024-09-27 16:05:27.488237+00:00, run_duration=32.870676, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:08:00+00:00, data_interval_end=2023-09-27 17:09:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:27.492+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:09:00+00:00, run_after=2023-09-27 17:10:00+00:00
[2024-09-27T18:05:27.507+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
[2024-09-27T18:05:27.507+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:27.508+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:27.508+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:27.509+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
[2024-09-27T18:05:27.511+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:27.512+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:27.512+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.513+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:27.513+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.513+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:27.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.518+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:28.458+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:28.542+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:29.630+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:30.599+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:30.690+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:31.503+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:32.456+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:32.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:33.536+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.543+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:32.583916+00:00, run_end_date=2024-09-27 16:05:33.143325+00:00, run_duration=0.559409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1363, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322078
[2024-09-27T18:05:33.544+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:30.731992+00:00, run_end_date=2024-09-27 16:05:31.142127+00:00, run_duration=0.410135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1362, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322071
[2024-09-27T18:05:33.545+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:28.580955+00:00, run_end_date=2024-09-27 16:05:29.224861+00:00, run_duration=0.643906, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1361, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322050
[2024-09-27T18:05:33.594+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:33.610+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:09:00+00:00: scheduled__2023-09-27T17:09:00+00:00, state:running, queued_at: 2024-09-27 16:05:01.395036+00:00. externally triggered: False> successful
[2024-09-27T18:05:33.610+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:09:00+00:00, run_id=scheduled__2023-09-27T17:09:00+00:00, run_start_date=2024-09-27 16:05:01.414159+00:00, run_end_date=2024-09-27 16:05:33.610393+00:00, run_duration=32.196234, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:09:00+00:00, data_interval_end=2023-09-27 17:10:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:33.612+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:33.618+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
[2024-09-27T18:05:33.620+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:33.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:33.620+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:33.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:33.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:33.624+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:34.556+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:34.643+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:36.000+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:36.931+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:37.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:38.006+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:38.007+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:38.012+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:37.054928+00:00, run_end_date=2024-09-27 16:05:37.625245+00:00, run_duration=0.570317, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1365, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:33.619732+00:00, queued_by_job_id=1230, pid=322097
[2024-09-27T18:05:38.013+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:34.678686+00:00, run_end_date=2024-09-27 16:05:35.622274+00:00, run_duration=0.943588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1364, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:33.619732+00:00, queued_by_job_id=1230, pid=322086
[2024-09-27T18:05:38.045+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:38.075+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:10:00+00:00: scheduled__2023-09-27T17:10:00+00:00, state:running, queued_at: 2024-09-27 16:05:12.501405+00:00. externally triggered: False> successful
[2024-09-27T18:05:38.076+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:10:00+00:00, run_id=scheduled__2023-09-27T17:10:00+00:00, run_start_date=2024-09-27 16:05:12.519862+00:00, run_end_date=2024-09-27 16:05:38.076459+00:00, run_duration=25.556597, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:10:00+00:00, data_interval_end=2023-09-27 17:11:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:38.081+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:38.093+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:38.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:38.094+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:38.096+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:38.097+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:38.097+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:38.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:39.044+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:39.131+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:40.049+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:40.054+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:39.168107+00:00, run_end_date=2024-09-27 16:05:39.683428+00:00, run_duration=0.515321, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1366, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:38.095507+00:00, queued_by_job_id=1230, pid=322127
[2024-09-27T18:05:40.090+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:40.106+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:40.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:40.107+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:40.108+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:40.108+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:40.108+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:40.111+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:41.053+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:41.140+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:42.086+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:42.090+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:41.175746+00:00, run_end_date=2024-09-27 16:05:41.678683+00:00, run_duration=0.502937, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1367, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:40.107540+00:00, queued_by_job_id=1230, pid=322137
[2024-09-27T18:05:42.121+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:42.160+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:11:00+00:00: scheduled__2023-09-27T17:11:00+00:00, state:running, queued_at: 2024-09-27 16:05:27.441893+00:00. externally triggered: False> successful
[2024-09-27T18:05:42.161+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:11:00+00:00, run_id=scheduled__2023-09-27T17:11:00+00:00, run_start_date=2024-09-27 16:05:27.455171+00:00, run_end_date=2024-09-27 16:05:42.161049+00:00, run_duration=14.705878, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:11:00+00:00, data_interval_end=2023-09-27 17:12:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:42.165+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:42.179+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:42.180+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:42.180+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:42.182+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:42.183+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:42.184+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:42.188+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:43.162+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:43.254+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:44.137+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:44.142+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:43.295822+00:00, run_end_date=2024-09-27 16:05:43.713516+00:00, run_duration=0.417694, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1368, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:42.181454+00:00, queued_by_job_id=1230, pid=322158
[2024-09-27T18:05:44.168+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:44.206+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:44.207+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:44.207+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:44.209+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:44.210+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:44.210+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:44.214+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:45.169+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:45.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:46.219+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:46.225+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:45.291235+00:00, run_end_date=2024-09-27 16:05:45.786829+00:00, run_duration=0.495594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1369, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:44.208562+00:00, queued_by_job_id=1230, pid=322166
[2024-09-27T18:05:46.263+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:14:00+00:00, run_after=2023-09-27 17:15:00+00:00
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:46.297+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:46.297+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:46.301+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:47.251+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:47.336+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:48.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:49.037+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:49.120+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:49.918+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:49.919+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:49.925+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:49.156214+00:00, run_end_date=2024-09-27 16:05:49.495324+00:00, run_duration=0.33911, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1371, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:46.296297+00:00, queued_by_job_id=1230, pid=322194
[2024-09-27T18:05:49.926+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:47.373798+00:00, run_end_date=2024-09-27 16:05:47.730848+00:00, run_duration=0.35705, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1370, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:46.296297+00:00, queued_by_job_id=1230, pid=322186
[2024-09-27T18:05:49.967+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:50.008+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:50.008+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:50.009+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.011+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.960+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:51.044+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:52.640+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:53.579+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:53.664+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:54.866+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:55.790+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:55.874+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:57.068+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.069+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.069+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.075+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:51.081800+00:00, run_end_date=2024-09-27 16:05:52.276958+00:00, run_duration=1.195158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1372, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322202
[2024-09-27T18:05:57.076+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:55.911232+00:00, run_end_date=2024-09-27 16:05:56.655537+00:00, run_duration=0.744305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1374, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322216
[2024-09-27T18:05:57.077+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:53.700865+00:00, run_end_date=2024-09-27 16:05:54.435959+00:00, run_duration=0.735094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1373, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322209
[2024-09-27T18:05:57.126+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:05:57.174+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:12:00+00:00: scheduled__2023-09-27T17:12:00+00:00, state:running, queued_at: 2024-09-27 16:05:42.115792+00:00. externally triggered: False> successful
[2024-09-27T18:05:57.174+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:12:00+00:00, run_id=scheduled__2023-09-27T17:12:00+00:00, run_start_date=2024-09-27 16:05:42.138392+00:00, run_end_date=2024-09-27 16:05:57.174568+00:00, run_duration=15.036176, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:12:00+00:00, data_interval_end=2023-09-27 17:13:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:57.179+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:57.192+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:05:57.193+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:57.193+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:57.194+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:57.194+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:05:57.197+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:57.197+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:57.197+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.198+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:57.198+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.198+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:57.199+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.202+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:58.134+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:58.219+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:59.777+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:00.761+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:00.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:01.891+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:02.805+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:02.891+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:03.824+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.824+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.825+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.830+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:00.887693+00:00, run_end_date=2024-09-27 16:06:01.460657+00:00, run_duration=0.572964, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1376, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322232
[2024-09-27T18:06:03.831+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:02.931089+00:00, run_end_date=2024-09-27 16:06:03.393375+00:00, run_duration=0.462286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1377, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322239
[2024-09-27T18:06:03.832+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:58.256155+00:00, run_end_date=2024-09-27 16:05:59.344750+00:00, run_duration=1.088595, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1375, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322225
[2024-09-27T18:06:03.978+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:04.011+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:06:04.013+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.015+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:04.015+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:05.067+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:06.126+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:07.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:07.182+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:08.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:09.056+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:09.144+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:10.087+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:11.100+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:11.191+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:11.968+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.968+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.969+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.969+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.975+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:09.184018+00:00, run_end_date=2024-09-27 16:06:09.673775+00:00, run_duration=0.489757, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1380, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322261
[2024-09-27T18:06:11.975+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:11.229256+00:00, run_end_date=2024-09-27 16:06:11.547940+00:00, run_duration=0.318684, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1381, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322268
[2024-09-27T18:06:11.976+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:05.103968+00:00, run_end_date=2024-09-27 16:06:05.766222+00:00, run_duration=0.662254, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1378, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322247
[2024-09-27T18:06:11.977+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:07.218412+00:00, run_end_date=2024-09-27 16:06:07.700197+00:00, run_duration=0.481785, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1379, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322254
[2024-09-27T18:06:12.025+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:12.056+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:13:00+00:00: scheduled__2023-09-27T17:13:00+00:00, state:running, queued_at: 2024-09-27 16:05:46.257167+00:00. externally triggered: False> successful
[2024-09-27T18:06:12.056+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:13:00+00:00, run_id=scheduled__2023-09-27T17:13:00+00:00, run_start_date=2024-09-27 16:05:46.274070+00:00, run_end_date=2024-09-27 16:06:12.056543+00:00, run_duration=25.782473, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:13:00+00:00, data_interval_end=2023-09-27 17:14:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:12.058+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:14:00+00:00, run_after=2023-09-27 17:15:00+00:00
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:12.067+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:12.068+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:13.065+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:13.160+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:13.911+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:14.887+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:14.981+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:15.758+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:16.710+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:16.798+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:17.751+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:18.717+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:18.802+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:19.700+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.701+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.701+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.702+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.707+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:13.199065+00:00, run_end_date=2024-09-27 16:06:13.522928+00:00, run_duration=0.323863, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1382, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322276
[2024-09-27T18:06:19.708+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:18.837871+00:00, run_end_date=2024-09-27 16:06:19.267727+00:00, run_duration=0.429856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1385, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322302
[2024-09-27T18:06:19.709+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:15.017011+00:00, run_end_date=2024-09-27 16:06:15.335420+00:00, run_duration=0.318409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1383, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322285
[2024-09-27T18:06:19.710+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:16.840703+00:00, run_end_date=2024-09-27 16:06:17.337026+00:00, run_duration=0.496323, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1384, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322294
[2024-09-27T18:06:19.753+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:06:19.788+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:14:00+00:00: scheduled__2023-09-27T17:14:00+00:00, state:running, queued_at: 2024-09-27 16:05:49.959863+00:00. externally triggered: False> successful
[2024-09-27T18:06:19.789+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:14:00+00:00, run_id=scheduled__2023-09-27T17:14:00+00:00, run_start_date=2024-09-27 16:05:49.983993+00:00, run_end_date=2024-09-27 16:06:19.789076+00:00, run_duration=29.805083, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:14:00+00:00, data_interval_end=2023-09-27 17:15:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:19.793+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:06:19.806+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
[2024-09-27T18:06:19.807+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:19.807+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:19.808+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:19.808+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
[2024-09-27T18:06:19.811+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:19.812+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:19.812+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.812+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:19.813+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.813+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:19.813+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.817+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:20.766+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:20.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:21.590+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:22.562+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:22.651+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:24.027+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:24.972+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:25.058+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:26.173+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.180+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:20.889038+00:00, run_end_date=2024-09-27 16:06:21.198726+00:00, run_duration=0.309688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1386, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322309
[2024-09-27T18:06:26.181+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:22.688306+00:00, run_end_date=2024-09-27 16:06:23.624340+00:00, run_duration=0.936034, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1387, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322316
[2024-09-27T18:06:26.182+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:25.094527+00:00, run_end_date=2024-09-27 16:06:25.775800+00:00, run_duration=0.681273, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1388, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322323
[2024-09-27T18:06:26.235+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:06:26.265+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:15:00+00:00: scheduled__2023-09-27T17:15:00+00:00, state:running, queued_at: 2024-09-27 16:05:57.120307+00:00. externally triggered: False> successful
[2024-09-27T18:06:26.265+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:15:00+00:00, run_id=scheduled__2023-09-27T17:15:00+00:00, run_start_date=2024-09-27 16:05:57.139110+00:00, run_end_date=2024-09-27 16:06:26.265751+00:00, run_duration=29.126641, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:15:00+00:00, data_interval_end=2023-09-27 17:16:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:26.270+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:06:26.283+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
[2024-09-27T18:06:26.283+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:26.284+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:26.284+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
[2024-09-27T18:06:26.286+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:26.287+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:26.287+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:26.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:26.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:26.292+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:27.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:27.311+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:28.234+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:29.186+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:29.276+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:30.338+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:30.339+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:30.344+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:27.346769+00:00, run_end_date=2024-09-27 16:06:27.825457+00:00, run_duration=0.478688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1389, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:26.285439+00:00, queued_by_job_id=1230, pid=322330
[2024-09-27T18:06:30.345+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:29.318407+00:00, run_end_date=2024-09-27 16:06:29.903811+00:00, run_duration=0.585404, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1390, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:26.285439+00:00, queued_by_job_id=1230, pid=322337
[2024-09-27T18:06:30.376+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:30.406+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:16:00+00:00: scheduled__2023-09-27T17:16:00+00:00, state:running, queued_at: 2024-09-27 16:06:03.976169+00:00. externally triggered: False> successful
[2024-09-27T18:06:30.407+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:16:00+00:00, run_id=scheduled__2023-09-27T17:16:00+00:00, run_start_date=2024-09-27 16:06:03.987159+00:00, run_end_date=2024-09-27 16:06:30.407475+00:00, run_duration=26.420316, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:16:00+00:00, data_interval_end=2023-09-27 17:17:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:30.411+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:30.423+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
[2024-09-27T18:06:30.424+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:30.424+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
[2024-09-27T18:06:30.426+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:30.427+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:30.427+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:30.431+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:31.364+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:31.448+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:32.281+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:32.286+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:31.484146+00:00, run_end_date=2024-09-27 16:06:31.905246+00:00, run_duration=0.4211, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1391, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:30.425450+00:00, queued_by_job_id=1230, pid=322344
[2024-09-27T18:06:32.323+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:32.340+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:17:00+00:00: scheduled__2023-09-27T17:17:00+00:00, state:running, queued_at: 2024-09-27 16:06:12.020170+00:00. externally triggered: False> successful
[2024-09-27T18:06:32.341+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:17:00+00:00, run_id=scheduled__2023-09-27T17:17:00+00:00, run_start_date=2024-09-27 16:06:12.034176+00:00, run_end_date=2024-09-27 16:06:32.341272+00:00, run_duration=20.307096, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:17:00+00:00, data_interval_end=2023-09-27 17:18:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:32.345+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:33.385+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:19:00+00:00, run_after=2023-09-27 17:20:00+00:00
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:33.429+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:33.429+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:33.429+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:33.432+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:34.365+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:34.449+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:36.044+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:36.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:34.484702+00:00, run_end_date=2024-09-27 16:06:35.616415+00:00, run_duration=1.131713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1392, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:33.428900+00:00, queued_by_job_id=1230, pid=322352
[2024-09-27T18:06:36.189+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:06:36.239+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:36.239+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:36.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:36.240+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:36.242+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:36.243+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:36.243+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:36.244+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:36.244+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:36.248+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:37.186+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:37.272+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:38.479+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:39.414+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:39.498+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:41.060+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:41.061+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:41.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:39.534447+00:00, run_end_date=2024-09-27 16:06:40.630070+00:00, run_duration=1.095623, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1394, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:36.241386+00:00, queued_by_job_id=1230, pid=322368
[2024-09-27T18:06:41.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:37.307987+00:00, run_end_date=2024-09-27 16:06:38.069646+00:00, run_duration=0.761659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1393, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:36.241386+00:00, queued_by_job_id=1230, pid=322360
[2024-09-27T18:06:41.121+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:21:00+00:00, run_after=2023-09-27 17:22:00+00:00
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:41.152+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.156+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:42.094+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:42.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:43.383+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:44.322+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:44.406+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:45.612+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:46.549+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:46.633+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:47.979+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.980+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.980+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.986+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:46.669693+00:00, run_end_date=2024-09-27 16:06:47.599347+00:00, run_duration=0.929654, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1397, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322389
[2024-09-27T18:06:47.987+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:44.441679+00:00, run_end_date=2024-09-27 16:06:45.227831+00:00, run_duration=0.786152, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1396, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322382
[2024-09-27T18:06:47.988+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:42.214696+00:00, run_end_date=2024-09-27 16:06:42.987812+00:00, run_duration=0.773116, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1395, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322375
[2024-09-27T18:06:48.039+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:48.083+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:48.083+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:48.084+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:48.087+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:48.087+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:48.087+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.088+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:48.088+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.089+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:48.089+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.089+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:48.090+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:49.029+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:49.113+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:50.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:51.097+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:51.181+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:52.375+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:53.284+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:53.368+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:54.448+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:55.385+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:55.469+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:56.382+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.383+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.383+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.384+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.390+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:55.505301+00:00, run_end_date=2024-09-27 16:06:56.023265+00:00, run_duration=0.517964, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1401, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322420
[2024-09-27T18:06:56.391+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:53.406632+00:00, run_end_date=2024-09-27 16:06:54.069817+00:00, run_duration=0.663185, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1400, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322413
[2024-09-27T18:06:56.392+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:49.148626+00:00, run_end_date=2024-09-27 16:06:49.748203+00:00, run_duration=0.599577, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1398, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322397
[2024-09-27T18:06:56.392+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:51.216408+00:00, run_end_date=2024-09-27 16:06:51.964029+00:00, run_duration=0.747621, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1399, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322404
[2024-09-27T18:06:56.440+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:06:56.492+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:18:00+00:00: scheduled__2023-09-27T17:18:00+00:00, state:running, queued_at: 2024-09-27 16:06:33.378757+00:00. externally triggered: False> successful
[2024-09-27T18:06:56.492+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:18:00+00:00, run_id=scheduled__2023-09-27T17:18:00+00:00, run_start_date=2024-09-27 16:06:33.402973+00:00, run_end_date=2024-09-27 16:06:56.492898+00:00, run_duration=23.089925, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:18:00+00:00, data_interval_end=2023-09-27 17:19:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:56.497+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:19:00+00:00, run_after=2023-09-27 17:20:00+00:00
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:56.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:56.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:56.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:56.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.511+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:57.445+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:57.529+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:58.422+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:59.327+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:59.411+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:00.308+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:01.244+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:01.329+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:02.322+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:03.237+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:03.323+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:04.387+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.395+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:57.565982+00:00, run_end_date=2024-09-27 16:06:58.054510+00:00, run_duration=0.488528, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1402, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322427
[2024-09-27T18:07:04.396+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:03.359596+00:00, run_end_date=2024-09-27 16:07:03.989756+00:00, run_duration=0.63016, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1405, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322451
[2024-09-27T18:07:04.397+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:59.447724+00:00, run_end_date=2024-09-27 16:06:59.908939+00:00, run_duration=0.461215, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1403, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322435
[2024-09-27T18:07:04.397+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:01.360582+00:00, run_end_date=2024-09-27 16:07:01.896717+00:00, run_duration=0.536135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1404, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322444
[2024-09-27T18:07:04.444+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:07:04.483+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:19:00+00:00: scheduled__2023-09-27T17:19:00+00:00, state:running, queued_at: 2024-09-27 16:06:36.183037+00:00. externally triggered: False> successful
[2024-09-27T18:07:04.484+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:19:00+00:00, run_id=scheduled__2023-09-27T17:19:00+00:00, run_start_date=2024-09-27 16:06:36.200652+00:00, run_end_date=2024-09-27 16:07:04.483932+00:00, run_duration=28.28328, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:19:00+00:00, data_interval_end=2023-09-27 17:20:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:04.488+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:07:04.502+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
[2024-09-27T18:07:04.502+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
[2024-09-27T18:07:04.506+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:04.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:04.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:04.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:04.509+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.512+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:05.442+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:05.527+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:07.055+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:07.989+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:08.074+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:09.516+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:10.457+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:10.542+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:11.652+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.652+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.653+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.659+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:05.564468+00:00, run_end_date=2024-09-27 16:07:06.652463+00:00, run_duration=1.087995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1406, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322458
[2024-09-27T18:07:11.660+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:08.111615+00:00, run_end_date=2024-09-27 16:07:09.112150+00:00, run_duration=1.000535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1407, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322466
[2024-09-27T18:07:11.660+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:10.579402+00:00, run_end_date=2024-09-27 16:07:11.254871+00:00, run_duration=0.675469, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1408, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322473
[2024-09-27T18:07:11.812+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:24:00+00:00, run_after=2023-09-27 17:25:00+00:00
[2024-09-27T18:07:11.835+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:20:00+00:00: scheduled__2023-09-27T17:20:00+00:00, state:running, queued_at: 2024-09-27 16:06:41.115630+00:00. externally triggered: False> successful
[2024-09-27T18:07:11.835+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:20:00+00:00, run_id=scheduled__2023-09-27T17:20:00+00:00, run_start_date=2024-09-27 16:06:41.130110+00:00, run_end_date=2024-09-27 16:07:11.835912+00:00, run_duration=30.705802, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:20:00+00:00, data_interval_end=2023-09-27 17:21:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:11.837+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:21:00+00:00, run_after=2023-09-27 17:22:00+00:00
[2024-09-27T18:07:11.845+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
[2024-09-27T18:07:11.845+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
[2024-09-27T18:07:11.847+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:11.847+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:11.847+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.848+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:11.848+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.848+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:11.848+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.851+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:12.787+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:12.871+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:13.952+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:14.889+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:14.974+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:15.854+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:16.797+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:16.882+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:17.912+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.913+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.913+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.919+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:15.010286+00:00, run_end_date=2024-09-27 16:07:15.480132+00:00, run_duration=0.469846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1410, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322491
[2024-09-27T18:07:17.920+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:12.906925+00:00, run_end_date=2024-09-27 16:07:13.526688+00:00, run_duration=0.619763, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1409, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322482
[2024-09-27T18:07:17.920+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:16.917646+00:00, run_end_date=2024-09-27 16:07:17.546806+00:00, run_duration=0.62916, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1411, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322500
[2024-09-27T18:07:17.961+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:07:17.990+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:21:00+00:00: scheduled__2023-09-27T17:21:00+00:00, state:running, queued_at: 2024-09-27 16:06:48.033610+00:00. externally triggered: False> successful
[2024-09-27T18:07:17.991+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:21:00+00:00, run_id=scheduled__2023-09-27T17:21:00+00:00, run_start_date=2024-09-27 16:06:48.052005+00:00, run_end_date=2024-09-27 16:07:17.991482+00:00, run_duration=29.939477, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:21:00+00:00, data_interval_end=2023-09-27 17:22:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:17.996+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:07:18.009+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
[2024-09-27T18:07:18.009+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:18.010+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:18.010+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
[2024-09-27T18:07:18.012+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:18.013+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:18.013+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:18.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:19.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:20.005+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:20.960+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:21.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:21.964+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:21.965+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:21.970+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:21.084047+00:00, run_end_date=2024-09-27 16:07:21.561213+00:00, run_duration=0.477166, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1413, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:18.011493+00:00, queued_by_job_id=1230, pid=322515
[2024-09-27T18:07:21.971+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:19.082046+00:00, run_end_date=2024-09-27 16:07:19.610619+00:00, run_duration=0.528573, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1412, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:18.011493+00:00, queued_by_job_id=1230, pid=322508
[2024-09-27T18:07:22.001+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:07:22.032+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:22:00+00:00: scheduled__2023-09-27T17:22:00+00:00, state:running, queued_at: 2024-09-27 16:06:56.434500+00:00. externally triggered: False> successful
[2024-09-27T18:07:22.032+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:22:00+00:00, run_id=scheduled__2023-09-27T17:22:00+00:00, run_start_date=2024-09-27 16:06:56.451884+00:00, run_end_date=2024-09-27 16:07:22.032648+00:00, run_duration=25.580764, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:22:00+00:00, data_interval_end=2023-09-27 17:23:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:22.036+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:07:22.048+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:22.049+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:22.049+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:22.051+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:22.051+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:22.052+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:22.055+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:22.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:23.072+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:23.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:23.910+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:23.108986+00:00, run_end_date=2024-09-27 16:07:23.485581+00:00, run_duration=0.376595, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1414, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:22.050298+00:00, queued_by_job_id=1230, pid=322523
[2024-09-27T18:07:23.950+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:24:00+00:00, run_after=2023-09-27 17:25:00+00:00
[2024-09-27T18:07:23.968+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:23.968+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:23.969+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:23.970+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:23.970+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:23.970+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:23.974+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:24.905+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:24.990+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
