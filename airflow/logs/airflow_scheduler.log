  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2024-09-27T18:25:44.734+0200] {_client.py:1038} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.11&platform=Linux&arch=x86_64&database=sqlite&db_version=3.41&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2024-09-27T18:25:44.837+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-27 18:25:44 +0200] [328792] [INFO] Starting gunicorn 23.0.0
[2024-09-27T18:25:44.865+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-27T18:25:44.865+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-27 18:25:44 +0200] [328792] [INFO] Listening at: http://[::]:8793 (328792)
[2024-09-27 18:25:44 +0200] [328792] [INFO] Using worker: sync
[2024-09-27T18:25:44.869+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 328794
[2024-09-27T18:25:44.870+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27 18:25:44 +0200] [328793] [INFO] Booting worker with pid: 328793
[2024-09-27T18:25:44.874+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T18:25:44.900+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27 18:25:44 +0200] [328796] [INFO] Booting worker with pid: 328796
[2024-09-27T18:25:45.249+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:08:00+00:00, run_after=2023-09-27 18:09:00+00:00
[2024-09-27T18:25:45.291+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:03:00+00:00: scheduled__2023-09-27T18:03:00+00:00, state:running, queued_at: 2024-09-27 16:13:02.640095+00:00. externally triggered: False> successful
[2024-09-27T18:25:45.292+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:03:00+00:00, run_id=scheduled__2023-09-27T18:03:00+00:00, run_start_date=2024-09-27 16:13:02.652441+00:00, run_end_date=2024-09-27 16:25:45.292292+00:00, run_duration=762.639851, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:03:00+00:00, data_interval_end=2023-09-27 18:04:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:25:45.295+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:04:00+00:00, run_after=2023-09-27 18:05:00+00:00
[2024-09-27T18:25:45.308+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
[2024-09-27T18:25:45.309+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:25:45.309+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:25:45.309+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:25:45.309+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:25:45.309+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
[2024-09-27T18:25:45.311+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:04:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:25:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:25:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:25:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:25:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:45.313+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:25:45.313+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:45.316+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:46.253+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:46.338+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:47.930+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:48.857+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:48.942+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:50.261+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:51.193+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:51.278+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:53.290+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:54.313+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:54.401+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:55.157+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:25:55.158+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:25:55.158+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:25:55.158+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:25:55.170+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:48.978604+00:00, run_end_date=2024-09-27 16:25:49.867787+00:00, run_duration=0.889183, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1587, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:25:45.310441+00:00, queued_by_job_id=1585, pid=328806
[2024-09-27T18:25:55.171+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:46.368729+00:00, run_end_date=2024-09-27 16:25:47.506668+00:00, run_duration=1.137939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1586, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:25:45.310441+00:00, queued_by_job_id=1585, pid=328798
[2024-09-27T18:25:55.172+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:54.439081+00:00, run_end_date=2024-09-27 16:25:54.745316+00:00, run_duration=0.306235, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1589, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:25:45.310441+00:00, queued_by_job_id=1585, pid=328928
[2024-09-27T18:25:55.172+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:51.314338+00:00, run_end_date=2024-09-27 16:25:52.730717+00:00, run_duration=1.416379, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1588, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:25:45.310441+00:00, queued_by_job_id=1585, pid=328813
[2024-09-27T18:25:55.232+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:05:00+00:00, run_after=2023-09-27 18:06:00+00:00
[2024-09-27T18:25:55.271+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:04:00+00:00: scheduled__2023-09-27T18:04:00+00:00, state:running, queued_at: 2024-09-27 16:13:07.672807+00:00. externally triggered: False> successful
[2024-09-27T18:25:55.271+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:04:00+00:00, run_id=scheduled__2023-09-27T18:04:00+00:00, run_start_date=2024-09-27 16:13:07.690582+00:00, run_end_date=2024-09-27 16:25:55.271669+00:00, run_duration=767.581087, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:04:00+00:00, data_interval_end=2023-09-27 18:05:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:25:55.276+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:05:00+00:00, run_after=2023-09-27 18:06:00+00:00
[2024-09-27T18:25:55.286+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
[2024-09-27T18:25:55.287+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:25:55.287+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:25:55.287+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:25:55.287+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
[2024-09-27T18:25:55.289+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:25:55.289+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:25:55.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:55.289+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:25:55.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:55.289+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:25:55.290+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:55.293+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:56.223+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:56.310+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:57.107+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:25:58.020+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:25:58.104+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:25:59.612+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:00.551+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:00.639+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:02.028+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:02.029+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:02.029+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:02.040+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:58.143110+00:00, run_end_date=2024-09-27 16:25:59.176960+00:00, run_duration=1.03385, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1591, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:25:55.287931+00:00, queued_by_job_id=1585, pid=328943
[2024-09-27T18:26:02.041+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:25:56.346017+00:00, run_end_date=2024-09-27 16:25:56.684185+00:00, run_duration=0.338168, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1590, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:25:55.287931+00:00, queued_by_job_id=1585, pid=328935
[2024-09-27T18:26:02.041+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:00.676694+00:00, run_end_date=2024-09-27 16:26:01.636852+00:00, run_duration=0.960158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1592, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:25:55.287931+00:00, queued_by_job_id=1585, pid=328950
[2024-09-27T18:26:02.090+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:06:00+00:00, run_after=2023-09-27 18:07:00+00:00
[2024-09-27T18:26:02.120+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:05:00+00:00: scheduled__2023-09-27T18:05:00+00:00, state:running, queued_at: 2024-09-27 16:13:14.268906+00:00. externally triggered: False> successful
[2024-09-27T18:26:02.121+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:05:00+00:00, run_id=scheduled__2023-09-27T18:05:00+00:00, run_start_date=2024-09-27 16:13:14.283133+00:00, run_end_date=2024-09-27 16:26:02.121092+00:00, run_duration=767.837959, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:05:00+00:00, data_interval_end=2023-09-27 18:06:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:02.125+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:06:00+00:00, run_after=2023-09-27 18:07:00+00:00
[2024-09-27T18:26:02.139+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
[2024-09-27T18:26:02.139+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:02.139+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:02.140+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
[2024-09-27T18:26:02.143+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:02.144+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:02.144+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:02.145+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:02.145+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:02.149+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:03.087+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:03.172+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:04.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:05.153+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:05.238+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:07.052+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:07.053+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:07.057+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:05.276140+00:00, run_end_date=2024-09-27 16:26:06.651566+00:00, run_duration=1.375426, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1594, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:02.141360+00:00, queued_by_job_id=1585, pid=328964
[2024-09-27T18:26:07.057+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:03.209500+00:00, run_end_date=2024-09-27 16:26:03.787468+00:00, run_duration=0.577968, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1593, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:02.141360+00:00, queued_by_job_id=1585, pid=328957
[2024-09-27T18:26:07.092+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:07:00+00:00, run_after=2023-09-27 18:08:00+00:00
[2024-09-27T18:26:07.104+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:06:00+00:00: scheduled__2023-09-27T18:06:00+00:00, state:running, queued_at: 2024-09-27 16:13:22.505371+00:00. externally triggered: False> successful
[2024-09-27T18:26:07.104+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:06:00+00:00, run_id=scheduled__2023-09-27T18:06:00+00:00, run_start_date=2024-09-27 16:13:22.515571+00:00, run_end_date=2024-09-27 16:26:07.104647+00:00, run_duration=764.589076, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:06:00+00:00, data_interval_end=2023-09-27 18:07:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:07.106+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:07:00+00:00, run_after=2023-09-27 18:08:00+00:00
[2024-09-27T18:26:07.118+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
[2024-09-27T18:26:07.119+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:07.119+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:07:00+00:00 [scheduled]>
[2024-09-27T18:26:07.121+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:07.122+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:07.122+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:07.125+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:08.038+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:08.123+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:09.358+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:09.368+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:08.159990+00:00, run_end_date=2024-09-27 16:26:08.942408+00:00, run_duration=0.782418, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1595, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:07.120353+00:00, queued_by_job_id=1585, pid=328971
[2024-09-27T18:26:09.394+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:08:00+00:00, run_after=2023-09-27 18:09:00+00:00
[2024-09-27T18:26:09.419+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:07:00+00:00: scheduled__2023-09-27T18:07:00+00:00, state:running, queued_at: 2024-09-27 16:25:45.158430+00:00. externally triggered: False> successful
[2024-09-27T18:26:09.419+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:07:00+00:00, run_id=scheduled__2023-09-27T18:07:00+00:00, run_start_date=2024-09-27 16:25:45.264947+00:00, run_end_date=2024-09-27 16:26:09.419803+00:00, run_duration=24.154856, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:07:00+00:00, data_interval_end=2023-09-27 18:08:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:09.424+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:08:00+00:00, run_after=2023-09-27 18:09:00+00:00
[2024-09-27T18:26:10.464+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:09:00+00:00, run_after=2023-09-27 18:10:00+00:00
[2024-09-27T18:26:10.506+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:10.507+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:10.507+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:10.509+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:10.510+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:10.510+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:10.515+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:11.450+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:11.536+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:13.082+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:13.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:11.574367+00:00, run_end_date=2024-09-27 16:26:12.694879+00:00, run_duration=1.120512, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1596, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:10.508293+00:00, queued_by_job_id=1585, pid=328978
[2024-09-27T18:26:13.132+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:10:00+00:00, run_after=2023-09-27 18:11:00+00:00
[2024-09-27T18:26:13.174+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:13.174+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:13.174+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:13.175+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:13.177+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:13.177+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:13.177+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:13.178+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:13.178+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:13.182+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:14.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:14.207+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:15.459+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:16.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:16.480+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:17.997+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:17.997+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:18.003+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:16.515749+00:00, run_end_date=2024-09-27 16:26:17.606099+00:00, run_duration=1.09035, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1598, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:13.175990+00:00, queued_by_job_id=1585, pid=328995
[2024-09-27T18:26:18.004+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:14.242936+00:00, run_end_date=2024-09-27 16:26:15.041503+00:00, run_duration=0.798567, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1597, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:13.175990+00:00, queued_by_job_id=1585, pid=328987
[2024-09-27T18:26:18.247+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:11:00+00:00, run_after=2023-09-27 18:12:00+00:00
[2024-09-27T18:26:18.277+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:18.277+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:18.278+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:18.278+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:26:18.278+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:18.279+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:18.279+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:18.279+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:18.280+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:18.280+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:18.280+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:18.280+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:18.283+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:19.239+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:19.326+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:20.452+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:21.384+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:21.471+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:22.615+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:23.558+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:23.644+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:25.379+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:25.380+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:25.380+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:25.386+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:23.680805+00:00, run_end_date=2024-09-27 16:26:24.981752+00:00, run_duration=1.300947, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1601, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:18.278745+00:00, queued_by_job_id=1585, pid=329019
[2024-09-27T18:26:25.387+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:19.362539+00:00, run_end_date=2024-09-27 16:26:20.067043+00:00, run_duration=0.704504, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1599, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:18.278745+00:00, queued_by_job_id=1585, pid=329005
[2024-09-27T18:26:25.388+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:21.506931+00:00, run_end_date=2024-09-27 16:26:22.217247+00:00, run_duration=0.710316, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1600, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:18.278745+00:00, queued_by_job_id=1585, pid=329012
[2024-09-27T18:26:25.438+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:12:00+00:00, run_after=2023-09-27 18:13:00+00:00
[2024-09-27T18:26:25.501+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:25.502+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:25.502+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:25.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:26:25.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:26:25.503+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:08:00+00:00 [scheduled]>
[2024-09-27T18:26:25.506+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:25.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:25.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:25.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:25.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:25.509+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:25.509+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:25.509+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:25.509+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:25.513+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:26.477+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:26.568+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:27.811+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:28.755+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:28.840+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:30.087+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:31.027+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:31.113+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:32.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:33.112+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:33.199+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:34.222+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:34.223+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:34.223+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:34.223+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:34.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:33.236711+00:00, run_end_date=2024-09-27 16:26:33.788373+00:00, run_duration=0.551662, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1605, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:25.505095+00:00, queued_by_job_id=1585, pid=329053
[2024-09-27T18:26:34.230+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:28.876510+00:00, run_end_date=2024-09-27 16:26:29.692801+00:00, run_duration=0.816291, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1603, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:25.505095+00:00, queued_by_job_id=1585, pid=329039
[2024-09-27T18:26:34.230+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:26.600176+00:00, run_end_date=2024-09-27 16:26:27.378911+00:00, run_duration=0.778735, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1602, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:25.505095+00:00, queued_by_job_id=1585, pid=329032
[2024-09-27T18:26:34.231+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:31.150030+00:00, run_end_date=2024-09-27 16:26:31.742906+00:00, run_duration=0.592876, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1604, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:25.505095+00:00, queued_by_job_id=1585, pid=329046
[2024-09-27T18:26:34.283+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:13:00+00:00, run_after=2023-09-27 18:14:00+00:00
[2024-09-27T18:26:34.309+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:08:00+00:00: scheduled__2023-09-27T18:08:00+00:00, state:running, queued_at: 2024-09-27 16:26:10.456888+00:00. externally triggered: False> successful
[2024-09-27T18:26:34.309+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:08:00+00:00, run_id=scheduled__2023-09-27T18:08:00+00:00, run_start_date=2024-09-27 16:26:10.475809+00:00, run_end_date=2024-09-27 16:26:34.309572+00:00, run_duration=23.833763, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:08:00+00:00, data_interval_end=2023-09-27 18:09:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:34.311+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:09:00+00:00, run_after=2023-09-27 18:10:00+00:00
[2024-09-27T18:26:34.319+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
[2024-09-27T18:26:34.319+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:34.319+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:34.320+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:26:34.320+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:26:34.320+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:09:00+00:00 [scheduled]>
[2024-09-27T18:26:34.321+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:12:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:09:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:34.321+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:34.322+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:34.322+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:34.322+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:34.322+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:34.322+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:34.322+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:34.322+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:34.325+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:35.274+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:35.360+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:36.299+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:37.245+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:37.331+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:38.177+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:39.121+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:39.206+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:40.427+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:41.368+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:41.454+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:42.892+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:42.893+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:42.893+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:42.893+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:42.899+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:39.243396+00:00, run_end_date=2024-09-27 16:26:40.034253+00:00, run_duration=0.790857, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1608, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:34.320868+00:00, queued_by_job_id=1585, pid=329086
[2024-09-27T18:26:42.900+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:37.368428+00:00, run_end_date=2024-09-27 16:26:37.779014+00:00, run_duration=0.410586, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1607, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:34.320868+00:00, queued_by_job_id=1585, pid=329067
[2024-09-27T18:26:42.901+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:35.397078+00:00, run_end_date=2024-09-27 16:26:35.925984+00:00, run_duration=0.528906, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1606, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:34.320868+00:00, queued_by_job_id=1585, pid=329060
[2024-09-27T18:26:42.902+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:41.492024+00:00, run_end_date=2024-09-27 16:26:42.491803+00:00, run_duration=0.999779, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1609, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:34.320868+00:00, queued_by_job_id=1585, pid=329093
[2024-09-27T18:26:42.945+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:10:00+00:00, run_after=2023-09-27 18:11:00+00:00
[2024-09-27T18:26:42.984+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:09:00+00:00: scheduled__2023-09-27T18:09:00+00:00, state:running, queued_at: 2024-09-27 16:26:13.126279+00:00. externally triggered: False> successful
[2024-09-27T18:26:42.985+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:09:00+00:00, run_id=scheduled__2023-09-27T18:09:00+00:00, run_start_date=2024-09-27 16:26:13.139864+00:00, run_end_date=2024-09-27 16:26:42.985201+00:00, run_duration=29.845337, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:09:00+00:00, data_interval_end=2023-09-27 18:10:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:42.990+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:10:00+00:00, run_after=2023-09-27 18:11:00+00:00
[2024-09-27T18:26:43.003+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
[2024-09-27T18:26:43.003+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:43.004+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:43.004+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:26:43.005+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:10:00+00:00 [scheduled]>
[2024-09-27T18:26:43.007+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:12:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:43.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:43.008+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:43.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:43.009+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:43.009+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:43.009+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:43.012+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:43.973+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:44.062+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:45.268+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:46.201+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:46.286+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:47.339+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:48.291+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:48.379+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:49.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:49.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:49.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:49.349+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:48.417403+00:00, run_end_date=2024-09-27 16:26:48.943693+00:00, run_duration=0.52629, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:43.006128+00:00, queued_by_job_id=1585, pid=329123
[2024-09-27T18:26:49.350+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:46.322616+00:00, run_end_date=2024-09-27 16:26:46.947984+00:00, run_duration=0.625368, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1611, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:43.006128+00:00, queued_by_job_id=1585, pid=329116
[2024-09-27T18:26:49.350+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:44.099122+00:00, run_end_date=2024-09-27 16:26:44.848447+00:00, run_duration=0.749325, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1610, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:43.006128+00:00, queued_by_job_id=1585, pid=329108
[2024-09-27T18:26:49.615+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:14:00+00:00, run_after=2023-09-27 18:15:00+00:00
[2024-09-27T18:26:49.641+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:10:00+00:00: scheduled__2023-09-27T18:10:00+00:00, state:running, queued_at: 2024-09-27 16:26:18.244227+00:00. externally triggered: False> successful
[2024-09-27T18:26:49.642+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:10:00+00:00, run_id=scheduled__2023-09-27T18:10:00+00:00, run_start_date=2024-09-27 16:26:18.253633+00:00, run_end_date=2024-09-27 16:26:49.642166+00:00, run_duration=31.388533, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:10:00+00:00, data_interval_end=2023-09-27 18:11:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:49.644+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:11:00+00:00, run_after=2023-09-27 18:12:00+00:00
[2024-09-27T18:26:49.652+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
[2024-09-27T18:26:49.652+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:49.653+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:49.653+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:26:49.653+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:11:00+00:00 [scheduled]>
[2024-09-27T18:26:49.654+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:12:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:49.654+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:26:49.654+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:49.655+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:26:49.655+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:49.655+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:49.655+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:49.658+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:50.643+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:50.733+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:52.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:53.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:53.172+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:54.243+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:55.181+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:55.267+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:56.063+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:56.064+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:56.064+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:26:56.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:50.769677+00:00, run_end_date=2024-09-27 16:26:51.722493+00:00, run_duration=0.952816, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1613, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:26:49.653755+00:00, queued_by_job_id=1585, pid=329145
[2024-09-27T18:26:56.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:53.208935+00:00, run_end_date=2024-09-27 16:26:53.856143+00:00, run_duration=0.647208, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1614, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:26:49.653755+00:00, queued_by_job_id=1585, pid=329154
[2024-09-27T18:26:56.068+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:55.303358+00:00, run_end_date=2024-09-27 16:26:55.652659+00:00, run_duration=0.349301, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1615, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:49.653755+00:00, queued_by_job_id=1585, pid=329193
[2024-09-27T18:26:56.105+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:12:00+00:00, run_after=2023-09-27 18:13:00+00:00
[2024-09-27T18:26:56.119+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:11:00+00:00: scheduled__2023-09-27T18:11:00+00:00, state:running, queued_at: 2024-09-27 16:26:25.432358+00:00. externally triggered: False> successful
[2024-09-27T18:26:56.120+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:11:00+00:00, run_id=scheduled__2023-09-27T18:11:00+00:00, run_start_date=2024-09-27 16:26:25.452216+00:00, run_end_date=2024-09-27 16:26:56.120083+00:00, run_duration=30.667867, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:11:00+00:00, data_interval_end=2023-09-27 18:12:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:26:56.122+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:12:00+00:00, run_after=2023-09-27 18:13:00+00:00
[2024-09-27T18:26:56.135+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
[2024-09-27T18:26:56.135+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:26:56.136+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:26:56.136+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:12:00+00:00 [scheduled]>
[2024-09-27T18:26:56.139+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:26:56.139+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:26:56.139+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:56.140+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:26:56.140+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:56.144+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:57.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:57.171+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:26:58.254+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:26:59.241+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:26:59.328+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:00.465+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:00.465+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:00.470+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:57.207142+00:00, run_end_date=2024-09-27 16:26:57.850967+00:00, run_duration=0.643825, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1616, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:26:56.137500+00:00, queued_by_job_id=1585, pid=329200
[2024-09-27T18:27:00.470+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:26:59.364190+00:00, run_end_date=2024-09-27 16:27:00.085858+00:00, run_duration=0.721668, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1617, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:26:56.137500+00:00, queued_by_job_id=1585, pid=329218
[2024-09-27T18:27:00.494+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:13:00+00:00, run_after=2023-09-27 18:14:00+00:00
[2024-09-27T18:27:00.511+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:12:00+00:00: scheduled__2023-09-27T18:12:00+00:00, state:running, queued_at: 2024-09-27 16:26:34.276836+00:00. externally triggered: False> successful
[2024-09-27T18:27:00.511+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:12:00+00:00, run_id=scheduled__2023-09-27T18:12:00+00:00, run_start_date=2024-09-27 16:26:34.290748+00:00, run_end_date=2024-09-27 16:27:00.511914+00:00, run_duration=26.221166, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:12:00+00:00, data_interval_end=2023-09-27 18:13:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:00.513+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:13:00+00:00, run_after=2023-09-27 18:14:00+00:00
[2024-09-27T18:27:00.526+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
[2024-09-27T18:27:00.527+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:00.528+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
[2024-09-27T18:27:00.530+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:00.531+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:00.531+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:00.535+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:01.494+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:01.580+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:02.464+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:02.469+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:01.618327+00:00, run_end_date=2024-09-27 16:27:02.086497+00:00, run_duration=0.46817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1618, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:00.528851+00:00, queued_by_job_id=1585, pid=329231
[2024-09-27T18:27:02.511+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:14:00+00:00, run_after=2023-09-27 18:15:00+00:00
[2024-09-27T18:27:02.545+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
[2024-09-27T18:27:02.546+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:02.546+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:13:00+00:00 [scheduled]>
[2024-09-27T18:27:02.548+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:02.549+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:02.549+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:02.553+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:03.492+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:03.579+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:05.020+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:05.026+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:03.615654+00:00, run_end_date=2024-09-27 16:27:04.609296+00:00, run_duration=0.993642, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1619, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:02.547232+00:00, queued_by_job_id=1585, pid=329239
[2024-09-27T18:27:05.064+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:15:00+00:00, run_after=2023-09-27 18:16:00+00:00
[2024-09-27T18:27:05.104+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:13:00+00:00: scheduled__2023-09-27T18:13:00+00:00, state:running, queued_at: 2024-09-27 16:26:49.610280+00:00. externally triggered: False> successful
[2024-09-27T18:27:05.105+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:13:00+00:00, run_id=scheduled__2023-09-27T18:13:00+00:00, run_start_date=2024-09-27 16:26:49.625123+00:00, run_end_date=2024-09-27 16:27:05.105435+00:00, run_duration=15.480312, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:13:00+00:00, data_interval_end=2023-09-27 18:14:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:05.109+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:14:00+00:00, run_after=2023-09-27 18:15:00+00:00
[2024-09-27T18:27:05.123+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:05.123+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:05.124+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:05.126+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:05.126+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:05.127+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:05.130+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:06.071+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:06.157+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:07.158+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:07.163+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:06.192572+00:00, run_end_date=2024-09-27 16:27:06.760818+00:00, run_duration=0.568246, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1620, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:05.124973+00:00, queued_by_job_id=1585, pid=329254
[2024-09-27T18:27:07.189+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:15:00+00:00, run_after=2023-09-27 18:16:00+00:00
[2024-09-27T18:27:07.229+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:07.229+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:07.230+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:07.232+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:07.233+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:07.233+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:07.238+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:08.179+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:08.263+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:09.225+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:09.231+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:08.299779+00:00, run_end_date=2024-09-27 16:27:08.808165+00:00, run_duration=0.508386, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1621, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:07.231216+00:00, queued_by_job_id=1585, pid=329261
[2024-09-27T18:27:09.279+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:16:00+00:00, run_after=2023-09-27 18:17:00+00:00
[2024-09-27T18:27:09.322+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:09.322+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:09.322+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:09.322+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:09.323+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:09.324+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:09.324+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:09.324+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:09.324+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:09.327+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:10.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:10.313+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:11.454+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:12.388+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:12.472+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:13.807+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:13.808+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:13.813+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:12.508899+00:00, run_end_date=2024-09-27 16:27:13.436852+00:00, run_duration=0.927953, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1623, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:09.323141+00:00, queued_by_job_id=1585, pid=329283
[2024-09-27T18:27:13.814+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:10.348345+00:00, run_end_date=2024-09-27 16:27:11.060705+00:00, run_duration=0.71236, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1622, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:09.323141+00:00, queued_by_job_id=1585, pid=329276
[2024-09-27T18:27:13.847+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:17:00+00:00, run_after=2023-09-27 18:18:00+00:00
[2024-09-27T18:27:13.904+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:13.905+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:13.905+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:13.905+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:27:13.906+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:14:00+00:00 [scheduled]>
[2024-09-27T18:27:13.908+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:13.909+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:13.909+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:13.909+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:13.910+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:13.910+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:13.910+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:13.916+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:14.851+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:14.936+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:15.818+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:16.763+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:16.849+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:17.929+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:18.874+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:18.959+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:19.871+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:19.871+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:19.871+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:19.874+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:18.995514+00:00, run_end_date=2024-09-27 16:27:19.449062+00:00, run_duration=0.453548, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1626, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:13.906996+00:00, queued_by_job_id=1585, pid=329326
[2024-09-27T18:27:19.875+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:14.972163+00:00, run_end_date=2024-09-27 16:27:15.386342+00:00, run_duration=0.414179, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1624, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:13.906996+00:00, queued_by_job_id=1585, pid=329300
[2024-09-27T18:27:19.875+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:16.885547+00:00, run_end_date=2024-09-27 16:27:17.522767+00:00, run_duration=0.63722, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1625, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:13.906996+00:00, queued_by_job_id=1585, pid=329309
[2024-09-27T18:27:20.120+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:18:00+00:00, run_after=2023-09-27 18:19:00+00:00
[2024-09-27T18:27:20.143+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:14:00+00:00: scheduled__2023-09-27T18:14:00+00:00, state:running, queued_at: 2024-09-27 16:27:05.057629+00:00. externally triggered: False> successful
[2024-09-27T18:27:20.143+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:14:00+00:00, run_id=scheduled__2023-09-27T18:14:00+00:00, run_start_date=2024-09-27 16:27:05.081790+00:00, run_end_date=2024-09-27 16:27:20.143949+00:00, run_duration=15.062159, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:14:00+00:00, data_interval_end=2023-09-27 18:15:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:20.146+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:15:00+00:00, run_after=2023-09-27 18:16:00+00:00
[2024-09-27T18:27:20.153+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
[2024-09-27T18:27:20.154+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:20.154+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:20.154+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:27:20.154+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
[2024-09-27T18:27:20.155+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:15:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:20.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:20.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:20.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:20.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:20.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:20.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:20.159+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:21.094+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:21.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:22.182+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:23.118+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:23.203+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:24.089+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:25.039+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:25.126+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:26.191+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:26.191+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:26.191+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:26.194+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:21.214830+00:00, run_end_date=2024-09-27 16:27:21.794335+00:00, run_duration=0.579505, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1627, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:20.154940+00:00, queued_by_job_id=1585, pid=329334
[2024-09-27T18:27:26.195+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:23.239079+00:00, run_end_date=2024-09-27 16:27:23.658715+00:00, run_duration=0.419636, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1628, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:20.154940+00:00, queued_by_job_id=1585, pid=329341
[2024-09-27T18:27:26.195+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:25.163623+00:00, run_end_date=2024-09-27 16:27:25.806530+00:00, run_duration=0.642907, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1629, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:20.154940+00:00, queued_by_job_id=1585, pid=329348
[2024-09-27T18:27:26.235+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:16:00+00:00, run_after=2023-09-27 18:17:00+00:00
[2024-09-27T18:27:26.259+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
[2024-09-27T18:27:26.259+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:26.260+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:26.260+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:27:26.260+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:15:00+00:00 [scheduled]>
[2024-09-27T18:27:26.261+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:15:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:26.261+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:26.261+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:26.262+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:26.262+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:26.262+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:26.262+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:26.265+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:27.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:27.283+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:28.367+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:29.307+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:29.396+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:30.466+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:31.483+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:31.570+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:33.028+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:33.029+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:33.029+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:33.035+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:27.319697+00:00, run_end_date=2024-09-27 16:27:27.955530+00:00, run_duration=0.635833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1630, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:26.260768+00:00, queued_by_job_id=1585, pid=329363
[2024-09-27T18:27:33.036+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:29.432389+00:00, run_end_date=2024-09-27 16:27:30.075518+00:00, run_duration=0.643129, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1631, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:26.260768+00:00, queued_by_job_id=1585, pid=329374
[2024-09-27T18:27:33.036+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:31.607453+00:00, run_end_date=2024-09-27 16:27:32.559600+00:00, run_duration=0.952147, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1632, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:26.260768+00:00, queued_by_job_id=1585, pid=329410
[2024-09-27T18:27:33.076+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:17:00+00:00, run_after=2023-09-27 18:18:00+00:00
[2024-09-27T18:27:33.105+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:15:00+00:00: scheduled__2023-09-27T18:15:00+00:00, state:running, queued_at: 2024-09-27 16:27:09.273590+00:00. externally triggered: False> successful
[2024-09-27T18:27:33.105+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:15:00+00:00, run_id=scheduled__2023-09-27T18:15:00+00:00, run_start_date=2024-09-27 16:27:09.291468+00:00, run_end_date=2024-09-27 16:27:33.105889+00:00, run_duration=23.814421, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:15:00+00:00, data_interval_end=2023-09-27 18:16:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:33.110+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:16:00+00:00, run_after=2023-09-27 18:17:00+00:00
[2024-09-27T18:27:33.118+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
[2024-09-27T18:27:33.118+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:33.119+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:33.119+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:16:00+00:00 [scheduled]>
[2024-09-27T18:27:33.120+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:16:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:33.120+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:33.120+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:33.120+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:33.120+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:33.124+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:34.090+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:34.178+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:35.305+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:36.258+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:36.346+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:37.242+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:37.242+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:37.246+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:34.215327+00:00, run_end_date=2024-09-27 16:27:34.903452+00:00, run_duration=0.688125, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1633, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:33.119535+00:00, queued_by_job_id=1585, pid=329422
[2024-09-27T18:27:37.246+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:36.379029+00:00, run_end_date=2024-09-27 16:27:36.864924+00:00, run_duration=0.485895, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1634, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:33.119535+00:00, queued_by_job_id=1585, pid=329446
[2024-09-27T18:27:37.273+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:17:00+00:00, run_after=2023-09-27 18:18:00+00:00
[2024-09-27T18:27:37.300+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:16:00+00:00: scheduled__2023-09-27T18:16:00+00:00, state:running, queued_at: 2024-09-27 16:27:13.841140+00:00. externally triggered: False> successful
[2024-09-27T18:27:37.301+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:16:00+00:00, run_id=scheduled__2023-09-27T18:16:00+00:00, run_start_date=2024-09-27 16:27:13.863702+00:00, run_end_date=2024-09-27 16:27:37.301408+00:00, run_duration=23.437706, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:16:00+00:00, data_interval_end=2023-09-27 18:17:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:37.306+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:17:00+00:00, run_after=2023-09-27 18:18:00+00:00
[2024-09-27T18:27:37.313+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
[2024-09-27T18:27:37.314+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:37.314+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:17:00+00:00 [scheduled]>
[2024-09-27T18:27:37.315+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:17:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:37.315+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:37.315+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:37.318+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:38.264+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:38.349+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:39.424+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:39.430+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:38.385008+00:00, run_end_date=2024-09-27 16:27:38.954829+00:00, run_duration=0.569821, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1635, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:37.314599+00:00, queued_by_job_id=1585, pid=329453
[2024-09-27T18:27:39.471+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:18:00+00:00, run_after=2023-09-27 18:19:00+00:00
[2024-09-27T18:27:39.489+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:17:00+00:00: scheduled__2023-09-27T18:17:00+00:00, state:running, queued_at: 2024-09-27 16:27:20.117668+00:00. externally triggered: False> successful
[2024-09-27T18:27:39.490+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:17:00+00:00, run_id=scheduled__2023-09-27T18:17:00+00:00, run_start_date=2024-09-27 16:27:20.127287+00:00, run_end_date=2024-09-27 16:27:39.490225+00:00, run_duration=19.362938, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:17:00+00:00, data_interval_end=2023-09-27 18:18:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:27:39.494+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:18:00+00:00, run_after=2023-09-27 18:19:00+00:00
[2024-09-27T18:27:40.537+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:19:00+00:00, run_after=2023-09-27 18:20:00+00:00
[2024-09-27T18:27:40.580+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:40.580+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:40.581+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:40.582+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:40.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:40.582+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:40.585+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:41.543+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:41.629+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:42.795+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:42.801+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:41.665500+00:00, run_end_date=2024-09-27 16:27:42.395338+00:00, run_duration=0.729838, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1636, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:40.581532+00:00, queued_by_job_id=1585, pid=329472
[2024-09-27T18:27:42.837+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:20:00+00:00, run_after=2023-09-27 18:21:00+00:00
[2024-09-27T18:27:42.893+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:42.894+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:42.894+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:42.895+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:42.897+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:42.898+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:42.898+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:42.899+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:42.899+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:42.903+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:43.849+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:43.935+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:45.055+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:46.001+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:46.086+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:47.130+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:47.130+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:47.136+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:46.123246+00:00, run_end_date=2024-09-27 16:27:46.698863+00:00, run_duration=0.575617, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1638, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:42.896295+00:00, queued_by_job_id=1585, pid=329486
[2024-09-27T18:27:47.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:43.971834+00:00, run_end_date=2024-09-27 16:27:44.642620+00:00, run_duration=0.670786, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1637, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:42.896295+00:00, queued_by_job_id=1585, pid=329479
[2024-09-27T18:27:47.192+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:21:00+00:00, run_after=2023-09-27 18:22:00+00:00
[2024-09-27T18:27:47.247+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:47.247+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:47.248+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:47.248+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:27:47.248+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:47.251+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:47.252+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:47.252+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:47.253+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:47.253+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:47.253+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:47.254+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:47.258+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:48.190+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:48.275+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:49.135+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:50.081+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:50.167+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:51.747+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:52.701+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:52.786+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:54.195+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:54.196+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:54.196+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:27:54.202+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:52.823753+00:00, run_end_date=2024-09-27 16:27:53.762031+00:00, run_duration=0.938278, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1641, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:47.249957+00:00, queued_by_job_id=1585, pid=329524
[2024-09-27T18:27:54.203+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:50.204573+00:00, run_end_date=2024-09-27 16:27:51.304248+00:00, run_duration=1.099675, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1640, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:47.249957+00:00, queued_by_job_id=1585, pid=329509
[2024-09-27T18:27:54.204+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:48.311468+00:00, run_end_date=2024-09-27 16:27:48.742224+00:00, run_duration=0.430756, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1639, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:47.249957+00:00, queued_by_job_id=1585, pid=329501
[2024-09-27T18:27:54.474+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:22:00+00:00, run_after=2023-09-27 18:23:00+00:00
[2024-09-27T18:27:54.511+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:54.511+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:27:54.511+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:27:54.512+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:27:54.512+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:27:54.512+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:18:00+00:00 [scheduled]>
[2024-09-27T18:27:54.513+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:27:54.514+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:27:54.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:54.514+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:27:54.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:54.514+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:27:54.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:54.514+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:27:54.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:54.517+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:55.446+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:55.531+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:56.882+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:27:57.821+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:27:57.905+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:27:59.348+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:00.279+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:00.364+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:01.243+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:02.195+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:02.280+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:03.282+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:03.282+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:03.283+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:03.283+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:03.290+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:02.317535+00:00, run_end_date=2024-09-27 16:28:02.926308+00:00, run_duration=0.608773, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1645, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:27:54.512854+00:00, queued_by_job_id=1585, pid=329571
[2024-09-27T18:28:03.290+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:55.562150+00:00, run_end_date=2024-09-27 16:27:56.528623+00:00, run_duration=0.966473, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1642, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:27:54.512854+00:00, queued_by_job_id=1585, pid=329533
[2024-09-27T18:28:03.291+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:00.399860+00:00, run_end_date=2024-09-27 16:28:00.827325+00:00, run_duration=0.427465, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1644, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:27:54.512854+00:00, queued_by_job_id=1585, pid=329556
[2024-09-27T18:28:03.292+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:27:57.941895+00:00, run_end_date=2024-09-27 16:27:58.942619+00:00, run_duration=1.000724, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1643, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:27:54.512854+00:00, queued_by_job_id=1585, pid=329548
[2024-09-27T18:28:03.346+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:23:00+00:00, run_after=2023-09-27 18:24:00+00:00
[2024-09-27T18:28:03.372+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:18:00+00:00: scheduled__2023-09-27T18:18:00+00:00, state:running, queued_at: 2024-09-27 16:27:40.531344+00:00. externally triggered: False> successful
[2024-09-27T18:28:03.372+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:18:00+00:00, run_id=scheduled__2023-09-27T18:18:00+00:00, run_start_date=2024-09-27 16:27:40.554651+00:00, run_end_date=2024-09-27 16:28:03.372878+00:00, run_duration=22.818227, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:18:00+00:00, data_interval_end=2023-09-27 18:19:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:03.374+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:19:00+00:00, run_after=2023-09-27 18:20:00+00:00
[2024-09-27T18:28:03.382+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
[2024-09-27T18:28:03.382+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:03.382+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:03.383+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:28:03.383+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:28:03.383+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:19:00+00:00 [scheduled]>
[2024-09-27T18:28:03.384+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:03.384+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:03.385+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:03.385+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:03.385+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:03.385+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:03.385+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:03.385+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:03.385+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:03.388+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:04.326+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:04.411+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:05.331+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:06.273+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:06.357+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:07.350+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:08.289+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:08.374+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:09.449+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:10.387+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:10.472+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:11.992+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:11.993+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:11.993+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:11.993+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:12.000+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:10.510554+00:00, run_end_date=2024-09-27 16:28:11.577839+00:00, run_duration=1.067285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1649, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:03.383828+00:00, queued_by_job_id=1585, pid=329609
[2024-09-27T18:28:12.001+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:06.387935+00:00, run_end_date=2024-09-27 16:28:06.960133+00:00, run_duration=0.572198, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1647, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:03.383828+00:00, queued_by_job_id=1585, pid=329587
[2024-09-27T18:28:12.001+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:04.448478+00:00, run_end_date=2024-09-27 16:28:04.900259+00:00, run_duration=0.451781, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1646, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:03.383828+00:00, queued_by_job_id=1585, pid=329580
[2024-09-27T18:28:12.002+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:08.409640+00:00, run_end_date=2024-09-27 16:28:09.035639+00:00, run_duration=0.625999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1648, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:03.383828+00:00, queued_by_job_id=1585, pid=329594
[2024-09-27T18:28:12.050+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:20:00+00:00, run_after=2023-09-27 18:21:00+00:00
[2024-09-27T18:28:12.089+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:19:00+00:00: scheduled__2023-09-27T18:19:00+00:00, state:running, queued_at: 2024-09-27 16:27:42.831420+00:00. externally triggered: False> successful
[2024-09-27T18:28:12.089+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:19:00+00:00, run_id=scheduled__2023-09-27T18:19:00+00:00, run_start_date=2024-09-27 16:27:42.855619+00:00, run_end_date=2024-09-27 16:28:12.089769+00:00, run_duration=29.23415, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:19:00+00:00, data_interval_end=2023-09-27 18:20:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:12.094+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:20:00+00:00, run_after=2023-09-27 18:21:00+00:00
[2024-09-27T18:28:12.108+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
[2024-09-27T18:28:12.109+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:12.109+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:12.109+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:28:12.110+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:20:00+00:00 [scheduled]>
[2024-09-27T18:28:12.113+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:20:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:12.113+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:12.114+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:12.114+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:12.114+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:12.115+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:12.115+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:12.118+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:13.055+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:13.141+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:14.471+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:15.400+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:15.485+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:17.063+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:18.002+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:18.088+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:19.241+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:19.241+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:19.242+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:19.248+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:15.522053+00:00, run_end_date=2024-09-27 16:28:16.680258+00:00, run_duration=1.158205, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1651, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:12.111451+00:00, queued_by_job_id=1585, pid=329636
[2024-09-27T18:28:19.249+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:13.177700+00:00, run_end_date=2024-09-27 16:28:14.036788+00:00, run_duration=0.859088, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1650, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:12.111451+00:00, queued_by_job_id=1585, pid=329618
[2024-09-27T18:28:19.249+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:18.126300+00:00, run_end_date=2024-09-27 16:28:18.848557+00:00, run_duration=0.722257, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1652, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:12.111451+00:00, queued_by_job_id=1585, pid=329645
[2024-09-27T18:28:19.295+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:21:00+00:00, run_after=2023-09-27 18:22:00+00:00
[2024-09-27T18:28:19.327+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:20:00+00:00: scheduled__2023-09-27T18:20:00+00:00, state:running, queued_at: 2024-09-27 16:27:47.186373+00:00. externally triggered: False> successful
[2024-09-27T18:28:19.327+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:20:00+00:00, run_id=scheduled__2023-09-27T18:20:00+00:00, run_start_date=2024-09-27 16:27:47.203485+00:00, run_end_date=2024-09-27 16:28:19.327715+00:00, run_duration=32.12423, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:20:00+00:00, data_interval_end=2023-09-27 18:21:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:19.332+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:21:00+00:00, run_after=2023-09-27 18:22:00+00:00
[2024-09-27T18:28:19.345+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
[2024-09-27T18:28:19.346+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:19.346+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:19.347+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:21:00+00:00 [scheduled]>
[2024-09-27T18:28:19.349+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:21:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:19.350+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:19.350+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:19.351+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:19.351+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:19.354+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:20.293+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:20.378+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:21.218+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:22.156+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:22.241+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:23.232+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:23.232+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:23.238+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:22.277371+00:00, run_end_date=2024-09-27 16:28:22.842177+00:00, run_duration=0.564806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1654, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:19.348051+00:00, queued_by_job_id=1585, pid=329669
[2024-09-27T18:28:23.239+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:20.414263+00:00, run_end_date=2024-09-27 16:28:20.793693+00:00, run_duration=0.37943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1653, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:19.348051+00:00, queued_by_job_id=1585, pid=329662
[2024-09-27T18:28:23.270+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:22:00+00:00, run_after=2023-09-27 18:23:00+00:00
[2024-09-27T18:28:23.299+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:21:00+00:00: scheduled__2023-09-27T18:21:00+00:00, state:running, queued_at: 2024-09-27 16:27:54.468372+00:00. externally triggered: False> successful
[2024-09-27T18:28:23.299+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:21:00+00:00, run_id=scheduled__2023-09-27T18:21:00+00:00, run_start_date=2024-09-27 16:27:54.486363+00:00, run_end_date=2024-09-27 16:28:23.299836+00:00, run_duration=28.813473, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:21:00+00:00, data_interval_end=2023-09-27 18:22:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:23.304+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:22:00+00:00, run_after=2023-09-27 18:23:00+00:00
[2024-09-27T18:28:23.317+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
[2024-09-27T18:28:23.318+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:23.318+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:22:00+00:00 [scheduled]>
[2024-09-27T18:28:23.320+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:22:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:23.321+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:23.321+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:23.325+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:24.262+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:24.347+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:25.367+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:25.373+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:24.383595+00:00, run_end_date=2024-09-27 16:28:24.982632+00:00, run_duration=0.599037, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1655, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:23.319221+00:00, queued_by_job_id=1585, pid=329676
[2024-09-27T18:28:25.630+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:24:00+00:00, run_after=2023-09-27 18:25:00+00:00
[2024-09-27T18:28:25.665+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:22:00+00:00: scheduled__2023-09-27T18:22:00+00:00, state:running, queued_at: 2024-09-27 16:28:03.340151+00:00. externally triggered: False> successful
[2024-09-27T18:28:25.666+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:22:00+00:00, run_id=scheduled__2023-09-27T18:22:00+00:00, run_start_date=2024-09-27 16:28:03.354605+00:00, run_end_date=2024-09-27 16:28:25.666145+00:00, run_duration=22.31154, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:22:00+00:00, data_interval_end=2023-09-27 18:23:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:25.670+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:23:00+00:00, run_after=2023-09-27 18:24:00+00:00
[2024-09-27T18:28:25.679+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:25.679+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:25.679+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:25.680+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:25.680+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:25.680+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:25.683+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:26.620+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:26.705+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:27.649+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:27.653+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:26.741667+00:00, run_end_date=2024-09-27 16:28:27.253501+00:00, run_duration=0.511834, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1656, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:25.679965+00:00, queued_by_job_id=1585, pid=329697
[2024-09-27T18:28:27.679+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:24:00+00:00, run_after=2023-09-27 18:25:00+00:00
[2024-09-27T18:28:27.707+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:27.707+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:27.708+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:27.710+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:27.710+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:27.710+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:27.714+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:28.634+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:28.720+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:29.809+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:29.812+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:28.755770+00:00, run_end_date=2024-09-27 16:28:29.396496+00:00, run_duration=0.640726, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1657, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:27.708848+00:00, queued_by_job_id=1585, pid=329708
[2024-09-27T18:28:29.841+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:25:00+00:00, run_after=2023-09-27 18:26:00+00:00
[2024-09-27T18:28:29.871+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:29.871+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:29.871+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:29.872+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:29.873+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:24:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:29.873+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:29.873+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:29.873+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:29.873+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:29.877+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:30.785+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:30.870+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:32.268+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:33.208+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:33.296+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:34.706+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:34.706+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:34.709+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:30.905294+00:00, run_end_date=2024-09-27 16:28:31.855830+00:00, run_duration=0.950536, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1658, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:29.872392+00:00, queued_by_job_id=1585, pid=329723
[2024-09-27T18:28:34.709+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:33.345646+00:00, run_end_date=2024-09-27 16:28:34.311944+00:00, run_duration=0.966298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1659, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:29.872392+00:00, queued_by_job_id=1585, pid=329730
[2024-09-27T18:28:34.747+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:26:00+00:00, run_after=2023-09-27 18:27:00+00:00
[2024-09-27T18:28:34.774+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:34.775+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:34.775+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:34.775+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:28:34.775+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:23:00+00:00 [scheduled]>
[2024-09-27T18:28:34.776+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:25:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:24:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:34.777+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:34.777+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:34.777+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:34.777+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:34.777+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:34.777+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:34.781+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:35.721+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:35.806+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:37.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:38.116+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:38.201+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:39.315+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:40.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:40.312+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:41.761+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:41.762+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:41.762+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:41.769+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:38.232812+00:00, run_end_date=2024-09-27 16:28:38.918952+00:00, run_duration=0.68614, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1661, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:34.776033+00:00, queued_by_job_id=1585, pid=329752
[2024-09-27T18:28:41.770+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:40.348487+00:00, run_end_date=2024-09-27 16:28:41.376418+00:00, run_duration=1.027931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1662, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:34.776033+00:00, queued_by_job_id=1585, pid=329767
[2024-09-27T18:28:41.770+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:35.843220+00:00, run_end_date=2024-09-27 16:28:36.769574+00:00, run_duration=0.926354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1660, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:34.776033+00:00, queued_by_job_id=1585, pid=329745
[2024-09-27T18:28:41.819+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:27:00+00:00, run_after=2023-09-27 18:28:00+00:00
[2024-09-27T18:28:41.866+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:23:00+00:00: scheduled__2023-09-27T18:23:00+00:00, state:running, queued_at: 2024-09-27 16:28:25.623848+00:00. externally triggered: False> successful
[2024-09-27T18:28:41.866+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:23:00+00:00, run_id=scheduled__2023-09-27T18:23:00+00:00, run_start_date=2024-09-27 16:28:25.642489+00:00, run_end_date=2024-09-27 16:28:41.866636+00:00, run_duration=16.224147, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:23:00+00:00, data_interval_end=2023-09-27 18:24:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:41.871+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:24:00+00:00, run_after=2023-09-27 18:25:00+00:00
[2024-09-27T18:28:41.880+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
[2024-09-27T18:28:41.880+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:41.880+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:41.880+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:28:41.880+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
[2024-09-27T18:28:41.882+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:25:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:41.882+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:41.882+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:41.882+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:41.882+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:41.882+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:41.883+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:41.885+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:42.819+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:42.904+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:44.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:45.173+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:45.260+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:46.545+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:47.482+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:47.567+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:49.162+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:49.162+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:49.163+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:49.169+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:47.603577+00:00, run_end_date=2024-09-27 16:28:48.762616+00:00, run_duration=1.159039, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1665, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:41.881351+00:00, queued_by_job_id=1585, pid=329796
[2024-09-27T18:28:49.170+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:45.296837+00:00, run_end_date=2024-09-27 16:28:46.155628+00:00, run_duration=0.858791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1664, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:41.881351+00:00, queued_by_job_id=1585, pid=329789
[2024-09-27T18:28:49.170+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:42.940260+00:00, run_end_date=2024-09-27 16:28:43.834480+00:00, run_duration=0.89422, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1663, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:41.881351+00:00, queued_by_job_id=1585, pid=329774
[2024-09-27T18:28:49.217+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:25:00+00:00, run_after=2023-09-27 18:26:00+00:00
[2024-09-27T18:28:49.263+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
[2024-09-27T18:28:49.263+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:49.264+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:49.264+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:28:49.264+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:24:00+00:00 [scheduled]>
[2024-09-27T18:28:49.267+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:25:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:49.268+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:28:49.268+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:49.269+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:49.269+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:49.269+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:49.270+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:49.274+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:50.219+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:50.306+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:51.279+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:52.193+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:52.277+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:53.196+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:54.108+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:54.193+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:55.107+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:55.108+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:55.108+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:55.114+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:54.230079+00:00, run_end_date=2024-09-27 16:28:54.739745+00:00, run_duration=0.509666, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1668, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:49.266025+00:00, queued_by_job_id=1585, pid=329827
[2024-09-27T18:28:55.115+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:52.313940+00:00, run_end_date=2024-09-27 16:28:52.804597+00:00, run_duration=0.490657, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1667, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:49.266025+00:00, queued_by_job_id=1585, pid=329819
[2024-09-27T18:28:55.116+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:50.343037+00:00, run_end_date=2024-09-27 16:28:50.899601+00:00, run_duration=0.556564, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1666, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:28:49.266025+00:00, queued_by_job_id=1585, pid=329812
[2024-09-27T18:28:55.172+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:26:00+00:00, run_after=2023-09-27 18:27:00+00:00
[2024-09-27T18:28:55.202+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:24:00+00:00: scheduled__2023-09-27T18:24:00+00:00, state:running, queued_at: 2024-09-27 16:28:29.835188+00:00. externally triggered: False> successful
[2024-09-27T18:28:55.203+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:24:00+00:00, run_id=scheduled__2023-09-27T18:24:00+00:00, run_start_date=2024-09-27 16:28:29.849301+00:00, run_end_date=2024-09-27 16:28:55.203539+00:00, run_duration=25.354238, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:24:00+00:00, data_interval_end=2023-09-27 18:25:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:55.208+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:25:00+00:00, run_after=2023-09-27 18:26:00+00:00
[2024-09-27T18:28:55.221+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
[2024-09-27T18:28:55.222+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:55.222+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:55.222+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:25:00+00:00 [scheduled]>
[2024-09-27T18:28:55.225+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:25:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:55.226+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:28:55.226+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:55.226+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:55.227+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:55.230+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:56.172+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:56.257+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:57.296+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:58.213+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:28:58.299+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:28:59.212+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:59.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:28:59.218+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:58.335250+00:00, run_end_date=2024-09-27 16:28:58.853528+00:00, run_duration=0.518278, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1670, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:55.223880+00:00, queued_by_job_id=1585, pid=329842
[2024-09-27T18:28:59.219+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:28:56.292639+00:00, run_end_date=2024-09-27 16:28:56.947424+00:00, run_duration=0.654785, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1669, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:28:55.223880+00:00, queued_by_job_id=1585, pid=329834
[2024-09-27T18:28:59.475+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:28:00+00:00, run_after=2023-09-27 18:29:00+00:00
[2024-09-27T18:28:59.513+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:25:00+00:00: scheduled__2023-09-27T18:25:00+00:00, state:running, queued_at: 2024-09-27 16:28:34.744842+00:00. externally triggered: False> successful
[2024-09-27T18:28:59.514+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:25:00+00:00, run_id=scheduled__2023-09-27T18:25:00+00:00, run_start_date=2024-09-27 16:28:34.754010+00:00, run_end_date=2024-09-27 16:28:59.514527+00:00, run_duration=24.760517, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:25:00+00:00, data_interval_end=2023-09-27 18:26:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:28:59.519+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:26:00+00:00, run_after=2023-09-27 18:27:00+00:00
[2024-09-27T18:28:59.528+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
[2024-09-27T18:28:59.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:28:59.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:28:59.529+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:26:00+00:00 [scheduled]>
[2024-09-27T18:28:59.530+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:27:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:26:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:28:59.530+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:28:59.530+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:59.531+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:28:59.531+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:28:59.533+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:00.446+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:00.531+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:01.412+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:02.354+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:02.441+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:03.432+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:03.433+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:03.439+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:00.566765+00:00, run_end_date=2024-09-27 16:29:01.056712+00:00, run_duration=0.489947, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1671, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:28:59.529771+00:00, queued_by_job_id=1585, pid=329850
[2024-09-27T18:29:03.440+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:02.478013+00:00, run_end_date=2024-09-27 16:29:03.043563+00:00, run_duration=0.56555, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1672, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:28:59.529771+00:00, queued_by_job_id=1585, pid=329857
[2024-09-27T18:29:03.485+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:27:00+00:00, run_after=2023-09-27 18:28:00+00:00
[2024-09-27T18:29:03.511+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:26:00+00:00: scheduled__2023-09-27T18:26:00+00:00, state:running, queued_at: 2024-09-27 16:28:41.813143+00:00. externally triggered: False> successful
[2024-09-27T18:29:03.511+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:26:00+00:00, run_id=scheduled__2023-09-27T18:26:00+00:00, run_start_date=2024-09-27 16:28:41.831350+00:00, run_end_date=2024-09-27 16:29:03.511826+00:00, run_duration=21.680476, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:26:00+00:00, data_interval_end=2023-09-27 18:27:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:03.516+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:27:00+00:00, run_after=2023-09-27 18:28:00+00:00
[2024-09-27T18:29:03.529+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:03.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:03.530+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:03.532+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:27:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:03.532+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:03.533+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:03.537+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:04.473+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:04.558+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:05.483+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:05.489+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:04.595026+00:00, run_end_date=2024-09-27 16:29:05.118164+00:00, run_duration=0.523138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1673, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:03.530961+00:00, queued_by_job_id=1585, pid=329865
[2024-09-27T18:29:05.516+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:28:00+00:00, run_after=2023-09-27 18:29:00+00:00
[2024-09-27T18:29:05.556+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:05.557+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:05.557+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:05.559+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:27:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:05.560+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:05.560+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:05.564+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:06.500+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:06.585+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:07.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:07.506+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:06.620930+00:00, run_end_date=2024-09-27 16:29:07.074138+00:00, run_duration=0.453208, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1674, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:05.558271+00:00, queued_by_job_id=1585, pid=329872
[2024-09-27T18:29:07.539+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:29:00+00:00, run_after=2023-09-27 18:30:00+00:00
[2024-09-27T18:29:07.591+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:07.591+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:07.592+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:07.592+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:27:00+00:00 [scheduled]>
[2024-09-27T18:29:07.595+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:28:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:27:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:07.595+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:07.596+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:07.596+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:07.596+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:07.600+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:08.539+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:08.624+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:09.621+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:10.555+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:10.640+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:11.587+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:11.588+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:11.594+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:08.661507+00:00, run_end_date=2024-09-27 16:29:09.228315+00:00, run_duration=0.566808, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1675, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:07.593511+00:00, queued_by_job_id=1585, pid=329879
[2024-09-27T18:29:11.594+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:10.677212+00:00, run_end_date=2024-09-27 16:29:11.174750+00:00, run_duration=0.497538, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1676, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:07.593511+00:00, queued_by_job_id=1585, pid=329886
[2024-09-27T18:29:11.652+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:30:00+00:00, run_after=2023-09-27 18:31:00+00:00
[2024-09-27T18:29:11.674+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:27:00+00:00: scheduled__2023-09-27T18:27:00+00:00, state:running, queued_at: 2024-09-27 16:28:59.468738+00:00. externally triggered: False> successful
[2024-09-27T18:29:11.674+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:27:00+00:00, run_id=scheduled__2023-09-27T18:27:00+00:00, run_start_date=2024-09-27 16:28:59.487187+00:00, run_end_date=2024-09-27 16:29:11.674364+00:00, run_duration=12.187177, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:27:00+00:00, data_interval_end=2023-09-27 18:28:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:11.676+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:28:00+00:00, run_after=2023-09-27 18:29:00+00:00
[2024-09-27T18:29:11.683+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:11.683+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:11.683+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:11.684+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:11.685+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:28:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:11.685+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:11.685+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:11.685+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:11.685+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:11.688+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:12.621+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:12.705+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:13.545+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:14.476+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:14.560+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:15.640+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:15.641+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:15.647+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:14.595976+00:00, run_end_date=2024-09-27 16:29:15.225093+00:00, run_duration=0.629117, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1678, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:11.684499+00:00, queued_by_job_id=1585, pid=329902
[2024-09-27T18:29:15.647+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:12.740870+00:00, run_end_date=2024-09-27 16:29:13.148960+00:00, run_duration=0.40809, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1677, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:11.684499+00:00, queued_by_job_id=1585, pid=329893
[2024-09-27T18:29:15.675+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:29:00+00:00, run_after=2023-09-27 18:30:00+00:00
[2024-09-27T18:29:15.721+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:15.722+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:15.722+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:15.723+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:15.725+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:28:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:15.726+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:15.726+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:15.727+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:15.727+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:15.731+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:16.664+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:16.749+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:18.031+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:18.958+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:19.043+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:20.444+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:20.445+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:20.450+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:19.078958+00:00, run_end_date=2024-09-27 16:29:20.084378+00:00, run_duration=1.00542, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1680, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:15.724298+00:00, queued_by_job_id=1585, pid=329927
[2024-09-27T18:29:20.451+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:16.785037+00:00, run_end_date=2024-09-27 16:29:17.627307+00:00, run_duration=0.84227, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1679, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:15.724298+00:00, queued_by_job_id=1585, pid=329919
[2024-09-27T18:29:20.495+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:30:00+00:00, run_after=2023-09-27 18:31:00+00:00
[2024-09-27T18:29:20.534+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:20.535+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:20.535+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:20.535+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:28:00+00:00 [scheduled]>
[2024-09-27T18:29:20.538+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:28:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:20.538+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:20.539+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:20.539+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:20.540+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:20.543+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:21.480+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:21.565+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:22.963+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:23.884+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:23.969+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:25.406+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:25.407+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:25.412+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:24.005955+00:00, run_end_date=2024-09-27 16:29:24.999931+00:00, run_duration=0.993976, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1682, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:20.536813+00:00, queued_by_job_id=1585, pid=329950
[2024-09-27T18:29:25.413+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:21.600726+00:00, run_end_date=2024-09-27 16:29:22.542476+00:00, run_duration=0.94175, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1681, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:20.536813+00:00, queued_by_job_id=1585, pid=329943
[2024-09-27T18:29:25.439+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:31:00+00:00, run_after=2023-09-27 18:32:00+00:00
[2024-09-27T18:29:25.464+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:28:00+00:00: scheduled__2023-09-27T18:28:00+00:00, state:running, queued_at: 2024-09-27 16:29:07.532997+00:00. externally triggered: False> successful
[2024-09-27T18:29:25.464+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:28:00+00:00, run_id=scheduled__2023-09-27T18:28:00+00:00, run_start_date=2024-09-27 16:29:07.556248+00:00, run_end_date=2024-09-27 16:29:25.464654+00:00, run_duration=17.908406, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:28:00+00:00, data_interval_end=2023-09-27 18:29:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:25.466+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:29:00+00:00, run_after=2023-09-27 18:30:00+00:00
[2024-09-27T18:29:25.473+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
[2024-09-27T18:29:25.473+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:25.473+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:25.473+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:29:00+00:00 [scheduled]>
[2024-09-27T18:29:25.475+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:30:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:29:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:25.475+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:25.475+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:25.475+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:25.475+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:25.478+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:26.422+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:26.507+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:27.866+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:28.800+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:28.885+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:30.145+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:30.145+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:30.150+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:26.542916+00:00, run_end_date=2024-09-27 16:29:27.458415+00:00, run_duration=0.915499, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1683, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:25.474326+00:00, queued_by_job_id=1585, pid=329965
[2024-09-27T18:29:30.151+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:28.921460+00:00, run_end_date=2024-09-27 16:29:29.714388+00:00, run_duration=0.792928, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1684, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:25.474326+00:00, queued_by_job_id=1585, pid=329972
[2024-09-27T18:29:30.304+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:32:00+00:00, run_after=2023-09-27 18:33:00+00:00
[2024-09-27T18:29:30.346+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:29:00+00:00: scheduled__2023-09-27T18:29:00+00:00, state:running, queued_at: 2024-09-27 16:29:11.645657+00:00. externally triggered: False> successful
[2024-09-27T18:29:30.346+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:29:00+00:00, run_id=scheduled__2023-09-27T18:29:00+00:00, run_start_date=2024-09-27 16:29:11.659919+00:00, run_end_date=2024-09-27 16:29:30.346754+00:00, run_duration=18.686835, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:29:00+00:00, data_interval_end=2023-09-27 18:30:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:30.351+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:30:00+00:00, run_after=2023-09-27 18:31:00+00:00
[2024-09-27T18:29:30.365+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:30.365+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:30.366+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:30.366+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:30.369+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:31:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:30.369+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:30.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:30.370+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:30.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:30.374+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:31.326+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:31.413+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:32.518+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:33.463+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:33.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:34.950+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:34.950+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:34.956+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:33.583052+00:00, run_end_date=2024-09-27 16:29:34.521882+00:00, run_duration=0.93883, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1686, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:30.367426+00:00, queued_by_job_id=1585, pid=330009
[2024-09-27T18:29:34.957+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:31.444783+00:00, run_end_date=2024-09-27 16:29:32.065148+00:00, run_duration=0.620365, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1685, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:30.367426+00:00, queued_by_job_id=1585, pid=330002
[2024-09-27T18:29:34.987+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:31:00+00:00, run_after=2023-09-27 18:32:00+00:00
[2024-09-27T18:29:35.034+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:35.035+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:35.035+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:35.035+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:35.038+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:31:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:35.039+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:35.039+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:35.039+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:35.040+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:35.043+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:35.988+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:36.074+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:37.253+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:38.193+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:38.277+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:39.557+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:39.557+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:39.563+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:38.313678+00:00, run_end_date=2024-09-27 16:29:39.131339+00:00, run_duration=0.817661, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1688, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:35.036900+00:00, queued_by_job_id=1585, pid=330031
[2024-09-27T18:29:39.564+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:36.110021+00:00, run_end_date=2024-09-27 16:29:36.877864+00:00, run_duration=0.767843, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1687, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:35.036900+00:00, queued_by_job_id=1585, pid=330024
[2024-09-27T18:29:39.611+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:32:00+00:00, run_after=2023-09-27 18:33:00+00:00
[2024-09-27T18:29:39.645+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:39.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:39.646+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:39.646+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:30:00+00:00 [scheduled]>
[2024-09-27T18:29:39.647+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:31:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:39.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:39.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:39.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:39.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:39.651+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:40.584+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:40.670+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:41.996+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:42.933+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:43.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:44.444+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:44.444+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:44.450+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:43.053365+00:00, run_end_date=2024-09-27 16:29:44.045821+00:00, run_duration=0.992456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1690, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:39.646539+00:00, queued_by_job_id=1585, pid=330053
[2024-09-27T18:29:44.451+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:40.706950+00:00, run_end_date=2024-09-27 16:29:41.587021+00:00, run_duration=0.880071, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1689, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:39.646539+00:00, queued_by_job_id=1585, pid=330038
[2024-09-27T18:29:44.484+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:33:00+00:00, run_after=2023-09-27 18:34:00+00:00
[2024-09-27T18:29:44.516+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:30:00+00:00: scheduled__2023-09-27T18:30:00+00:00, state:running, queued_at: 2024-09-27 16:29:25.436907+00:00. externally triggered: False> successful
[2024-09-27T18:29:44.516+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:30:00+00:00, run_id=scheduled__2023-09-27T18:30:00+00:00, run_start_date=2024-09-27 16:29:25.451149+00:00, run_end_date=2024-09-27 16:29:44.516845+00:00, run_duration=19.065696, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:30:00+00:00, data_interval_end=2023-09-27 18:31:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:44.518+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:31:00+00:00, run_after=2023-09-27 18:32:00+00:00
[2024-09-27T18:29:44.531+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
[2024-09-27T18:29:44.531+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:44.532+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:44.532+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:31:00+00:00 [scheduled]>
[2024-09-27T18:29:44.534+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:32:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:31:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:44.535+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:44.535+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:44.536+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:44.536+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:44.540+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:45.478+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:45.562+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:46.474+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:47.386+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:47.471+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:48.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:48.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:48.352+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:47.508655+00:00, run_end_date=2024-09-27 16:29:47.961623+00:00, run_duration=0.452968, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1692, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:44.533330+00:00, queued_by_job_id=1585, pid=330075
[2024-09-27T18:29:48.353+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:45.598822+00:00, run_end_date=2024-09-27 16:29:46.082261+00:00, run_duration=0.483439, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1691, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:44.533330+00:00, queued_by_job_id=1585, pid=330060
[2024-09-27T18:29:48.403+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:32:00+00:00, run_after=2023-09-27 18:33:00+00:00
[2024-09-27T18:29:48.429+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:31:00+00:00: scheduled__2023-09-27T18:31:00+00:00, state:running, queued_at: 2024-09-27 16:29:30.298290+00:00. externally triggered: False> successful
[2024-09-27T18:29:48.429+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:31:00+00:00, run_id=scheduled__2023-09-27T18:31:00+00:00, run_start_date=2024-09-27 16:29:30.316480+00:00, run_end_date=2024-09-27 16:29:48.429703+00:00, run_duration=18.113223, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:31:00+00:00, data_interval_end=2023-09-27 18:32:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:48.434+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:32:00+00:00, run_after=2023-09-27 18:33:00+00:00
[2024-09-27T18:29:48.446+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:48.447+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:48.447+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:48.450+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:32:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:48.450+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:48.451+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:48.454+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:49.367+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:49.458+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:50.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:50.391+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:49.494045+00:00, run_end_date=2024-09-27 16:29:50.015148+00:00, run_duration=0.521103, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1693, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:48.448758+00:00, queued_by_job_id=1585, pid=330083
[2024-09-27T18:29:50.418+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:33:00+00:00, run_after=2023-09-27 18:34:00+00:00
[2024-09-27T18:29:50.457+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:50.458+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:50.458+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:50.460+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:32:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:50.461+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:29:50.461+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:50.465+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:51.399+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:51.485+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:52.565+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:52.570+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:51.521011+00:00, run_end_date=2024-09-27 16:29:52.148325+00:00, run_duration=0.627314, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1694, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:29:50.459522+00:00, queued_by_job_id=1585, pid=330090
[2024-09-27T18:29:52.603+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:34:00+00:00, run_after=2023-09-27 18:35:00+00:00
[2024-09-27T18:29:52.652+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:52.652+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:52.652+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:52.652+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:32:00+00:00 [scheduled]>
[2024-09-27T18:29:52.653+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:33:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:32:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:52.654+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:52.654+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:52.654+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:29:52.654+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:52.657+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:53.571+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:53.656+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:54.657+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:55.599+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:55.684+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:57.363+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:57.363+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:29:57.369+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:53.693553+00:00, run_end_date=2024-09-27 16:29:54.251939+00:00, run_duration=0.558386, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1695, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:52.653099+00:00, queued_by_job_id=1585, pid=330105
[2024-09-27T18:29:57.370+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:55.721389+00:00, run_end_date=2024-09-27 16:29:56.943636+00:00, run_duration=1.222247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1696, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:29:52.653099+00:00, queued_by_job_id=1585, pid=330113
[2024-09-27T18:29:57.429+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:35:00+00:00, run_after=2023-09-27 18:36:00+00:00
[2024-09-27T18:29:57.451+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:32:00+00:00: scheduled__2023-09-27T18:32:00+00:00, state:running, queued_at: 2024-09-27 16:29:44.478507+00:00. externally triggered: False> successful
[2024-09-27T18:29:57.451+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:32:00+00:00, run_id=scheduled__2023-09-27T18:32:00+00:00, run_start_date=2024-09-27 16:29:44.502795+00:00, run_end_date=2024-09-27 16:29:57.451790+00:00, run_duration=12.948995, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:32:00+00:00, data_interval_end=2023-09-27 18:33:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:29:57.453+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:33:00+00:00, run_after=2023-09-27 18:34:00+00:00
[2024-09-27T18:29:57.461+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:29:57.461+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:29:57.461+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:29:57.461+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:29:57.462+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:34:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:33:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:29:57.463+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:29:57.463+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:57.463+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:29:57.463+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:57.466+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:29:58.403+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:29:58.489+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:29:59.812+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:00.754+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:00.839+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:02.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:02.281+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:02.287+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:29:58.524897+00:00, run_end_date=2024-09-27 16:29:59.391226+00:00, run_duration=0.866329, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1697, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:29:57.462175+00:00, queued_by_job_id=1585, pid=330129
[2024-09-27T18:30:02.288+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:00.875949+00:00, run_end_date=2024-09-27 16:30:01.857415+00:00, run_duration=0.981466, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1698, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:29:57.462175+00:00, queued_by_job_id=1585, pid=330136
[2024-09-27T18:30:02.430+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:36:00+00:00, run_after=2023-09-27 18:37:00+00:00
[2024-09-27T18:30:02.462+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:30:02.462+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:02.462+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:02.462+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:30:02.462+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:30:02.464+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:35:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:34:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:33:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:02.464+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:02.464+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:02.464+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:02.464+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:02.465+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:02.465+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:02.468+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:03.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:03.489+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:05.015+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:05.951+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:06.035+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:07.479+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:08.417+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:08.502+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:09.541+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:09.542+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:09.542+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:09.548+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:06.072502+00:00, run_end_date=2024-09-27 16:30:07.078327+00:00, run_duration=1.005825, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1700, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:02.463406+00:00, queued_by_job_id=1585, pid=330163
[2024-09-27T18:30:09.549+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:03.525714+00:00, run_end_date=2024-09-27 16:30:04.613397+00:00, run_duration=1.087683, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1699, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:02.463406+00:00, queued_by_job_id=1585, pid=330154
[2024-09-27T18:30:09.550+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:08.538374+00:00, run_end_date=2024-09-27 16:30:09.143719+00:00, run_duration=0.605345, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1701, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:02.463406+00:00, queued_by_job_id=1585, pid=330178
[2024-09-27T18:30:09.603+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:37:00+00:00, run_after=2023-09-27 18:38:00+00:00
[2024-09-27T18:30:09.635+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:30:09.636+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:09.636+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:09.636+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:30:09.636+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:30:09.636+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:33:00+00:00 [scheduled]>
[2024-09-27T18:30:09.638+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:35:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:34:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:33:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:09.638+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:09.638+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:09.638+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:09.638+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:09.638+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:09.639+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:09.639+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:09.639+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:09.642+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:10.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:10.661+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:12.107+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:13.047+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:13.133+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:14.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:15.029+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:15.113+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:16.393+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:17.310+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:17.395+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:18.831+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:18.832+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:18.832+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:18.832+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:18.839+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:15.150766+00:00, run_end_date=2024-09-27 16:30:15.986190+00:00, run_duration=0.835424, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1704, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:09.637324+00:00, queued_by_job_id=1585, pid=330209
[2024-09-27T18:30:18.840+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:10.698823+00:00, run_end_date=2024-09-27 16:30:11.686665+00:00, run_duration=0.987842, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1702, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:09.637324+00:00, queued_by_job_id=1585, pid=330185
[2024-09-27T18:30:18.841+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:13.168994+00:00, run_end_date=2024-09-27 16:30:13.698516+00:00, run_duration=0.529522, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1703, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:09.637324+00:00, queued_by_job_id=1585, pid=330201
[2024-09-27T18:30:18.841+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:17.434196+00:00, run_end_date=2024-09-27 16:30:18.442291+00:00, run_duration=1.008095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1705, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:09.637324+00:00, queued_by_job_id=1585, pid=330220
[2024-09-27T18:30:18.893+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:38:00+00:00, run_after=2023-09-27 18:39:00+00:00
[2024-09-27T18:30:18.919+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:33:00+00:00: scheduled__2023-09-27T18:33:00+00:00, state:running, queued_at: 2024-09-27 16:29:52.596874+00:00. externally triggered: False> successful
[2024-09-27T18:30:18.920+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:33:00+00:00, run_id=scheduled__2023-09-27T18:33:00+00:00, run_start_date=2024-09-27 16:29:52.619749+00:00, run_end_date=2024-09-27 16:30:18.920174+00:00, run_duration=26.300425, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:33:00+00:00, data_interval_end=2023-09-27 18:34:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:18.922+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:34:00+00:00, run_after=2023-09-27 18:35:00+00:00
[2024-09-27T18:30:18.929+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
[2024-09-27T18:30:18.929+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:18.929+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:18.929+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:30:18.929+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:30:18.930+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:34:00+00:00 [scheduled]>
[2024-09-27T18:30:18.931+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:37:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:35:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:34:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:18.931+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:18.931+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:18.932+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:18.932+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:18.932+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:18.932+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:18.932+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:18.932+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:18.935+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:19.867+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:19.951+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:21.106+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:22.041+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:22.126+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:23.173+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:24.109+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:24.194+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:25.187+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:26.123+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:26.207+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:27.243+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:27.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:27.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:27.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:27.251+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:26.244053+00:00, run_end_date=2024-09-27 16:30:26.864873+00:00, run_duration=0.62082, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1709, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:18.930569+00:00, queued_by_job_id=1585, pid=330266
[2024-09-27T18:30:27.252+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:22.162938+00:00, run_end_date=2024-09-27 16:30:22.745425+00:00, run_duration=0.582487, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1707, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:18.930569+00:00, queued_by_job_id=1585, pid=330244
[2024-09-27T18:30:27.252+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:24.231164+00:00, run_end_date=2024-09-27 16:30:24.825893+00:00, run_duration=0.594729, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1708, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:18.930569+00:00, queued_by_job_id=1585, pid=330259
[2024-09-27T18:30:27.253+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:19.987041+00:00, run_end_date=2024-09-27 16:30:20.696446+00:00, run_duration=0.709405, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1706, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:18.930569+00:00, queued_by_job_id=1585, pid=330237
[2024-09-27T18:30:27.299+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:35:00+00:00, run_after=2023-09-27 18:36:00+00:00
[2024-09-27T18:30:27.338+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:34:00+00:00: scheduled__2023-09-27T18:34:00+00:00, state:running, queued_at: 2024-09-27 16:29:57.423193+00:00. externally triggered: False> successful
[2024-09-27T18:30:27.338+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:34:00+00:00, run_id=scheduled__2023-09-27T18:34:00+00:00, run_start_date=2024-09-27 16:29:57.437787+00:00, run_end_date=2024-09-27 16:30:27.338619+00:00, run_duration=29.900832, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:34:00+00:00, data_interval_end=2023-09-27 18:35:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:27.343+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:35:00+00:00, run_after=2023-09-27 18:36:00+00:00
[2024-09-27T18:30:27.357+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
[2024-09-27T18:30:27.357+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:27.358+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:27.358+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:30:27.358+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:35:00+00:00 [scheduled]>
[2024-09-27T18:30:27.361+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:37:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:35:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:27.362+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:27.362+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:27.363+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:27.363+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:27.364+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:27.364+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:27.367+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:28.298+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:28.383+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:29.466+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:30.446+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:30.530+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:31.409+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:32.313+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:32.399+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:33.390+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:33.391+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:33.391+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:33.398+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:30.568009+00:00, run_end_date=2024-09-27 16:30:31.019315+00:00, run_duration=0.451306, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1711, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:27.360098+00:00, queued_by_job_id=1585, pid=330303
[2024-09-27T18:30:33.398+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:32.437555+00:00, run_end_date=2024-09-27 16:30:32.992076+00:00, run_duration=0.554521, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:27.360098+00:00, queued_by_job_id=1585, pid=330310
[2024-09-27T18:30:33.399+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:28.419734+00:00, run_end_date=2024-09-27 16:30:29.057844+00:00, run_duration=0.63811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1710, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:27.360098+00:00, queued_by_job_id=1585, pid=330274
[2024-09-27T18:30:33.559+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:39:00+00:00, run_after=2023-09-27 18:40:00+00:00
[2024-09-27T18:30:33.604+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:35:00+00:00: scheduled__2023-09-27T18:35:00+00:00, state:running, queued_at: 2024-09-27 16:30:02.424838+00:00. externally triggered: False> successful
[2024-09-27T18:30:33.605+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:35:00+00:00, run_id=scheduled__2023-09-27T18:35:00+00:00, run_start_date=2024-09-27 16:30:02.438386+00:00, run_end_date=2024-09-27 16:30:33.605491+00:00, run_duration=31.167105, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:35:00+00:00, data_interval_end=2023-09-27 18:36:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:33.610+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:36:00+00:00, run_after=2023-09-27 18:37:00+00:00
[2024-09-27T18:30:33.619+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
[2024-09-27T18:30:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:30:33.619+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:36:00+00:00 [scheduled]>
[2024-09-27T18:30:33.621+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:37:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:36:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:33.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:33.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:33.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:33.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:33.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:33.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:33.625+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:34.564+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:34.650+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:36.017+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:36.960+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:37.044+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:38.527+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:39.468+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:39.552+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:42.197+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:42.198+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:42.198+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:42.204+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:34.686548+00:00, run_end_date=2024-09-27 16:30:35.643280+00:00, run_duration=0.956732, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1713, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:33.620240+00:00, queued_by_job_id=1585, pid=330318
[2024-09-27T18:30:42.205+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:39.587805+00:00, run_end_date=2024-09-27 16:30:41.791110+00:00, run_duration=2.203305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:33.620240+00:00, queued_by_job_id=1585, pid=330340
[2024-09-27T18:30:42.206+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:37.080422+00:00, run_end_date=2024-09-27 16:30:38.102107+00:00, run_duration=1.021685, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1714, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:33.620240+00:00, queued_by_job_id=1585, pid=330333
[2024-09-27T18:30:42.251+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:37:00+00:00, run_after=2023-09-27 18:38:00+00:00
[2024-09-27T18:30:42.284+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:36:00+00:00: scheduled__2023-09-27T18:36:00+00:00, state:running, queued_at: 2024-09-27 16:30:09.597634+00:00. externally triggered: False> successful
[2024-09-27T18:30:42.285+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:36:00+00:00, run_id=scheduled__2023-09-27T18:36:00+00:00, run_start_date=2024-09-27 16:30:09.611428+00:00, run_end_date=2024-09-27 16:30:42.285282+00:00, run_duration=32.673854, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:36:00+00:00, data_interval_end=2023-09-27 18:37:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:42.290+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:37:00+00:00, run_after=2023-09-27 18:38:00+00:00
[2024-09-27T18:30:42.297+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
[2024-09-27T18:30:42.298+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:42.298+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:42.298+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:37:00+00:00 [scheduled]>
[2024-09-27T18:30:42.299+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:42.299+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:42.299+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:42.300+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:42.300+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:42.302+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:43.236+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:43.321+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:44.683+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:45.613+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:45.698+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:47.011+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:47.012+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:47.017+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:43.357347+00:00, run_end_date=2024-09-27 16:30:44.272087+00:00, run_duration=0.91474, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1716, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:42.298851+00:00, queued_by_job_id=1585, pid=330355
[2024-09-27T18:30:47.018+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:45.734814+00:00, run_end_date=2024-09-27 16:30:46.590185+00:00, run_duration=0.855371, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1717, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:42.298851+00:00, queued_by_job_id=1585, pid=330362
[2024-09-27T18:30:47.038+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:30:47.074+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:38:00+00:00, run_after=2023-09-27 18:39:00+00:00
[2024-09-27T18:30:47.106+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:37:00+00:00: scheduled__2023-09-27T18:37:00+00:00, state:running, queued_at: 2024-09-27 16:30:18.886971+00:00. externally triggered: False> successful
[2024-09-27T18:30:47.107+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:37:00+00:00, run_id=scheduled__2023-09-27T18:37:00+00:00, run_start_date=2024-09-27 16:30:18.901236+00:00, run_end_date=2024-09-27 16:30:47.107076+00:00, run_duration=28.20584, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:37:00+00:00, data_interval_end=2023-09-27 18:38:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:47.111+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:38:00+00:00, run_after=2023-09-27 18:39:00+00:00
[2024-09-27T18:30:47.124+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
[2024-09-27T18:30:47.124+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:47.125+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
[2024-09-27T18:30:47.127+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:47.127+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:47.128+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:47.131+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:48.066+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:48.151+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:49.271+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:49.276+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:48.187854+00:00, run_end_date=2024-09-27 16:30:48.851263+00:00, run_duration=0.663409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1718, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:47.126126+00:00, queued_by_job_id=1585, pid=330377
[2024-09-27T18:30:49.319+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:39:00+00:00, run_after=2023-09-27 18:40:00+00:00
[2024-09-27T18:30:49.351+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
[2024-09-27T18:30:49.352+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:49.352+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:38:00+00:00 [scheduled]>
[2024-09-27T18:30:49.354+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:49.355+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:30:49.355+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:49.359+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:50.296+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:50.381+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:51.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:51.394+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:50.418831+00:00, run_end_date=2024-09-27 16:30:51.001310+00:00, run_duration=0.582479, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1719, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:30:49.353705+00:00, queued_by_job_id=1585, pid=330385
[2024-09-27T18:30:51.426+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:40:00+00:00, run_after=2023-09-27 18:41:00+00:00
[2024-09-27T18:30:51.446+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:38:00+00:00: scheduled__2023-09-27T18:38:00+00:00, state:running, queued_at: 2024-09-27 16:30:33.553004+00:00. externally triggered: False> successful
[2024-09-27T18:30:51.446+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:38:00+00:00, run_id=scheduled__2023-09-27T18:38:00+00:00, run_start_date=2024-09-27 16:30:33.571614+00:00, run_end_date=2024-09-27 16:30:51.446719+00:00, run_duration=17.875105, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:38:00+00:00, data_interval_end=2023-09-27 18:39:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:30:51.448+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:39:00+00:00, run_after=2023-09-27 18:40:00+00:00
[2024-09-27T18:30:51.455+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:51.456+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:51.456+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:51.457+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:51.457+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:51.457+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:51.460+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:52.396+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:52.483+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:53.659+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:53.664+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:52.519376+00:00, run_end_date=2024-09-27 16:30:53.253524+00:00, run_duration=0.734148, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1720, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:51.456501+00:00, queued_by_job_id=1585, pid=330400
[2024-09-27T18:30:53.691+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:40:00+00:00, run_after=2023-09-27 18:41:00+00:00
[2024-09-27T18:30:53.731+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:53.732+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:53.732+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:53.734+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:53.735+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:30:53.735+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:53.739+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:54.653+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:54.739+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:56.340+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:30:56.345+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:54.770459+00:00, run_end_date=2024-09-27 16:30:55.915134+00:00, run_duration=1.144675, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1721, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:30:53.733526+00:00, queued_by_job_id=1585, pid=330408
[2024-09-27T18:30:56.389+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:41:00+00:00, run_after=2023-09-27 18:42:00+00:00
[2024-09-27T18:30:56.438+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:56.439+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:30:56.439+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:30:56.440+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:30:56.442+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:30:56.443+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:30:56.443+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:56.443+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:30:56.444+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:56.448+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:57.381+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:57.468+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:30:58.793+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:30:59.751+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:30:59.835+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:01.034+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:01.035+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:01.040+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:59.871732+00:00, run_end_date=2024-09-27 16:31:00.608174+00:00, run_duration=0.736442, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1723, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:30:56.440969+00:00, queued_by_job_id=1585, pid=330431
[2024-09-27T18:31:01.040+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:30:57.504158+00:00, run_end_date=2024-09-27 16:30:58.372596+00:00, run_duration=0.868438, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1722, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:30:56.440969+00:00, queued_by_job_id=1585, pid=330423
[2024-09-27T18:31:01.083+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:42:00+00:00, run_after=2023-09-27 18:43:00+00:00
[2024-09-27T18:31:01.143+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:31:01.143+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:01.144+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:01.144+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:01.145+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:39:00+00:00 [scheduled]>
[2024-09-27T18:31:01.147+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:01.148+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:01.148+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:01.149+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:01.149+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:01.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:01.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:01.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:02.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:02.180+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:03.304+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:04.249+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:04.335+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:05.257+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:06.199+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:06.284+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:07.233+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:07.233+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:07.233+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:07.236+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:02.216400+00:00, run_end_date=2024-09-27 16:31:02.877679+00:00, run_duration=0.661279, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1724, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:01.146242+00:00, queued_by_job_id=1585, pid=330446
[2024-09-27T18:31:07.237+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:06.321280+00:00, run_end_date=2024-09-27 16:31:06.814946+00:00, run_duration=0.493666, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1726, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:01.146242+00:00, queued_by_job_id=1585, pid=330470
[2024-09-27T18:31:07.237+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:04.370870+00:00, run_end_date=2024-09-27 16:31:04.869747+00:00, run_duration=0.498877, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1725, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:01.146242+00:00, queued_by_job_id=1585, pid=330455
[2024-09-27T18:31:07.389+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:43:00+00:00, run_after=2023-09-27 18:44:00+00:00
[2024-09-27T18:31:07.412+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:39:00+00:00: scheduled__2023-09-27T18:39:00+00:00, state:running, queued_at: 2024-09-27 16:30:51.420218+00:00. externally triggered: False> successful
[2024-09-27T18:31:07.413+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:39:00+00:00, run_id=scheduled__2023-09-27T18:39:00+00:00, run_start_date=2024-09-27 16:30:51.433952+00:00, run_end_date=2024-09-27 16:31:07.413099+00:00, run_duration=15.979147, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:39:00+00:00, data_interval_end=2023-09-27 18:40:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:07.415+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:40:00+00:00, run_after=2023-09-27 18:41:00+00:00
[2024-09-27T18:31:07.422+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
[2024-09-27T18:31:07.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:07.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:07.423+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:07.423+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
[2024-09-27T18:31:07.424+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:07.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:07.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:07.425+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:07.425+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:07.425+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:07.425+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:07.428+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:08.364+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:08.450+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:09.339+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:10.274+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:10.359+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:11.417+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:12.359+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:12.444+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:13.358+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:13.358+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:13.359+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:13.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:10.397156+00:00, run_end_date=2024-09-27 16:31:11.011557+00:00, run_duration=0.614401, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1728, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:07.423684+00:00, queued_by_job_id=1585, pid=330485
[2024-09-27T18:31:13.366+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:12.480451+00:00, run_end_date=2024-09-27 16:31:12.936231+00:00, run_duration=0.45578, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1729, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:07.423684+00:00, queued_by_job_id=1585, pid=330500
[2024-09-27T18:31:13.367+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:08.487017+00:00, run_end_date=2024-09-27 16:31:08.947713+00:00, run_duration=0.460696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1727, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:07.423684+00:00, queued_by_job_id=1585, pid=330478
[2024-09-27T18:31:13.410+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:41:00+00:00, run_after=2023-09-27 18:42:00+00:00
[2024-09-27T18:31:13.453+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
[2024-09-27T18:31:13.454+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:13.454+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:13.455+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:13.455+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:40:00+00:00 [scheduled]>
[2024-09-27T18:31:13.458+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:13.458+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:13.459+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:13.459+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:13.460+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:13.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:13.460+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:13.464+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:14.396+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:14.481+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:16.009+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:16.950+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:17.036+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:18.144+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:19.083+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:19.168+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:20.602+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:20.602+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:20.603+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:20.609+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:17.072033+00:00, run_end_date=2024-09-27 16:31:17.726587+00:00, run_duration=0.654554, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1731, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:13.456606+00:00, queued_by_job_id=1585, pid=330526
[2024-09-27T18:31:20.610+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:19.204606+00:00, run_end_date=2024-09-27 16:31:20.180206+00:00, run_duration=0.9756, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1732, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:13.456606+00:00, queued_by_job_id=1585, pid=330534
[2024-09-27T18:31:20.611+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:14.517665+00:00, run_end_date=2024-09-27 16:31:15.574702+00:00, run_duration=1.057037, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1730, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:13.456606+00:00, queued_by_job_id=1585, pid=330509
[2024-09-27T18:31:20.653+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:42:00+00:00, run_after=2023-09-27 18:43:00+00:00
[2024-09-27T18:31:20.685+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:40:00+00:00: scheduled__2023-09-27T18:40:00+00:00, state:running, queued_at: 2024-09-27 16:30:56.382858+00:00. externally triggered: False> successful
[2024-09-27T18:31:20.685+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:40:00+00:00, run_id=scheduled__2023-09-27T18:40:00+00:00, run_start_date=2024-09-27 16:30:56.401679+00:00, run_end_date=2024-09-27 16:31:20.685561+00:00, run_duration=24.283882, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:40:00+00:00, data_interval_end=2023-09-27 18:41:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:20.690+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:41:00+00:00, run_after=2023-09-27 18:42:00+00:00
[2024-09-27T18:31:20.703+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
[2024-09-27T18:31:20.704+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:20.704+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:20.705+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:41:00+00:00 [scheduled]>
[2024-09-27T18:31:20.707+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:20.708+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:20.708+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:20.708+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:20.709+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:20.713+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:21.652+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:21.737+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:23.028+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:23.963+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:24.048+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:25.201+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:25.202+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:25.208+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:24.085902+00:00, run_end_date=2024-09-27 16:31:24.788401+00:00, run_duration=0.702499, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1734, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:20.705952+00:00, queued_by_job_id=1585, pid=330557
[2024-09-27T18:31:25.209+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:21.773376+00:00, run_end_date=2024-09-27 16:31:22.625919+00:00, run_duration=0.852543, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1733, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:20.705952+00:00, queued_by_job_id=1585, pid=330550
[2024-09-27T18:31:25.244+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:42:00+00:00, run_after=2023-09-27 18:43:00+00:00
[2024-09-27T18:31:25.268+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:41:00+00:00: scheduled__2023-09-27T18:41:00+00:00, state:running, queued_at: 2024-09-27 16:31:01.078123+00:00. externally triggered: False> successful
[2024-09-27T18:31:25.269+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:41:00+00:00, run_id=scheduled__2023-09-27T18:41:00+00:00, run_start_date=2024-09-27 16:31:01.100175+00:00, run_end_date=2024-09-27 16:31:25.269403+00:00, run_duration=24.169228, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:41:00+00:00, data_interval_end=2023-09-27 18:42:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:25.274+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:42:00+00:00, run_after=2023-09-27 18:43:00+00:00
[2024-09-27T18:31:25.286+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
[2024-09-27T18:31:25.287+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:25.288+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:42:00+00:00 [scheduled]>
[2024-09-27T18:31:25.290+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:42:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:25.290+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:25.291+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:25.294+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:26.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:26.312+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:27.343+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:27.348+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:26.347676+00:00, run_end_date=2024-09-27 16:31:26.938014+00:00, run_duration=0.590338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1735, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:25.288792+00:00, queued_by_job_id=1585, pid=330564
[2024-09-27T18:31:27.391+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:43:00+00:00, run_after=2023-09-27 18:44:00+00:00
[2024-09-27T18:31:27.410+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:42:00+00:00: scheduled__2023-09-27T18:42:00+00:00, state:running, queued_at: 2024-09-27 16:31:07.382996+00:00. externally triggered: False> successful
[2024-09-27T18:31:27.411+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:42:00+00:00, run_id=scheduled__2023-09-27T18:42:00+00:00, run_start_date=2024-09-27 16:31:07.396150+00:00, run_end_date=2024-09-27 16:31:27.411335+00:00, run_duration=20.015185, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:42:00+00:00, data_interval_end=2023-09-27 18:43:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:27.415+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:43:00+00:00, run_after=2023-09-27 18:44:00+00:00
[2024-09-27T18:31:28.459+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:44:00+00:00, run_after=2023-09-27 18:45:00+00:00
[2024-09-27T18:31:28.502+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:28.502+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:28.503+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:28.505+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:28.505+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:28.506+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:28.509+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:29.442+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:29.527+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:31.050+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:31.056+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:29.563590+00:00, run_end_date=2024-09-27 16:31:30.626885+00:00, run_duration=1.063295, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1736, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:28.504055+00:00, queued_by_job_id=1585, pid=330579
[2024-09-27T18:31:31.089+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:45:00+00:00, run_after=2023-09-27 18:46:00+00:00
[2024-09-27T18:31:31.142+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:31.143+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:31.143+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:31.143+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:31.146+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:31.147+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:31.147+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:31.147+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:31.148+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:31.151+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:32.089+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:32.173+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:33.175+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:34.113+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:34.197+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:35.217+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:35.217+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:35.220+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:32.210259+00:00, run_end_date=2024-09-27 16:31:32.774243+00:00, run_duration=0.563984, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1737, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:31.144896+00:00, queued_by_job_id=1585, pid=330594
[2024-09-27T18:31:35.220+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:34.233664+00:00, run_end_date=2024-09-27 16:31:34.822465+00:00, run_duration=0.588801, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1738, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:31.144896+00:00, queued_by_job_id=1585, pid=330601
[2024-09-27T18:31:35.259+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:46:00+00:00, run_after=2023-09-27 18:47:00+00:00
[2024-09-27T18:31:35.286+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:35.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:35.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:35.287+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:35.287+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:35.288+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:35.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:35.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:35.289+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:35.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:35.289+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:35.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:35.292+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:36.226+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:36.310+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:38.088+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:39.025+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:39.111+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:40.535+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:41.443+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:41.528+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:42.973+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:42.973+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:42.974+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:42.980+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:39.147530+00:00, run_end_date=2024-09-27 16:31:40.150721+00:00, run_duration=1.003191, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1740, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:35.287659+00:00, queued_by_job_id=1585, pid=330623
[2024-09-27T18:31:42.981+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:41.564483+00:00, run_end_date=2024-09-27 16:31:42.606510+00:00, run_duration=1.042027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1741, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:35.287659+00:00, queued_by_job_id=1585, pid=330630
[2024-09-27T18:31:42.982+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:36.346128+00:00, run_end_date=2024-09-27 16:31:37.691922+00:00, run_duration=1.345794, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1739, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:35.287659+00:00, queued_by_job_id=1585, pid=330608
[2024-09-27T18:31:43.141+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:47:00+00:00, run_after=2023-09-27 18:48:00+00:00
[2024-09-27T18:31:43.198+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:43.198+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:43.198+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:43.198+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:43.198+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:31:43.199+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:43:00+00:00 [scheduled]>
[2024-09-27T18:31:43.200+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:43.200+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:43.200+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:43.201+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:43.201+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:43.201+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:43.201+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:43.201+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:43.201+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:43.204+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:44.138+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:44.223+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:45.183+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:46.119+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:46.204+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:47.205+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:48.119+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:48.204+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:49.355+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:50.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:50.370+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:51.218+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:51.219+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:51.219+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:51.219+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:51.225+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:48.241215+00:00, run_end_date=2024-09-27 16:31:48.970553+00:00, run_duration=0.729338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1744, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:43.199572+00:00, queued_by_job_id=1585, pid=330668
[2024-09-27T18:31:51.226+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:44.259236+00:00, run_end_date=2024-09-27 16:31:44.756271+00:00, run_duration=0.497035, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1742, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:43.199572+00:00, queued_by_job_id=1585, pid=330646
[2024-09-27T18:31:51.226+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:50.406778+00:00, run_end_date=2024-09-27 16:31:50.831560+00:00, run_duration=0.424782, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1745, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:43.199572+00:00, queued_by_job_id=1585, pid=330676
[2024-09-27T18:31:51.227+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:46.240460+00:00, run_end_date=2024-09-27 16:31:46.782941+00:00, run_duration=0.542481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1743, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:43.199572+00:00, queued_by_job_id=1585, pid=330653
[2024-09-27T18:31:51.284+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:48:00+00:00, run_after=2023-09-27 18:49:00+00:00
[2024-09-27T18:31:51.337+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:43:00+00:00: scheduled__2023-09-27T18:43:00+00:00, state:running, queued_at: 2024-09-27 16:31:28.453511+00:00. externally triggered: False> successful
[2024-09-27T18:31:51.337+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:43:00+00:00, run_id=scheduled__2023-09-27T18:43:00+00:00, run_start_date=2024-09-27 16:31:28.473037+00:00, run_end_date=2024-09-27 16:31:51.337858+00:00, run_duration=22.864821, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:43:00+00:00, data_interval_end=2023-09-27 18:44:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:51.342+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:44:00+00:00, run_after=2023-09-27 18:45:00+00:00
[2024-09-27T18:31:51.351+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
[2024-09-27T18:31:51.351+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:51.351+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:51.351+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:51.352+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:31:51.352+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:44:00+00:00 [scheduled]>
[2024-09-27T18:31:51.353+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:51.353+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:31:51.353+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:51.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:51.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:51.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:51.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:51.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:51.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:51.358+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:52.289+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:52.374+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:53.231+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:54.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:54.254+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:55.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:56.034+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:56.118+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:57.334+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:58.278+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:31:58.362+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:31:59.273+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:59.274+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:59.274+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:59.274+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:31:59.281+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:58.398042+00:00, run_end_date=2024-09-27 16:31:58.884226+00:00, run_duration=0.486184, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1749, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:51.352747+00:00, queued_by_job_id=1585, pid=330721
[2024-09-27T18:31:59.282+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:56.154387+00:00, run_end_date=2024-09-27 16:31:56.940439+00:00, run_duration=0.786052, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1748, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:51.352747+00:00, queued_by_job_id=1585, pid=330706
[2024-09-27T18:31:59.282+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:54.290011+00:00, run_end_date=2024-09-27 16:31:54.686303+00:00, run_duration=0.396292, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1747, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:51.352747+00:00, queued_by_job_id=1585, pid=330699
[2024-09-27T18:31:59.283+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:31:52.410572+00:00, run_end_date=2024-09-27 16:31:52.827915+00:00, run_duration=0.417343, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1746, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:31:51.352747+00:00, queued_by_job_id=1585, pid=330683
[2024-09-27T18:31:59.330+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:45:00+00:00, run_after=2023-09-27 18:46:00+00:00
[2024-09-27T18:31:59.368+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:44:00+00:00: scheduled__2023-09-27T18:44:00+00:00, state:running, queued_at: 2024-09-27 16:31:31.082736+00:00. externally triggered: False> successful
[2024-09-27T18:31:59.369+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:44:00+00:00, run_id=scheduled__2023-09-27T18:44:00+00:00, run_start_date=2024-09-27 16:31:31.105344+00:00, run_end_date=2024-09-27 16:31:59.369520+00:00, run_duration=28.264176, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:44:00+00:00, data_interval_end=2023-09-27 18:45:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:31:59.374+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:45:00+00:00, run_after=2023-09-27 18:46:00+00:00
[2024-09-27T18:31:59.388+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
[2024-09-27T18:31:59.388+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:31:59.389+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:31:59.389+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:31:59.390+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:45:00+00:00 [scheduled]>
[2024-09-27T18:31:59.393+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:31:59.393+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:31:59.394+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:59.394+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:31:59.394+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:59.395+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:31:59.395+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:31:59.399+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:00.309+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:00.393+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:01.266+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:02.205+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:02.290+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:03.166+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:04.106+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:04.191+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:05.343+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:05.343+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:05.344+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:05.350+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:04.227530+00:00, run_end_date=2024-09-27 16:32:04.954743+00:00, run_duration=0.727213, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1752, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:31:59.391339+00:00, queued_by_job_id=1585, pid=330745
[2024-09-27T18:32:05.351+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:02.327486+00:00, run_end_date=2024-09-27 16:32:02.774898+00:00, run_duration=0.447412, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1751, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:31:59.391339+00:00, queued_by_job_id=1585, pid=330736
[2024-09-27T18:32:05.351+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:00.429304+00:00, run_end_date=2024-09-27 16:32:00.867555+00:00, run_duration=0.438251, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1750, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:31:59.391339+00:00, queued_by_job_id=1585, pid=330729
[2024-09-27T18:32:05.408+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:46:00+00:00, run_after=2023-09-27 18:47:00+00:00
[2024-09-27T18:32:05.438+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:45:00+00:00: scheduled__2023-09-27T18:45:00+00:00, state:running, queued_at: 2024-09-27 16:31:35.256572+00:00. externally triggered: False> successful
[2024-09-27T18:32:05.438+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:45:00+00:00, run_id=scheduled__2023-09-27T18:45:00+00:00, run_start_date=2024-09-27 16:31:35.265535+00:00, run_end_date=2024-09-27 16:32:05.438821+00:00, run_duration=30.173286, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:45:00+00:00, data_interval_end=2023-09-27 18:46:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:05.443+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:46:00+00:00, run_after=2023-09-27 18:47:00+00:00
[2024-09-27T18:32:05.456+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
[2024-09-27T18:32:05.457+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:05.457+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:05.457+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:46:00+00:00 [scheduled]>
[2024-09-27T18:32:05.460+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:05.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:05.461+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:05.461+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:05.462+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:05.465+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:06.401+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:06.487+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:07.469+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:08.410+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:08.496+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:10.051+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:10.052+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:10.058+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:08.532332+00:00, run_end_date=2024-09-27 16:32:09.635422+00:00, run_duration=1.10309, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1754, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:05.458782+00:00, queued_by_job_id=1585, pid=330767
[2024-09-27T18:32:10.058+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:06.523761+00:00, run_end_date=2024-09-27 16:32:07.089143+00:00, run_duration=0.565382, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1753, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:05.458782+00:00, queued_by_job_id=1585, pid=330760
[2024-09-27T18:32:10.086+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:47:00+00:00, run_after=2023-09-27 18:48:00+00:00
[2024-09-27T18:32:10.116+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:46:00+00:00: scheduled__2023-09-27T18:46:00+00:00, state:running, queued_at: 2024-09-27 16:31:43.135226+00:00. externally triggered: False> successful
[2024-09-27T18:32:10.116+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:46:00+00:00, run_id=scheduled__2023-09-27T18:46:00+00:00, run_start_date=2024-09-27 16:31:43.154405+00:00, run_end_date=2024-09-27 16:32:10.116882+00:00, run_duration=26.962477, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:46:00+00:00, data_interval_end=2023-09-27 18:47:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:10.121+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:47:00+00:00, run_after=2023-09-27 18:48:00+00:00
[2024-09-27T18:32:10.134+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
[2024-09-27T18:32:10.135+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:10.135+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:47:00+00:00 [scheduled]>
[2024-09-27T18:32:10.137+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:10.138+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:10.138+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:10.142+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:11.080+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:11.167+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:12.487+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:12.492+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:11.206433+00:00, run_end_date=2024-09-27 16:32:12.092812+00:00, run_duration=0.886379, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1755, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:10.136291+00:00, queued_by_job_id=1585, pid=330782
[2024-09-27T18:32:12.536+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:48:00+00:00, run_after=2023-09-27 18:49:00+00:00
[2024-09-27T18:32:12.555+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:47:00+00:00: scheduled__2023-09-27T18:47:00+00:00, state:running, queued_at: 2024-09-27 16:31:51.278718+00:00. externally triggered: False> successful
[2024-09-27T18:32:12.555+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:47:00+00:00, run_id=scheduled__2023-09-27T18:47:00+00:00, run_start_date=2024-09-27 16:31:51.297674+00:00, run_end_date=2024-09-27 16:32:12.555679+00:00, run_duration=21.258005, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:47:00+00:00, data_interval_end=2023-09-27 18:48:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:12.560+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:48:00+00:00, run_after=2023-09-27 18:49:00+00:00
[2024-09-27T18:32:13.707+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:49:00+00:00, run_after=2023-09-27 18:50:00+00:00
[2024-09-27T18:32:13.750+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:13.750+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:13.751+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:13.753+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:13.753+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:13.754+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:13.757+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:14.692+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:14.776+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:16.180+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:16.185+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:14.811991+00:00, run_end_date=2024-09-27 16:32:15.781900+00:00, run_duration=0.969909, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1756, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:13.752064+00:00, queued_by_job_id=1585, pid=330792
[2024-09-27T18:32:16.227+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:50:00+00:00, run_after=2023-09-27 18:51:00+00:00
[2024-09-27T18:32:16.277+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:16.277+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:16.277+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:16.277+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:16.278+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:16.279+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:16.279+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:16.279+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:16.279+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:16.282+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:17.217+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:17.301+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:18.666+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:19.606+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:19.691+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:21.058+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:21.059+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:21.065+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:17.337694+00:00, run_end_date=2024-09-27 16:32:18.248905+00:00, run_duration=0.911211, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1757, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:16.278115+00:00, queued_by_job_id=1585, pid=330810
[2024-09-27T18:32:21.065+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:19.728900+00:00, run_end_date=2024-09-27 16:32:20.693581+00:00, run_duration=0.964681, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1758, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:16.278115+00:00, queued_by_job_id=1585, pid=330818
[2024-09-27T18:32:21.114+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:51:00+00:00, run_after=2023-09-27 18:52:00+00:00
[2024-09-27T18:32:21.173+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:21.173+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:21.174+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:21.174+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:32:21.174+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:21.177+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:21.178+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:21.178+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:21.179+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:21.179+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:21.179+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:21.180+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:21.184+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:22.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:22.207+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:23.561+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:24.505+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:24.590+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:25.470+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:26.409+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:26.495+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:27.455+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:27.455+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:27.456+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:27.462+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:24.626510+00:00, run_end_date=2024-09-27 16:32:25.089393+00:00, run_duration=0.462883, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1760, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:21.176040+00:00, queued_by_job_id=1585, pid=330841
[2024-09-27T18:32:27.463+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:26.531638+00:00, run_end_date=2024-09-27 16:32:27.057932+00:00, run_duration=0.526294, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1761, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:21.176040+00:00, queued_by_job_id=1585, pid=330856
[2024-09-27T18:32:27.463+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:22.242581+00:00, run_end_date=2024-09-27 16:32:23.153134+00:00, run_duration=0.910553, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1759, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:21.176040+00:00, queued_by_job_id=1585, pid=330834
[2024-09-27T18:32:27.516+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:52:00+00:00, run_after=2023-09-27 18:53:00+00:00
[2024-09-27T18:32:27.578+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:27.578+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:27.579+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:27.579+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:32:27.579+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:32:27.580+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:48:00+00:00 [scheduled]>
[2024-09-27T18:32:27.582+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:27.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:27.582+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:27.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:27.582+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:27.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:27.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:27.583+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:27.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:27.586+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:28.506+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:28.591+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:29.461+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:30.432+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:30.517+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:31.392+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:32.300+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:32.387+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:33.307+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:34.217+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:34.301+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:35.856+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:35.857+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:35.857+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:35.858+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:35.864+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:32.425090+00:00, run_end_date=2024-09-27 16:32:32.928152+00:00, run_duration=0.503062, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1764, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:27.581179+00:00, queued_by_job_id=1585, pid=330891
[2024-09-27T18:32:35.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:34.339532+00:00, run_end_date=2024-09-27 16:32:35.437633+00:00, run_duration=1.098101, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1765, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:27.581179+00:00, queued_by_job_id=1585, pid=330898
[2024-09-27T18:32:35.866+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:30.555481+00:00, run_end_date=2024-09-27 16:32:30.977490+00:00, run_duration=0.422009, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1763, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:27.581179+00:00, queued_by_job_id=1585, pid=330884
[2024-09-27T18:32:35.867+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:28.627304+00:00, run_end_date=2024-09-27 16:32:29.056576+00:00, run_duration=0.429272, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1762, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:27.581179+00:00, queued_by_job_id=1585, pid=330863
[2024-09-27T18:32:35.919+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:53:00+00:00, run_after=2023-09-27 18:54:00+00:00
[2024-09-27T18:32:35.950+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:48:00+00:00: scheduled__2023-09-27T18:48:00+00:00, state:running, queued_at: 2024-09-27 16:32:13.701327+00:00. externally triggered: False> successful
[2024-09-27T18:32:35.950+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:48:00+00:00, run_id=scheduled__2023-09-27T18:48:00+00:00, run_start_date=2024-09-27 16:32:13.719374+00:00, run_end_date=2024-09-27 16:32:35.950776+00:00, run_duration=22.231402, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:48:00+00:00, data_interval_end=2023-09-27 18:49:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:35.952+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:49:00+00:00, run_after=2023-09-27 18:50:00+00:00
[2024-09-27T18:32:35.960+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
[2024-09-27T18:32:35.960+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:35.960+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:35.961+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:32:35.961+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:32:35.961+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:49:00+00:00 [scheduled]>
[2024-09-27T18:32:35.962+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:35.962+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:35.963+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:35.963+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:35.963+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:35.963+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:35.963+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:35.963+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:35.963+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:35.966+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:36.902+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:36.988+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:38.110+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:39.054+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:39.139+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:40.143+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:41.090+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:41.175+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:42.449+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:43.385+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:43.472+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:44.542+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:44.542+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:44.543+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:44.543+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:44.550+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:43.509320+00:00, run_end_date=2024-09-27 16:32:44.143902+00:00, run_duration=0.634582, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1769, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:35.961853+00:00, queued_by_job_id=1585, pid=330942
[2024-09-27T18:32:44.550+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:39.175653+00:00, run_end_date=2024-09-27 16:32:39.737680+00:00, run_duration=0.562027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1767, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:35.961853+00:00, queued_by_job_id=1585, pid=330920
[2024-09-27T18:32:44.551+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:41.210939+00:00, run_end_date=2024-09-27 16:32:42.058864+00:00, run_duration=0.847925, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1768, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:35.961853+00:00, queued_by_job_id=1585, pid=330935
[2024-09-27T18:32:44.552+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:37.024002+00:00, run_end_date=2024-09-27 16:32:37.690431+00:00, run_duration=0.666429, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1766, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:35.961853+00:00, queued_by_job_id=1585, pid=330913
[2024-09-27T18:32:44.711+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:54:00+00:00, run_after=2023-09-27 18:55:00+00:00
[2024-09-27T18:32:44.765+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:49:00+00:00: scheduled__2023-09-27T18:49:00+00:00, state:running, queued_at: 2024-09-27 16:32:16.220999+00:00. externally triggered: False> successful
[2024-09-27T18:32:44.765+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:49:00+00:00, run_id=scheduled__2023-09-27T18:49:00+00:00, run_start_date=2024-09-27 16:32:16.244292+00:00, run_end_date=2024-09-27 16:32:44.765804+00:00, run_duration=28.521512, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:49:00+00:00, data_interval_end=2023-09-27 18:50:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:44.770+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:50:00+00:00, run_after=2023-09-27 18:51:00+00:00
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:32:44.779+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:50:00+00:00 [scheduled]>
[2024-09-27T18:32:44.781+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:50:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:44.781+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:32:44.781+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:44.781+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:44.782+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:44.782+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:44.782+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:44.782+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:44.782+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:44.785+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:45.720+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:45.807+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:46.741+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:47.688+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:47.775+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:48.734+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:49.649+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:49.737+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:50.494+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:51.434+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:51.519+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:52.548+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:52.548+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:52.549+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:52.549+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:52.556+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:49.773434+00:00, run_end_date=2024-09-27 16:32:50.078622+00:00, run_duration=0.305188, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1772, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:44.780460+00:00, queued_by_job_id=1585, pid=330973
[2024-09-27T18:32:52.557+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:51.555906+00:00, run_end_date=2024-09-27 16:32:52.135571+00:00, run_duration=0.579665, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1773, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:44.780460+00:00, queued_by_job_id=1585, pid=330980
[2024-09-27T18:32:52.557+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:45.843569+00:00, run_end_date=2024-09-27 16:32:46.348454+00:00, run_duration=0.504885, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1770, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:32:44.780460+00:00, queued_by_job_id=1585, pid=330958
[2024-09-27T18:32:52.558+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:47.812112+00:00, run_end_date=2024-09-27 16:32:48.304031+00:00, run_duration=0.491919, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1771, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:44.780460+00:00, queued_by_job_id=1585, pid=330965
[2024-09-27T18:32:52.607+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:51:00+00:00, run_after=2023-09-27 18:52:00+00:00
[2024-09-27T18:32:52.646+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:50:00+00:00: scheduled__2023-09-27T18:50:00+00:00, state:running, queued_at: 2024-09-27 16:32:21.107602+00:00. externally triggered: False> successful
[2024-09-27T18:32:52.646+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:50:00+00:00, run_id=scheduled__2023-09-27T18:50:00+00:00, run_start_date=2024-09-27 16:32:21.126345+00:00, run_end_date=2024-09-27 16:32:52.646630+00:00, run_duration=31.520285, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:50:00+00:00, data_interval_end=2023-09-27 18:51:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:52.651+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:51:00+00:00, run_after=2023-09-27 18:52:00+00:00
[2024-09-27T18:32:52.665+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
[2024-09-27T18:32:52.666+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:52.666+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:52.666+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:32:52.667+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:51:00+00:00 [scheduled]>
[2024-09-27T18:32:52.670+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:52.670+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:32:52.671+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:52.671+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:52.671+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:52.672+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:52.672+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:52.675+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:53.610+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:53.695+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:54.697+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:55.637+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:55.722+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:56.718+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:57.670+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:57.755+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:32:58.669+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:58.669+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:58.669+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:32:58.672+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:57.792072+00:00, run_end_date=2024-09-27 16:32:58.309741+00:00, run_duration=0.517669, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1776, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:52.668329+00:00, queued_by_job_id=1585, pid=331002
[2024-09-27T18:32:58.673+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:53.733080+00:00, run_end_date=2024-09-27 16:32:54.295811+00:00, run_duration=0.562731, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1774, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:32:52.668329+00:00, queued_by_job_id=1585, pid=330987
[2024-09-27T18:32:58.673+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:55.758498+00:00, run_end_date=2024-09-27 16:32:56.318559+00:00, run_duration=0.560061, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1775, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:52.668329+00:00, queued_by_job_id=1585, pid=330995
[2024-09-27T18:32:58.707+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:52:00+00:00, run_after=2023-09-27 18:53:00+00:00
[2024-09-27T18:32:58.723+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:51:00+00:00: scheduled__2023-09-27T18:51:00+00:00, state:running, queued_at: 2024-09-27 16:32:27.509618+00:00. externally triggered: False> successful
[2024-09-27T18:32:58.723+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:51:00+00:00, run_id=scheduled__2023-09-27T18:51:00+00:00, run_start_date=2024-09-27 16:32:27.529551+00:00, run_end_date=2024-09-27 16:32:58.723441+00:00, run_duration=31.19389, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:51:00+00:00, data_interval_end=2023-09-27 18:52:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:32:58.725+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:52:00+00:00, run_after=2023-09-27 18:53:00+00:00
[2024-09-27T18:32:58.732+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
[2024-09-27T18:32:58.732+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:32:58.732+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:32:58.732+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:52:00+00:00 [scheduled]>
[2024-09-27T18:32:58.733+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:32:58.734+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:32:58.734+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:58.734+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:32:58.734+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:58.737+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:32:59.655+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:32:59.740+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:00.765+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:01.677+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:01.765+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:02.676+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:02.677+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:02.683+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:32:59.776124+00:00, run_end_date=2024-09-27 16:33:00.366485+00:00, run_duration=0.590361, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1777, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:32:58.733274+00:00, queued_by_job_id=1585, pid=331010
[2024-09-27T18:33:02.684+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:01.802424+00:00, run_end_date=2024-09-27 16:33:02.256270+00:00, run_duration=0.453846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1778, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:32:58.733274+00:00, queued_by_job_id=1585, pid=331017
[2024-09-27T18:33:02.710+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:53:00+00:00, run_after=2023-09-27 18:54:00+00:00
[2024-09-27T18:33:02.727+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:52:00+00:00: scheduled__2023-09-27T18:52:00+00:00, state:running, queued_at: 2024-09-27 16:32:35.912865+00:00. externally triggered: False> successful
[2024-09-27T18:33:02.727+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:52:00+00:00, run_id=scheduled__2023-09-27T18:52:00+00:00, run_start_date=2024-09-27 16:32:35.931377+00:00, run_end_date=2024-09-27 16:33:02.727368+00:00, run_duration=26.795991, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:52:00+00:00, data_interval_end=2023-09-27 18:53:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:02.729+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:53:00+00:00, run_after=2023-09-27 18:54:00+00:00
[2024-09-27T18:33:02.736+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
[2024-09-27T18:33:02.736+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:02.736+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:53:00+00:00 [scheduled]>
[2024-09-27T18:33:02.737+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:02.738+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:02.738+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:02.740+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:03.675+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:03.772+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:04.960+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:04.966+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:03.809133+00:00, run_end_date=2024-09-27 16:33:04.568619+00:00, run_duration=0.759486, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1779, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:02.737180+00:00, queued_by_job_id=1585, pid=331025
[2024-09-27T18:33:05.009+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:54:00+00:00, run_after=2023-09-27 18:55:00+00:00
[2024-09-27T18:33:05.030+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:53:00+00:00: scheduled__2023-09-27T18:53:00+00:00, state:running, queued_at: 2024-09-27 16:32:44.705658+00:00. externally triggered: False> successful
[2024-09-27T18:33:05.031+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:53:00+00:00, run_id=scheduled__2023-09-27T18:53:00+00:00, run_start_date=2024-09-27 16:32:44.725003+00:00, run_end_date=2024-09-27 16:33:05.031163+00:00, run_duration=20.30616, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:53:00+00:00, data_interval_end=2023-09-27 18:54:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:05.035+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:54:00+00:00, run_after=2023-09-27 18:55:00+00:00
[2024-09-27T18:33:05.400+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:55:00+00:00, run_after=2023-09-27 18:56:00+00:00
[2024-09-27T18:33:05.447+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:05.447+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:05.448+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:05.450+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:05.450+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:05.450+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:05.454+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:06.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:06.491+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:07.448+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:07.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:06.527657+00:00, run_end_date=2024-09-27 16:33:07.025771+00:00, run_duration=0.498114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1780, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:05.449057+00:00, queued_by_job_id=1585, pid=331041
[2024-09-27T18:33:07.490+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:56:00+00:00, run_after=2023-09-27 18:57:00+00:00
[2024-09-27T18:33:07.539+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:07.540+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:07.540+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:07.540+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:07.541+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:07.541+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:07.542+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:07.542+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:07.542+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:07.545+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:08.483+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:08.568+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:09.560+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:10.473+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:10.557+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:11.475+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:11.476+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:11.481+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:08.599285+00:00, run_end_date=2024-09-27 16:33:09.147010+00:00, run_duration=0.547725, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1781, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:07.540922+00:00, queued_by_job_id=1585, pid=331048
[2024-09-27T18:33:11.482+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:10.593548+00:00, run_end_date=2024-09-27 16:33:11.054834+00:00, run_duration=0.461286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1782, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:07.540922+00:00, queued_by_job_id=1585, pid=331055
[2024-09-27T18:33:11.538+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:57:00+00:00, run_after=2023-09-27 18:58:00+00:00
[2024-09-27T18:33:11.595+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:11.595+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:11.596+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:11.596+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:33:11.596+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:11.599+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:56:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:11.600+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:11.600+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:11.601+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:11.601+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:11.601+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:11.602+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:11.606+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:12.538+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:12.623+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:13.580+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:14.482+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:14.568+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:15.525+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:16.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:16.512+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:17.524+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:17.525+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:17.525+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:17.530+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:12.654636+00:00, run_end_date=2024-09-27 16:33:13.158598+00:00, run_duration=0.503962, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1783, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:11.597971+00:00, queued_by_job_id=1585, pid=331062
[2024-09-27T18:33:17.531+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:14.604041+00:00, run_end_date=2024-09-27 16:33:15.102279+00:00, run_duration=0.498238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1784, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:11.597971+00:00, queued_by_job_id=1585, pid=331072
[2024-09-27T18:33:17.532+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:16.548392+00:00, run_end_date=2024-09-27 16:33:17.134215+00:00, run_duration=0.585823, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1785, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:11.597971+00:00, queued_by_job_id=1585, pid=331082
[2024-09-27T18:33:17.684+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:58:00+00:00, run_after=2023-09-27 18:59:00+00:00
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:33:17.739+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:54:00+00:00 [scheduled]>
[2024-09-27T18:33:17.741+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:56:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:17.741+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:17.741+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:17.741+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:17.741+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:17.742+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:17.742+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:17.742+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:17.742+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:17.746+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:18.697+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:18.781+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:19.730+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:20.654+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:20.743+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:21.552+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:22.469+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:22.558+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:23.877+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:24.824+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:24.909+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:25.904+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:25.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:25.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:25.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:25.911+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:20.779851+00:00, run_end_date=2024-09-27 16:33:21.173421+00:00, run_duration=0.39357, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1787, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:17.740389+00:00, queued_by_job_id=1585, pid=331099
[2024-09-27T18:33:25.912+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:22.595464+00:00, run_end_date=2024-09-27 16:33:23.456614+00:00, run_duration=0.86115, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1788, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:17.740389+00:00, queued_by_job_id=1585, pid=331106
[2024-09-27T18:33:25.913+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:18.818313+00:00, run_end_date=2024-09-27 16:33:19.336032+00:00, run_duration=0.517719, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1786, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:17.740389+00:00, queued_by_job_id=1585, pid=331091
[2024-09-27T18:33:25.914+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:24.946010+00:00, run_end_date=2024-09-27 16:33:25.508496+00:00, run_duration=0.562486, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1789, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:17.740389+00:00, queued_by_job_id=1585, pid=331113
[2024-09-27T18:33:25.968+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:59:00+00:00, run_after=2023-09-27 19:00:00+00:00
[2024-09-27T18:33:26.021+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:54:00+00:00: scheduled__2023-09-27T18:54:00+00:00, state:running, queued_at: 2024-09-27 16:33:05.394609+00:00. externally triggered: False> successful
[2024-09-27T18:33:26.021+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:54:00+00:00, run_id=scheduled__2023-09-27T18:54:00+00:00, run_start_date=2024-09-27 16:33:05.417476+00:00, run_end_date=2024-09-27 16:33:26.021864+00:00, run_duration=20.604388, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:54:00+00:00, data_interval_end=2023-09-27 18:55:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:26.026+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:55:00+00:00, run_after=2023-09-27 18:56:00+00:00
[2024-09-27T18:33:26.034+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
[2024-09-27T18:33:26.034+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:26.034+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:26.034+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:33:26.035+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:33:26.035+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:55:00+00:00 [scheduled]>
[2024-09-27T18:33:26.036+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:56:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:26.036+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:26.036+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:26.037+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:26.037+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:26.037+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:26.037+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:26.037+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:26.037+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:26.040+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:26.977+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:27.061+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:28.181+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:29.087+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:29.172+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:30.138+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:31.060+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:31.147+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:32.715+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:33.662+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:33.747+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:35.260+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:35.261+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:35.261+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:35.261+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:35.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:27.097421+00:00, run_end_date=2024-09-27 16:33:27.767543+00:00, run_duration=0.670122, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1790, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:26.035736+00:00, queued_by_job_id=1585, pid=331121
[2024-09-27T18:33:35.269+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:31.186324+00:00, run_end_date=2024-09-27 16:33:32.266141+00:00, run_duration=1.079817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1792, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:26.035736+00:00, queued_by_job_id=1585, pid=331149
[2024-09-27T18:33:35.269+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:33.783644+00:00, run_end_date=2024-09-27 16:33:34.846944+00:00, run_duration=1.0633, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1793, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:26.035736+00:00, queued_by_job_id=1585, pid=331156
[2024-09-27T18:33:35.270+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:29.208498+00:00, run_end_date=2024-09-27 16:33:29.716808+00:00, run_duration=0.50831, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1791, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:26.035736+00:00, queued_by_job_id=1585, pid=331128
[2024-09-27T18:33:35.317+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:56:00+00:00, run_after=2023-09-27 18:57:00+00:00
[2024-09-27T18:33:35.353+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:55:00+00:00: scheduled__2023-09-27T18:55:00+00:00, state:running, queued_at: 2024-09-27 16:33:07.484848+00:00. externally triggered: False> successful
[2024-09-27T18:33:35.354+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:55:00+00:00, run_id=scheduled__2023-09-27T18:55:00+00:00, run_start_date=2024-09-27 16:33:07.507872+00:00, run_end_date=2024-09-27 16:33:35.353977+00:00, run_duration=27.846105, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:55:00+00:00, data_interval_end=2023-09-27 18:56:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:35.358+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:56:00+00:00, run_after=2023-09-27 18:57:00+00:00
[2024-09-27T18:33:35.373+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
[2024-09-27T18:33:35.373+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:35.374+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:35.374+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:33:35.375+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:56:00+00:00 [scheduled]>
[2024-09-27T18:33:35.377+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:35.378+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:35.378+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:35.379+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:35.379+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:35.380+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:35.380+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:35.383+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:36.321+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:36.405+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:37.685+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:38.622+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:38.706+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:40.023+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:40.957+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:41.042+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:42.519+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:42.520+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:42.520+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:42.526+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:36.436726+00:00, run_end_date=2024-09-27 16:33:37.274895+00:00, run_duration=0.838169, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1794, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:35.376223+00:00, queued_by_job_id=1585, pid=331163
[2024-09-27T18:33:42.527+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:41.077606+00:00, run_end_date=2024-09-27 16:33:42.096789+00:00, run_duration=1.019183, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1796, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:35.376223+00:00, queued_by_job_id=1585, pid=331177
[2024-09-27T18:33:42.528+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:38.743293+00:00, run_end_date=2024-09-27 16:33:39.638400+00:00, run_duration=0.895107, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1795, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:35.376223+00:00, queued_by_job_id=1585, pid=331170
[2024-09-27T18:33:42.575+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:57:00+00:00, run_after=2023-09-27 18:58:00+00:00
[2024-09-27T18:33:42.605+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:56:00+00:00: scheduled__2023-09-27T18:56:00+00:00, state:running, queued_at: 2024-09-27 16:33:11.532057+00:00. externally triggered: False> successful
[2024-09-27T18:33:42.606+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:56:00+00:00, run_id=scheduled__2023-09-27T18:56:00+00:00, run_start_date=2024-09-27 16:33:11.549657+00:00, run_end_date=2024-09-27 16:33:42.606058+00:00, run_duration=31.056401, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:56:00+00:00, data_interval_end=2023-09-27 18:57:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:42.610+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:57:00+00:00, run_after=2023-09-27 18:58:00+00:00
[2024-09-27T18:33:42.624+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
[2024-09-27T18:33:42.624+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:42.625+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:42.625+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:57:00+00:00 [scheduled]>
[2024-09-27T18:33:42.627+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:42.628+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:42.628+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:42.629+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:42.629+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:42.635+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:43.567+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:43.652+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:44.971+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:45.896+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:45.981+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:47.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:47.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:47.101+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:43.688008+00:00, run_end_date=2024-09-27 16:33:44.545157+00:00, run_duration=0.857149, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1797, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:42.626398+00:00, queued_by_job_id=1585, pid=331184
[2024-09-27T18:33:47.102+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:46.018667+00:00, run_end_date=2024-09-27 16:33:46.702802+00:00, run_duration=0.684135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1798, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:42.626398+00:00, queued_by_job_id=1585, pid=331192
[2024-09-27T18:33:47.129+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:58:00+00:00, run_after=2023-09-27 18:59:00+00:00
[2024-09-27T18:33:47.158+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:57:00+00:00: scheduled__2023-09-27T18:57:00+00:00, state:running, queued_at: 2024-09-27 16:33:17.678432+00:00. externally triggered: False> successful
[2024-09-27T18:33:47.159+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:57:00+00:00, run_id=scheduled__2023-09-27T18:57:00+00:00, run_start_date=2024-09-27 16:33:17.696719+00:00, run_end_date=2024-09-27 16:33:47.159111+00:00, run_duration=29.462392, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:57:00+00:00, data_interval_end=2023-09-27 18:58:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:47.163+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:58:00+00:00, run_after=2023-09-27 18:59:00+00:00
[2024-09-27T18:33:47.176+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
[2024-09-27T18:33:47.177+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:47.177+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:58:00+00:00 [scheduled]>
[2024-09-27T18:33:47.179+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:58:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:47.180+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:47.180+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:47.184+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:48.118+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:48.202+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:49.114+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:49.117+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:48.238769+00:00, run_end_date=2024-09-27 16:33:48.752281+00:00, run_duration=0.513512, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1799, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:47.178417+00:00, queued_by_job_id=1585, pid=331199
[2024-09-27T18:33:49.268+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:00:00+00:00, run_after=2023-09-27 19:01:00+00:00
[2024-09-27T18:33:49.303+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:58:00+00:00: scheduled__2023-09-27T18:58:00+00:00, state:running, queued_at: 2024-09-27 16:33:25.961806+00:00. externally triggered: False> successful
[2024-09-27T18:33:49.304+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:58:00+00:00, run_id=scheduled__2023-09-27T18:58:00+00:00, run_start_date=2024-09-27 16:33:25.980643+00:00, run_end_date=2024-09-27 16:33:49.304579+00:00, run_duration=23.323936, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:58:00+00:00, data_interval_end=2023-09-27 18:59:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:33:49.309+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:59:00+00:00, run_after=2023-09-27 19:00:00+00:00
[2024-09-27T18:33:49.322+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:49.322+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:49.323+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:49.325+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:49.325+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:49.326+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:49.329+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:50.282+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:50.367+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:51.247+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:51.252+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:50.404753+00:00, run_end_date=2024-09-27 16:33:50.801489+00:00, run_duration=0.396736, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1800, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:49.323972+00:00, queued_by_job_id=1585, pid=331208
[2024-09-27T18:33:51.287+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:00:00+00:00, run_after=2023-09-27 19:01:00+00:00
[2024-09-27T18:33:51.327+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:51.327+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:51.328+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:51.329+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:51.330+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:51.330+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:51.337+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:52.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:52.370+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:53.214+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:53.219+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:52.407502+00:00, run_end_date=2024-09-27 16:33:52.848082+00:00, run_duration=0.44058, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1801, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:51.328720+00:00, queued_by_job_id=1585, pid=331216
[2024-09-27T18:33:53.256+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:01:00+00:00, run_after=2023-09-27 19:02:00+00:00
[2024-09-27T18:33:53.290+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:53.291+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:53.291+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:53.291+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:53.292+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:53.292+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:53.292+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:53.293+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:33:53.293+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:53.296+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:54.223+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:54.307+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:55.329+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:56.278+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:56.378+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:57.434+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:57.435+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:33:57.440+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:56.412718+00:00, run_end_date=2024-09-27 16:33:57.014008+00:00, run_duration=0.60129, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1803, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:33:53.291811+00:00, queued_by_job_id=1585, pid=331232
[2024-09-27T18:33:57.441+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:54.344040+00:00, run_end_date=2024-09-27 16:33:54.895287+00:00, run_duration=0.551247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1802, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:53.291811+00:00, queued_by_job_id=1585, pid=331224
[2024-09-27T18:33:57.486+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:02:00+00:00, run_after=2023-09-27 19:03:00+00:00
[2024-09-27T18:33:57.533+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:57.533+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:33:57.533+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:33:57.533+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:33:57.533+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:59:00+00:00 [scheduled]>
[2024-09-27T18:33:57.535+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:33:57.535+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:33:57.535+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:57.535+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:33:57.535+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:57.536+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:33:57.536+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:57.539+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:33:58.494+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:33:58.584+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:33:59.338+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:00.302+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:00.387+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:01.132+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:02.105+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:02.193+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:02.965+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:02.966+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:02.966+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:02.973+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:02.232753+00:00, run_end_date=2024-09-27 16:34:02.601943+00:00, run_duration=0.36919, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1806, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:33:57.534247+00:00, queued_by_job_id=1585, pid=331254
[2024-09-27T18:34:02.973+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:00.425676+00:00, run_end_date=2024-09-27 16:34:00.751825+00:00, run_duration=0.326149, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1805, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:33:57.534247+00:00, queued_by_job_id=1585, pid=331247
[2024-09-27T18:34:02.974+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:33:58.621492+00:00, run_end_date=2024-09-27 16:33:58.926841+00:00, run_duration=0.305349, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1804, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:33:57.534247+00:00, queued_by_job_id=1585, pid=331239
[2024-09-27T18:34:03.022+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:03:00+00:00, run_after=2023-09-27 19:04:00+00:00
[2024-09-27T18:34:03.050+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:59:00+00:00: scheduled__2023-09-27T18:59:00+00:00, state:running, queued_at: 2024-09-27 16:33:49.262376+00:00. externally triggered: False> successful
[2024-09-27T18:34:03.050+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:59:00+00:00, run_id=scheduled__2023-09-27T18:59:00+00:00, run_start_date=2024-09-27 16:33:49.281314+00:00, run_end_date=2024-09-27 16:34:03.050425+00:00, run_duration=13.769111, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:59:00+00:00, data_interval_end=2023-09-27 19:00:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:03.052+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:00:00+00:00, run_after=2023-09-27 19:01:00+00:00
[2024-09-27T18:34:03.060+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
[2024-09-27T18:34:03.060+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:03.061+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:03.061+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:34:03.061+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
[2024-09-27T18:34:03.062+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:03.062+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:03.062+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:03.063+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:03.063+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:03.063+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:03.063+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:03.066+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:04.039+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:04.129+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:04.888+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:05.876+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:05.965+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:06.753+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:07.687+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:07.777+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:08.617+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:08.617+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:08.618+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:08.624+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:04.168920+00:00, run_end_date=2024-09-27 16:34:04.495409+00:00, run_duration=0.326489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1807, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:03.061753+00:00, queued_by_job_id=1585, pid=331262
[2024-09-27T18:34:08.625+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:07.815246+00:00, run_end_date=2024-09-27 16:34:08.205949+00:00, run_duration=0.390703, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1809, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:03.061753+00:00, queued_by_job_id=1585, pid=331276
[2024-09-27T18:34:08.626+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:06.004095+00:00, run_end_date=2024-09-27 16:34:06.323028+00:00, run_duration=0.318933, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1808, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:03.061753+00:00, queued_by_job_id=1585, pid=331269
[2024-09-27T18:34:08.685+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:01:00+00:00, run_after=2023-09-27 19:02:00+00:00
[2024-09-27T18:34:08.730+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
[2024-09-27T18:34:08.731+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:08.731+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:08.732+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:34:08.732+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:00:00+00:00 [scheduled]>
[2024-09-27T18:34:08.734+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:08.735+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:08.735+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:08.736+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:08.736+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:08.736+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:08.737+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:08.740+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:09.694+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:09.782+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:10.567+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:11.554+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:11.644+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:12.422+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:13.407+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:13.497+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:14.319+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:14.320+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:14.320+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:14.326+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:09.820125+00:00, run_end_date=2024-09-27 16:34:10.145061+00:00, run_duration=0.324936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1810, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:08.733599+00:00, queued_by_job_id=1585, pid=331283
[2024-09-27T18:34:14.326+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:13.535145+00:00, run_end_date=2024-09-27 16:34:13.873737+00:00, run_duration=0.338592, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1812, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:08.733599+00:00, queued_by_job_id=1585, pid=331298
[2024-09-27T18:34:14.327+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:11.682553+00:00, run_end_date=2024-09-27 16:34:11.999222+00:00, run_duration=0.316669, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1811, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:08.733599+00:00, queued_by_job_id=1585, pid=331290
[2024-09-27T18:34:14.364+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:02:00+00:00, run_after=2023-09-27 19:03:00+00:00
[2024-09-27T18:34:14.393+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:00:00+00:00: scheduled__2023-09-27T19:00:00+00:00, state:running, queued_at: 2024-09-27 16:33:53.250372+00:00. externally triggered: False> successful
[2024-09-27T18:34:14.393+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:00:00+00:00, run_id=scheduled__2023-09-27T19:00:00+00:00, run_start_date=2024-09-27 16:33:53.270747+00:00, run_end_date=2024-09-27 16:34:14.393626+00:00, run_duration=21.122879, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:00:00+00:00, data_interval_end=2023-09-27 19:01:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:14.397+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:01:00+00:00, run_after=2023-09-27 19:02:00+00:00
[2024-09-27T18:34:14.410+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
[2024-09-27T18:34:14.410+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:14.411+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:14.411+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:01:00+00:00 [scheduled]>
[2024-09-27T18:34:14.413+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:14.414+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:14.414+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:14.414+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:14.415+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:14.418+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:15.391+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:15.478+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:16.263+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:17.220+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:17.308+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:18.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:18.082+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:18.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:15.516267+00:00, run_end_date=2024-09-27 16:34:15.842314+00:00, run_duration=0.326047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1813, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:14.412268+00:00, queued_by_job_id=1585, pid=331307
[2024-09-27T18:34:18.088+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:17.344329+00:00, run_end_date=2024-09-27 16:34:17.693006+00:00, run_duration=0.348677, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1814, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:14.412268+00:00, queued_by_job_id=1585, pid=331315
[2024-09-27T18:34:18.111+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:02:00+00:00, run_after=2023-09-27 19:03:00+00:00
[2024-09-27T18:34:18.128+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:01:00+00:00: scheduled__2023-09-27T19:01:00+00:00, state:running, queued_at: 2024-09-27 16:33:57.480841+00:00. externally triggered: False> successful
[2024-09-27T18:34:18.129+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:01:00+00:00, run_id=scheduled__2023-09-27T19:01:00+00:00, run_start_date=2024-09-27 16:33:57.498043+00:00, run_end_date=2024-09-27 16:34:18.128986+00:00, run_duration=20.630943, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:01:00+00:00, data_interval_end=2023-09-27 19:02:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:18.131+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:02:00+00:00, run_after=2023-09-27 19:03:00+00:00
[2024-09-27T18:34:18.137+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
[2024-09-27T18:34:18.137+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:18.137+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:02:00+00:00 [scheduled]>
[2024-09-27T18:34:18.138+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:18.139+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:18.139+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:18.141+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:19.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:19.198+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:20.025+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:20.029+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:19.235828+00:00, run_end_date=2024-09-27 16:34:19.586726+00:00, run_duration=0.350898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1815, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:18.138194+00:00, queued_by_job_id=1585, pid=331323
[2024-09-27T18:34:20.176+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:04:00+00:00, run_after=2023-09-27 19:05:00+00:00
[2024-09-27T18:34:20.196+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:02:00+00:00: scheduled__2023-09-27T19:02:00+00:00, state:running, queued_at: 2024-09-27 16:34:03.016655+00:00. externally triggered: False> successful
[2024-09-27T18:34:20.196+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:02:00+00:00, run_id=scheduled__2023-09-27T19:02:00+00:00, run_start_date=2024-09-27 16:34:03.030562+00:00, run_end_date=2024-09-27 16:34:20.196394+00:00, run_duration=17.165832, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:02:00+00:00, data_interval_end=2023-09-27 19:03:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:20.198+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:03:00+00:00, run_after=2023-09-27 19:04:00+00:00
[2024-09-27T18:34:20.206+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:20.206+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:20.207+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:20.208+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:20.208+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:20.208+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:20.211+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:21.191+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:21.282+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:22.072+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:22.076+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:21.319489+00:00, run_end_date=2024-09-27 16:34:21.636787+00:00, run_duration=0.317298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1816, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:20.207617+00:00, queued_by_job_id=1585, pid=331332
[2024-09-27T18:34:22.100+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:04:00+00:00, run_after=2023-09-27 19:05:00+00:00
[2024-09-27T18:34:22.123+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:22.124+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:22.124+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:22.125+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:22.125+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:22.125+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:22.128+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:23.105+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:23.193+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:23.997+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:24.002+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:23.231582+00:00, run_end_date=2024-09-27 16:34:23.548059+00:00, run_duration=0.316477, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1817, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:22.124793+00:00, queued_by_job_id=1585, pid=331339
[2024-09-27T18:34:24.035+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:05:00+00:00, run_after=2023-09-27 19:06:00+00:00
[2024-09-27T18:34:24.072+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:24.073+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:24.073+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:24.073+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:24.074+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:24.075+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:24.075+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:24.075+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:24.075+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:24.078+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:25.025+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:25.111+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:25.831+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:26.786+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:26.871+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:27.651+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:27.652+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:27.658+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:25.148413+00:00, run_end_date=2024-09-27 16:34:25.469074+00:00, run_duration=0.320661, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1818, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:24.073826+00:00, queued_by_job_id=1585, pid=331346
[2024-09-27T18:34:27.659+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:26.907832+00:00, run_end_date=2024-09-27 16:34:27.246118+00:00, run_duration=0.338286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1819, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:24.073826+00:00, queued_by_job_id=1585, pid=331353
[2024-09-27T18:34:27.708+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:06:00+00:00, run_after=2023-09-27 19:07:00+00:00
[2024-09-27T18:34:27.763+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:27.763+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:27.764+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:27.764+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:34:27.765+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:03:00+00:00 [scheduled]>
[2024-09-27T18:34:27.767+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:27.768+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:27.768+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:27.769+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:27.769+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:27.769+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:27.770+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:27.773+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:28.713+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:28.798+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:30.182+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:31.124+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:31.213+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:32.526+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:33.492+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:33.576+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:35.010+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:35.010+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:35.011+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:35.017+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:28.834704+00:00, run_end_date=2024-09-27 16:34:29.709797+00:00, run_duration=0.875093, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1820, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:27.766124+00:00, queued_by_job_id=1585, pid=331360
[2024-09-27T18:34:35.018+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:31.252156+00:00, run_end_date=2024-09-27 16:34:32.126975+00:00, run_duration=0.874819, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1821, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:27.766124+00:00, queued_by_job_id=1585, pid=331381
[2024-09-27T18:34:35.019+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:33.613824+00:00, run_end_date=2024-09-27 16:34:34.624090+00:00, run_duration=1.010266, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1822, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:27.766124+00:00, queued_by_job_id=1585, pid=331388
[2024-09-27T18:34:35.069+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:07:00+00:00, run_after=2023-09-27 19:08:00+00:00
[2024-09-27T18:34:35.114+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:03:00+00:00: scheduled__2023-09-27T19:03:00+00:00, state:running, queued_at: 2024-09-27 16:34:20.173237+00:00. externally triggered: False> successful
[2024-09-27T18:34:35.114+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:03:00+00:00, run_id=scheduled__2023-09-27T19:03:00+00:00, run_start_date=2024-09-27 16:34:20.183325+00:00, run_end_date=2024-09-27 16:34:35.114809+00:00, run_duration=14.931484, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:03:00+00:00, data_interval_end=2023-09-27 19:04:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:35.119+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:04:00+00:00, run_after=2023-09-27 19:05:00+00:00
[2024-09-27T18:34:35.133+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
[2024-09-27T18:34:35.134+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:35.134+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:35.134+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:34:35.135+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
[2024-09-27T18:34:35.137+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:04:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:35.137+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:35.138+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:35.138+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:35.138+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:35.138+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:35.138+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:35.142+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:36.097+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:36.182+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:37.320+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:38.337+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:38.422+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:39.377+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:40.313+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:40.399+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:41.167+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:41.167+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:41.167+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:41.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:36.217399+00:00, run_end_date=2024-09-27 16:34:36.875045+00:00, run_duration=0.657646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1823, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:35.136237+00:00, queued_by_job_id=1585, pid=331395
[2024-09-27T18:34:41.175+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:38.459061+00:00, run_end_date=2024-09-27 16:34:38.929231+00:00, run_duration=0.47017, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1824, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:35.136237+00:00, queued_by_job_id=1585, pid=331415
[2024-09-27T18:34:41.175+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:40.436008+00:00, run_end_date=2024-09-27 16:34:40.784589+00:00, run_duration=0.348581, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1825, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:35.136237+00:00, queued_by_job_id=1585, pid=331447
[2024-09-27T18:34:41.223+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:05:00+00:00, run_after=2023-09-27 19:06:00+00:00
[2024-09-27T18:34:41.262+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
[2024-09-27T18:34:41.263+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:41.263+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:41.263+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:34:41.263+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:04:00+00:00 [scheduled]>
[2024-09-27T18:34:41.264+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:04:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:41.265+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:41.265+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:41.265+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:41.265+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:41.265+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:41.265+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:41.268+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:42.214+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:42.306+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:43.112+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:44.057+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:44.143+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:45.014+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:45.938+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:46.022+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:46.963+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:46.964+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:46.965+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:46.971+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:42.343720+00:00, run_end_date=2024-09-27 16:34:42.684255+00:00, run_duration=0.340535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1826, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:41.264019+00:00, queued_by_job_id=1585, pid=331455
[2024-09-27T18:34:46.971+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:44.181292+00:00, run_end_date=2024-09-27 16:34:44.618601+00:00, run_duration=0.437309, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1827, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:41.264019+00:00, queued_by_job_id=1585, pid=331462
[2024-09-27T18:34:46.972+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:46.059590+00:00, run_end_date=2024-09-27 16:34:46.535644+00:00, run_duration=0.476054, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1828, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:41.264019+00:00, queued_by_job_id=1585, pid=331469
[2024-09-27T18:34:47.017+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:06:00+00:00, run_after=2023-09-27 19:07:00+00:00
[2024-09-27T18:34:47.046+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:04:00+00:00: scheduled__2023-09-27T19:04:00+00:00, state:running, queued_at: 2024-09-27 16:34:24.030264+00:00. externally triggered: False> successful
[2024-09-27T18:34:47.047+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:04:00+00:00, run_id=scheduled__2023-09-27T19:04:00+00:00, run_start_date=2024-09-27 16:34:24.049146+00:00, run_end_date=2024-09-27 16:34:47.047257+00:00, run_duration=22.998111, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:04:00+00:00, data_interval_end=2023-09-27 19:05:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:47.052+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:05:00+00:00, run_after=2023-09-27 19:06:00+00:00
[2024-09-27T18:34:47.065+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
[2024-09-27T18:34:47.065+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:47.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:47.066+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:05:00+00:00 [scheduled]>
[2024-09-27T18:34:47.068+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:47.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:47.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:47.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:47.070+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:47.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:48.064+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:48.159+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:49.124+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:50.078+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:50.163+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:51.152+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:51.153+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:51.159+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:48.197799+00:00, run_end_date=2024-09-27 16:34:48.723697+00:00, run_duration=0.525898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1829, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:47.067367+00:00, queued_by_job_id=1585, pid=331476
[2024-09-27T18:34:51.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:50.200478+00:00, run_end_date=2024-09-27 16:34:50.765697+00:00, run_duration=0.565219, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1830, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:47.067367+00:00, queued_by_job_id=1585, pid=331484
[2024-09-27T18:34:51.294+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:08:00+00:00, run_after=2023-09-27 19:09:00+00:00
[2024-09-27T18:34:51.331+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:05:00+00:00: scheduled__2023-09-27T19:05:00+00:00, state:running, queued_at: 2024-09-27 16:34:27.702163+00:00. externally triggered: False> successful
[2024-09-27T18:34:51.332+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:05:00+00:00, run_id=scheduled__2023-09-27T19:05:00+00:00, run_start_date=2024-09-27 16:34:27.719843+00:00, run_end_date=2024-09-27 16:34:51.331987+00:00, run_duration=23.612144, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:05:00+00:00, data_interval_end=2023-09-27 19:06:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:51.336+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:06:00+00:00, run_after=2023-09-27 19:07:00+00:00
[2024-09-27T18:34:51.345+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
[2024-09-27T18:34:51.346+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:51.346+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:51.346+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:06:00+00:00 [scheduled]>
[2024-09-27T18:34:51.347+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:51.347+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:51.347+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:51.348+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:51.348+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:51.351+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:52.261+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:52.346+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:53.356+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:54.305+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:54.395+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:55.266+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:55.267+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:55.273+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:52.383465+00:00, run_end_date=2024-09-27 16:34:52.918859+00:00, run_duration=0.535394, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1831, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:51.346806+00:00, queued_by_job_id=1585, pid=331492
[2024-09-27T18:34:55.274+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:54.432328+00:00, run_end_date=2024-09-27 16:34:54.904744+00:00, run_duration=0.472416, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1832, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:51.346806+00:00, queued_by_job_id=1585, pid=331500
[2024-09-27T18:34:55.319+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:07:00+00:00, run_after=2023-09-27 19:08:00+00:00
[2024-09-27T18:34:55.345+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:06:00+00:00: scheduled__2023-09-27T19:06:00+00:00, state:running, queued_at: 2024-09-27 16:34:35.063073+00:00. externally triggered: False> successful
[2024-09-27T18:34:55.346+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:06:00+00:00, run_id=scheduled__2023-09-27T19:06:00+00:00, run_start_date=2024-09-27 16:34:35.081285+00:00, run_end_date=2024-09-27 16:34:55.345981+00:00, run_duration=20.264696, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:06:00+00:00, data_interval_end=2023-09-27 19:07:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:34:55.350+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:07:00+00:00, run_after=2023-09-27 19:08:00+00:00
[2024-09-27T18:34:55.363+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:55.363+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:55.364+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:55.366+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:55.366+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:34:55.367+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:55.371+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:56.312+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:56.399+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:57.284+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:57.289+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:56.430593+00:00, run_end_date=2024-09-27 16:34:56.887213+00:00, run_duration=0.45662, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1833, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:34:55.365036+00:00, queued_by_job_id=1585, pid=331507
[2024-09-27T18:34:57.319+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:08:00+00:00, run_after=2023-09-27 19:09:00+00:00
[2024-09-27T18:34:57.353+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:57.353+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:57.353+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:57.354+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:57.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:34:57.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:57.358+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:58.329+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:34:58.418+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:34:59.622+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:34:59.628+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:34:58.454189+00:00, run_end_date=2024-09-27 16:34:59.206572+00:00, run_duration=0.752383, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1834, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:34:57.353983+00:00, queued_by_job_id=1585, pid=331514
[2024-09-27T18:34:59.654+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:09:00+00:00, run_after=2023-09-27 19:10:00+00:00
[2024-09-27T18:34:59.687+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:59.687+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:34:59.687+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:34:59.687+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:07:00+00:00 [scheduled]>
[2024-09-27T18:34:59.689+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:34:59.689+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:34:59.689+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:59.689+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:34:59.689+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:34:59.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:00.599+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:00.686+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:01.839+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:02.903+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:03.003+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:03.899+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:03.900+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:03.903+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:03.037857+00:00, run_end_date=2024-09-27 16:35:03.441771+00:00, run_duration=0.403914, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1836, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:34:59.688296+00:00, queued_by_job_id=1585, pid=331589
[2024-09-27T18:35:03.903+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:00.723235+00:00, run_end_date=2024-09-27 16:35:01.351138+00:00, run_duration=0.627903, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1835, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:34:59.688296+00:00, queued_by_job_id=1585, pid=331526
[2024-09-27T18:35:03.934+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:10:00+00:00, run_after=2023-09-27 19:11:00+00:00
[2024-09-27T18:35:03.972+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:07:00+00:00: scheduled__2023-09-27T19:07:00+00:00, state:running, queued_at: 2024-09-27 16:34:51.291425+00:00. externally triggered: False> successful
[2024-09-27T18:35:03.972+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:07:00+00:00, run_id=scheduled__2023-09-27T19:07:00+00:00, run_start_date=2024-09-27 16:34:51.304752+00:00, run_end_date=2024-09-27 16:35:03.972669+00:00, run_duration=12.667917, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:07:00+00:00, data_interval_end=2023-09-27 19:08:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:03.976+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:08:00+00:00, run_after=2023-09-27 19:09:00+00:00
[2024-09-27T18:35:03.990+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:03.991+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:03.991+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:03.992+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:03.994+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:03.995+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:03.995+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:03.995+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:03.996+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:03.999+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:04.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:05.049+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:05.765+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:06.734+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:06.819+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:08.511+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:08.512+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:08.518+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:05.086545+00:00, run_end_date=2024-09-27 16:35:05.393288+00:00, run_duration=0.306743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1837, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:03.992880+00:00, queued_by_job_id=1585, pid=331650
[2024-09-27T18:35:08.519+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:06.855374+00:00, run_end_date=2024-09-27 16:35:08.107643+00:00, run_duration=1.252269, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1838, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:03.992880+00:00, queued_by_job_id=1585, pid=331660
[2024-09-27T18:35:08.550+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:09:00+00:00, run_after=2023-09-27 19:10:00+00:00
[2024-09-27T18:35:08.591+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:08.591+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:08.591+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:08.592+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:08.593+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:08.593+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:08.593+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:08.593+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:08.593+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:08.597+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:09.519+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:09.609+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:10.902+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:11.834+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:11.924+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:13.310+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:13.310+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:13.316+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:09.647159+00:00, run_end_date=2024-09-27 16:35:10.521132+00:00, run_duration=0.873973, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1839, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:08.592464+00:00, queued_by_job_id=1585, pid=331667
[2024-09-27T18:35:13.317+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:11.960886+00:00, run_end_date=2024-09-27 16:35:12.894810+00:00, run_duration=0.933924, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1840, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:08.592464+00:00, queued_by_job_id=1585, pid=331674
[2024-09-27T18:35:13.373+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:10:00+00:00, run_after=2023-09-27 19:11:00+00:00
[2024-09-27T18:35:13.414+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:13.415+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:13.415+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:13.416+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:08:00+00:00 [scheduled]>
[2024-09-27T18:35:13.418+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:13.419+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:13.419+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:13.419+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:35:13.420+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:13.423+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:14.353+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:14.438+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:15.603+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:16.526+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:16.615+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:18.338+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:18.339+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:18.345+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:14.475942+00:00, run_end_date=2024-09-27 16:35:15.175593+00:00, run_duration=0.699651, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1841, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:13.417011+00:00, queued_by_job_id=1585, pid=331683
[2024-09-27T18:35:18.346+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:16.654038+00:00, run_end_date=2024-09-27 16:35:17.938068+00:00, run_duration=1.28403, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1842, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:35:13.417011+00:00, queued_by_job_id=1585, pid=331691
[2024-09-27T18:35:18.396+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:11:00+00:00, run_after=2023-09-27 19:12:00+00:00
[2024-09-27T18:35:18.434+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:08:00+00:00: scheduled__2023-09-27T19:08:00+00:00, state:running, queued_at: 2024-09-27 16:34:59.651744+00:00. externally triggered: False> successful
[2024-09-27T18:35:18.435+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:08:00+00:00, run_id=scheduled__2023-09-27T19:08:00+00:00, run_start_date=2024-09-27 16:34:59.668791+00:00, run_end_date=2024-09-27 16:35:18.435270+00:00, run_duration=18.766479, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:08:00+00:00, data_interval_end=2023-09-27 19:09:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:18.439+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:09:00+00:00, run_after=2023-09-27 19:10:00+00:00
[2024-09-27T18:35:18.453+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
[2024-09-27T18:35:18.454+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:18.454+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:18.454+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:09:00+00:00 [scheduled]>
[2024-09-27T18:35:18.457+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:09:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:18.458+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:18.458+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:18.458+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:35:18.459+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:18.462+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:19.393+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:19.477+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:20.807+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:21.738+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:21.822+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:23.259+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:23.259+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:23.265+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:21.858157+00:00, run_end_date=2024-09-27 16:35:22.855148+00:00, run_duration=0.996991, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1844, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:35:18.455901+00:00, queued_by_job_id=1585, pid=331706
[2024-09-27T18:35:23.266+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:19.513124+00:00, run_end_date=2024-09-27 16:35:20.396553+00:00, run_duration=0.883429, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1843, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:18.455901+00:00, queued_by_job_id=1585, pid=331698
[2024-09-27T18:35:23.410+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:12:00+00:00, run_after=2023-09-27 19:13:00+00:00
[2024-09-27T18:35:23.434+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:09:00+00:00: scheduled__2023-09-27T19:09:00+00:00, state:running, queued_at: 2024-09-27 16:35:03.931641+00:00. externally triggered: False> successful
[2024-09-27T18:35:23.434+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:09:00+00:00, run_id=scheduled__2023-09-27T19:09:00+00:00, run_start_date=2024-09-27 16:35:03.942864+00:00, run_end_date=2024-09-27 16:35:23.434466+00:00, run_duration=19.491602, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:09:00+00:00, data_interval_end=2023-09-27 19:10:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:23.436+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:10:00+00:00, run_after=2023-09-27 19:11:00+00:00
[2024-09-27T18:35:23.444+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:23.444+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:23.444+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:23.444+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:23.445+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:23.446+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:23.446+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:23.446+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:23.446+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:23.449+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:24.390+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:24.478+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:26.137+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:27.046+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:27.134+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:28.163+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:28.163+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:28.166+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:24.515428+00:00, run_end_date=2024-09-27 16:35:25.694803+00:00, run_duration=1.179375, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1845, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:23.445085+00:00, queued_by_job_id=1585, pid=331714
[2024-09-27T18:35:28.167+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:27.172069+00:00, run_end_date=2024-09-27 16:35:27.767554+00:00, run_duration=0.595485, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1846, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:23.445085+00:00, queued_by_job_id=1585, pid=331721
[2024-09-27T18:35:28.203+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:11:00+00:00, run_after=2023-09-27 19:12:00+00:00
[2024-09-27T18:35:28.224+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:28.224+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:28.224+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:28.225+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:28.226+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:28.226+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:28.226+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:28.226+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:28.226+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:28.231+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:29.190+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:29.277+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:30.264+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:31.233+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:31.319+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:32.220+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:32.220+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:32.226+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:29.314782+00:00, run_end_date=2024-09-27 16:35:29.820261+00:00, run_duration=0.505479, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1847, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:28.225395+00:00, queued_by_job_id=1585, pid=331729
[2024-09-27T18:35:32.227+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:31.356955+00:00, run_end_date=2024-09-27 16:35:31.838296+00:00, run_duration=0.481341, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1848, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:28.225395+00:00, queued_by_job_id=1585, pid=331750
[2024-09-27T18:35:32.258+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:12:00+00:00, run_after=2023-09-27 19:13:00+00:00
[2024-09-27T18:35:32.303+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:32.303+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:32.304+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:32.304+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:10:00+00:00 [scheduled]>
[2024-09-27T18:35:32.307+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:32.307+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:32.308+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:32.308+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:35:32.309+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:32.313+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:33.292+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:33.382+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:35.520+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:36.458+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:36.542+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:38.140+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:38.140+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:38.146+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:33.419732+00:00, run_end_date=2024-09-27 16:35:35.140401+00:00, run_duration=1.720669, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1849, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:32.305783+00:00, queued_by_job_id=1585, pid=331757
[2024-09-27T18:35:38.146+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:36.579364+00:00, run_end_date=2024-09-27 16:35:37.738130+00:00, run_duration=1.158766, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1850, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:35:32.305783+00:00, queued_by_job_id=1585, pid=331764
[2024-09-27T18:35:38.187+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:13:00+00:00, run_after=2023-09-27 19:14:00+00:00
[2024-09-27T18:35:38.208+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:10:00+00:00: scheduled__2023-09-27T19:10:00+00:00, state:running, queued_at: 2024-09-27 16:35:18.390135+00:00. externally triggered: False> successful
[2024-09-27T18:35:38.208+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:10:00+00:00, run_id=scheduled__2023-09-27T19:10:00+00:00, run_start_date=2024-09-27 16:35:18.407838+00:00, run_end_date=2024-09-27 16:35:38.208473+00:00, run_duration=19.800635, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:10:00+00:00, data_interval_end=2023-09-27 19:11:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:38.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:11:00+00:00, run_after=2023-09-27 19:12:00+00:00
[2024-09-27T18:35:38.217+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
[2024-09-27T18:35:38.217+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:38.217+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:38.218+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:11:00+00:00 [scheduled]>
[2024-09-27T18:35:38.219+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:12:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:38.219+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:38.219+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:38.219+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:35:38.219+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:38.222+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:39.144+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:39.230+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:40.344+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:41.281+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:41.366+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:42.268+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:42.269+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:42.274+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:39.267529+00:00, run_end_date=2024-09-27 16:35:39.953277+00:00, run_duration=0.685748, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1851, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:38.218468+00:00, queued_by_job_id=1585, pid=331779
[2024-09-27T18:35:42.275+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:41.397568+00:00, run_end_date=2024-09-27 16:35:41.894947+00:00, run_duration=0.497379, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1852, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:35:38.218468+00:00, queued_by_job_id=1585, pid=331786
[2024-09-27T18:35:42.302+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:12:00+00:00, run_after=2023-09-27 19:13:00+00:00
[2024-09-27T18:35:42.333+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:11:00+00:00: scheduled__2023-09-27T19:11:00+00:00, state:running, queued_at: 2024-09-27 16:35:23.403864+00:00. externally triggered: False> successful
[2024-09-27T18:35:42.334+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:11:00+00:00, run_id=scheduled__2023-09-27T19:11:00+00:00, run_start_date=2024-09-27 16:35:23.419003+00:00, run_end_date=2024-09-27 16:35:42.334344+00:00, run_duration=18.915341, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:11:00+00:00, data_interval_end=2023-09-27 19:12:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:42.339+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:12:00+00:00, run_after=2023-09-27 19:13:00+00:00
[2024-09-27T18:35:42.352+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:42.352+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:42.353+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:42.355+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:42.355+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:42.356+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:42.359+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:43.299+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:43.384+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:44.320+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:44.326+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:43.421220+00:00, run_end_date=2024-09-27 16:35:43.890247+00:00, run_duration=0.469027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1853, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:42.353768+00:00, queued_by_job_id=1585, pid=331802
[2024-09-27T18:35:44.370+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:13:00+00:00, run_after=2023-09-27 19:14:00+00:00
[2024-09-27T18:35:44.405+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:44.406+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:44.406+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:44.408+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:44.409+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:44.409+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:44.413+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:45.366+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:45.450+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:46.607+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:46.612+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:45.486799+00:00, run_end_date=2024-09-27 16:35:46.199382+00:00, run_duration=0.712583, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1854, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:44.407296+00:00, queued_by_job_id=1585, pid=331809
[2024-09-27T18:35:46.645+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:14:00+00:00, run_after=2023-09-27 19:15:00+00:00
[2024-09-27T18:35:46.697+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:46.698+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:46.698+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:46.699+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:12:00+00:00 [scheduled]>
[2024-09-27T18:35:46.701+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:46.702+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:46.702+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:46.703+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:35:46.703+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:46.707+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:47.638+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:47.723+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:48.649+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:49.582+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:49.669+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:50.697+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:50.697+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:50.702+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:47.760329+00:00, run_end_date=2024-09-27 16:35:48.272373+00:00, run_duration=0.512044, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1855, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:46.700277+00:00, queued_by_job_id=1585, pid=331816
[2024-09-27T18:35:50.703+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:49.706300+00:00, run_end_date=2024-09-27 16:35:50.295925+00:00, run_duration=0.589625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1856, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:35:46.700277+00:00, queued_by_job_id=1585, pid=331824
[2024-09-27T18:35:50.727+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:35:50.761+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:15:00+00:00, run_after=2023-09-27 19:16:00+00:00
[2024-09-27T18:35:50.783+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:12:00+00:00: scheduled__2023-09-27T19:12:00+00:00, state:running, queued_at: 2024-09-27 16:35:38.185025+00:00. externally triggered: False> successful
[2024-09-27T18:35:50.783+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:12:00+00:00, run_id=scheduled__2023-09-27T19:12:00+00:00, run_start_date=2024-09-27 16:35:38.195163+00:00, run_end_date=2024-09-27 16:35:50.783455+00:00, run_duration=12.588292, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:12:00+00:00, data_interval_end=2023-09-27 19:13:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:35:50.785+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:13:00+00:00, run_after=2023-09-27 19:14:00+00:00
[2024-09-27T18:35:50.792+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:35:50.793+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:50.793+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:50.793+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:35:50.794+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:50.794+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:50.794+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:50.794+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:50.795+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:50.798+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:51.729+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:51.814+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:52.900+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:53.837+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:53.921+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:54.962+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:54.963+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:35:54.969+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:53.958907+00:00, run_end_date=2024-09-27 16:35:54.560011+00:00, run_duration=0.601104, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1858, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:50.793694+00:00, queued_by_job_id=1585, pid=331839
[2024-09-27T18:35:54.970+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:51.849997+00:00, run_end_date=2024-09-27 16:35:52.486786+00:00, run_duration=0.636789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1857, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:50.793694+00:00, queued_by_job_id=1585, pid=331831
[2024-09-27T18:35:55.114+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:16:00+00:00, run_after=2023-09-27 19:17:00+00:00
[2024-09-27T18:35:55.154+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:35:55.155+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:35:55.155+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:35:55.155+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:35:55.156+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:35:55.158+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:35:55.158+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:35:55.159+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:55.159+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:35:55.159+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:55.160+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:35:55.160+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:55.163+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:56.096+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:56.181+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:35:58.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:35:59.077+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:35:59.161+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:00.537+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:01.481+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:01.567+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:02.479+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:02.479+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:02.479+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:02.486+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:01.608057+00:00, run_end_date=2024-09-27 16:36:02.046067+00:00, run_duration=0.43801, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1861, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:35:55.156947+00:00, queued_by_job_id=1585, pid=331863
[2024-09-27T18:36:02.487+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:59.196905+00:00, run_end_date=2024-09-27 16:36:00.160757+00:00, run_duration=0.963852, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1860, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:35:55.156947+00:00, queued_by_job_id=1585, pid=331855
[2024-09-27T18:36:02.487+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:35:56.216372+00:00, run_end_date=2024-09-27 16:35:57.768913+00:00, run_duration=1.552541, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1859, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:35:55.156947+00:00, queued_by_job_id=1585, pid=331847
[2024-09-27T18:36:02.543+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:17:00+00:00, run_after=2023-09-27 19:18:00+00:00
[2024-09-27T18:36:02.595+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:36:02.595+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:02.596+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:02.596+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:36:02.596+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:36:02.596+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:13:00+00:00 [scheduled]>
[2024-09-27T18:36:02.597+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:02.598+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:02.598+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:02.598+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:02.598+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:02.598+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:02.598+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:02.599+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:02.599+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:02.602+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:03.522+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:03.612+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:04.739+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:05.693+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:05.783+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:07.193+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:08.143+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:08.231+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:09.642+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:10.600+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:10.689+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:12.004+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:12.004+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:12.005+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:12.005+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:12.012+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:10.726440+00:00, run_end_date=2024-09-27 16:36:11.648754+00:00, run_duration=0.922314, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1865, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:02.597055+00:00, queued_by_job_id=1585, pid=331896
[2024-09-27T18:36:12.013+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:03.651503+00:00, run_end_date=2024-09-27 16:36:04.325101+00:00, run_duration=0.673598, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1862, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:02.597055+00:00, queued_by_job_id=1585, pid=331873
[2024-09-27T18:36:12.013+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:08.269047+00:00, run_end_date=2024-09-27 16:36:09.238268+00:00, run_duration=0.969221, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1864, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:02.597055+00:00, queued_by_job_id=1585, pid=331889
[2024-09-27T18:36:12.014+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:05.821881+00:00, run_end_date=2024-09-27 16:36:06.782003+00:00, run_duration=0.960122, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1863, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:02.597055+00:00, queued_by_job_id=1585, pid=331882
[2024-09-27T18:36:12.066+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:18:00+00:00, run_after=2023-09-27 19:19:00+00:00
[2024-09-27T18:36:12.119+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:13:00+00:00: scheduled__2023-09-27T19:13:00+00:00, state:running, queued_at: 2024-09-27 16:35:46.639128+00:00. externally triggered: False> successful
[2024-09-27T18:36:12.119+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:13:00+00:00, run_id=scheduled__2023-09-27T19:13:00+00:00, run_start_date=2024-09-27 16:35:46.662589+00:00, run_end_date=2024-09-27 16:36:12.119567+00:00, run_duration=25.456978, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:13:00+00:00, data_interval_end=2023-09-27 19:14:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:12.122+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:14:00+00:00, run_after=2023-09-27 19:15:00+00:00
[2024-09-27T18:36:12.129+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
[2024-09-27T18:36:12.130+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:12.130+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:12.130+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:36:12.130+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:36:12.130+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:14:00+00:00 [scheduled]>
[2024-09-27T18:36:12.132+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:12.132+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:12.132+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:12.132+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:12.132+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:12.132+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:12.133+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:12.133+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:12.133+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:12.136+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:13.063+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:13.147+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:14.265+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:15.201+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:15.286+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:16.726+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:17.661+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:17.746+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:18.834+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:19.766+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:19.850+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:20.915+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:20.916+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:20.916+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:20.916+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:20.923+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:13.184164+00:00, run_end_date=2024-09-27 16:36:13.849774+00:00, run_duration=0.66561, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1866, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:12.131227+00:00, queued_by_job_id=1585, pid=331904
[2024-09-27T18:36:20.924+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:15.322213+00:00, run_end_date=2024-09-27 16:36:16.305240+00:00, run_duration=0.983027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1867, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:12.131227+00:00, queued_by_job_id=1585, pid=331912
[2024-09-27T18:36:20.924+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:19.885917+00:00, run_end_date=2024-09-27 16:36:20.529594+00:00, run_duration=0.643677, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1869, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:12.131227+00:00, queued_by_job_id=1585, pid=331928
[2024-09-27T18:36:20.925+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:17.782994+00:00, run_end_date=2024-09-27 16:36:18.433532+00:00, run_duration=0.650538, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1868, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:12.131227+00:00, queued_by_job_id=1585, pid=331921
[2024-09-27T18:36:20.981+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:15:00+00:00, run_after=2023-09-27 19:16:00+00:00
[2024-09-27T18:36:21.018+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:14:00+00:00: scheduled__2023-09-27T19:14:00+00:00, state:running, queued_at: 2024-09-27 16:35:50.758589+00:00. externally triggered: False> successful
[2024-09-27T18:36:21.018+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:14:00+00:00, run_id=scheduled__2023-09-27T19:14:00+00:00, run_start_date=2024-09-27 16:35:50.768469+00:00, run_end_date=2024-09-27 16:36:21.018730+00:00, run_duration=30.250261, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:14:00+00:00, data_interval_end=2023-09-27 19:15:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:21.023+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:15:00+00:00, run_after=2023-09-27 19:16:00+00:00
[2024-09-27T18:36:21.037+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
[2024-09-27T18:36:21.037+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:21.038+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:21.038+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:36:21.038+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:15:00+00:00 [scheduled]>
[2024-09-27T18:36:21.041+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:15:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:21.041+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:21.041+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:21.041+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:21.041+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:21.041+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:21.042+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:21.044+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:21.975+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:22.059+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:23.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:24.028+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:24.113+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:25.031+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:25.962+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:26.047+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:27.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:27.079+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:27.079+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:27.086+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:22.095697+00:00, run_end_date=2024-09-27 16:36:22.713088+00:00, run_duration=0.617391, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1870, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:21.040152+00:00, queued_by_job_id=1585, pid=331937
[2024-09-27T18:36:27.086+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:24.149625+00:00, run_end_date=2024-09-27 16:36:24.603049+00:00, run_duration=0.453424, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1871, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:21.040152+00:00, queued_by_job_id=1585, pid=331944
[2024-09-27T18:36:27.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:26.084126+00:00, run_end_date=2024-09-27 16:36:26.665141+00:00, run_duration=0.581015, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1872, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:21.040152+00:00, queued_by_job_id=1585, pid=331951
[2024-09-27T18:36:27.246+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:19:00+00:00, run_after=2023-09-27 19:20:00+00:00
[2024-09-27T18:36:27.293+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:15:00+00:00: scheduled__2023-09-27T19:15:00+00:00, state:running, queued_at: 2024-09-27 16:35:55.107689+00:00. externally triggered: False> successful
[2024-09-27T18:36:27.293+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:15:00+00:00, run_id=scheduled__2023-09-27T19:15:00+00:00, run_start_date=2024-09-27 16:35:55.126298+00:00, run_end_date=2024-09-27 16:36:27.293564+00:00, run_duration=32.167266, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:15:00+00:00, data_interval_end=2023-09-27 19:16:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:27.298+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:16:00+00:00, run_after=2023-09-27 19:17:00+00:00
[2024-09-27T18:36:27.306+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
[2024-09-27T18:36:27.307+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:27.307+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:27.307+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:36:27.307+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:16:00+00:00 [scheduled]>
[2024-09-27T18:36:27.308+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:18:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:16:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:27.308+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:27.309+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:27.309+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:27.309+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:27.309+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:27.309+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:27.312+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:28.246+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:28.329+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:29.212+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:30.116+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:30.201+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:31.417+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:32.345+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:32.429+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:33.889+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:33.890+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:33.890+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:33.896+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:30.238715+00:00, run_end_date=2024-09-27 16:36:31.045162+00:00, run_duration=0.806447, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1874, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:27.307926+00:00, queued_by_job_id=1585, pid=331966
[2024-09-27T18:36:33.897+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:32.465662+00:00, run_end_date=2024-09-27 16:36:33.510036+00:00, run_duration=1.044374, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1875, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:27.307926+00:00, queued_by_job_id=1585, pid=331973
[2024-09-27T18:36:33.897+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:28.366289+00:00, run_end_date=2024-09-27 16:36:28.814887+00:00, run_duration=0.448598, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1873, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:27.307926+00:00, queued_by_job_id=1585, pid=331959
[2024-09-27T18:36:33.945+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:17:00+00:00, run_after=2023-09-27 19:18:00+00:00
[2024-09-27T18:36:33.977+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:16:00+00:00: scheduled__2023-09-27T19:16:00+00:00, state:running, queued_at: 2024-09-27 16:36:02.537551+00:00. externally triggered: False> successful
[2024-09-27T18:36:33.978+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:16:00+00:00, run_id=scheduled__2023-09-27T19:16:00+00:00, run_start_date=2024-09-27 16:36:02.555423+00:00, run_end_date=2024-09-27 16:36:33.978367+00:00, run_duration=31.422944, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:16:00+00:00, data_interval_end=2023-09-27 19:17:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:33.983+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:17:00+00:00, run_after=2023-09-27 19:18:00+00:00
[2024-09-27T18:36:33.996+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
[2024-09-27T18:36:33.996+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:33.996+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:33.997+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:17:00+00:00 [scheduled]>
[2024-09-27T18:36:33.999+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:18:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:17:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:34.000+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:34.000+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:34.001+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:34.001+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:34.004+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:34.915+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:35.006+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:36.136+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:37.092+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:37.177+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:38.530+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:38.531+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:38.537+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:37.213387+00:00, run_end_date=2024-09-27 16:36:38.116499+00:00, run_duration=0.903112, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1877, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:33.998164+00:00, queued_by_job_id=1585, pid=331987
[2024-09-27T18:36:38.537+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:35.042822+00:00, run_end_date=2024-09-27 16:36:35.695913+00:00, run_duration=0.653091, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1876, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:33.998164+00:00, queued_by_job_id=1585, pid=331980
[2024-09-27T18:36:38.564+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:18:00+00:00, run_after=2023-09-27 19:19:00+00:00
[2024-09-27T18:36:38.595+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:17:00+00:00: scheduled__2023-09-27T19:17:00+00:00, state:running, queued_at: 2024-09-27 16:36:12.059888+00:00. externally triggered: False> successful
[2024-09-27T18:36:38.596+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:17:00+00:00, run_id=scheduled__2023-09-27T19:17:00+00:00, run_start_date=2024-09-27 16:36:12.078217+00:00, run_end_date=2024-09-27 16:36:38.596488+00:00, run_duration=26.518271, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:17:00+00:00, data_interval_end=2023-09-27 19:18:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:38.601+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:18:00+00:00, run_after=2023-09-27 19:19:00+00:00
[2024-09-27T18:36:38.613+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
[2024-09-27T18:36:38.614+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:38.614+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
[2024-09-27T18:36:38.617+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:38.617+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:38.617+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:38.621+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:39.563+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:39.649+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:40.970+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:40.973+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:39.686066+00:00, run_end_date=2024-09-27 16:36:40.571907+00:00, run_duration=0.885841, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1878, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:38.615699+00:00, queued_by_job_id=1585, pid=331994
[2024-09-27T18:36:41.005+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:19:00+00:00, run_after=2023-09-27 19:20:00+00:00
[2024-09-27T18:36:41.022+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
[2024-09-27T18:36:41.023+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:41.023+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:18:00+00:00 [scheduled]>
[2024-09-27T18:36:41.024+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:41.024+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:41.024+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:41.027+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:41.959+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:42.043+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:43.438+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:43.443+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:42.080196+00:00, run_end_date=2024-09-27 16:36:43.028282+00:00, run_duration=0.948086, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1879, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:41.023520+00:00, queued_by_job_id=1585, pid=332001
[2024-09-27T18:36:43.479+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:20:00+00:00, run_after=2023-09-27 19:21:00+00:00
[2024-09-27T18:36:43.518+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:18:00+00:00: scheduled__2023-09-27T19:18:00+00:00, state:running, queued_at: 2024-09-27 16:36:27.240263+00:00. externally triggered: False> successful
[2024-09-27T18:36:43.519+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:18:00+00:00, run_id=scheduled__2023-09-27T19:18:00+00:00, run_start_date=2024-09-27 16:36:27.259846+00:00, run_end_date=2024-09-27 16:36:43.519101+00:00, run_duration=16.259255, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:18:00+00:00, data_interval_end=2023-09-27 19:19:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:36:43.523+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:19:00+00:00, run_after=2023-09-27 19:20:00+00:00
[2024-09-27T18:36:43.536+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:43.537+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:43.537+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:43.539+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:43.540+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:43.540+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:43.544+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:44.474+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:44.558+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:45.921+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:45.924+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:44.593556+00:00, run_end_date=2024-09-27 16:36:45.494758+00:00, run_duration=0.901202, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1880, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:43.538672+00:00, queued_by_job_id=1585, pid=332008
[2024-09-27T18:36:45.949+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:20:00+00:00, run_after=2023-09-27 19:21:00+00:00
[2024-09-27T18:36:45.971+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:45.971+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:45.972+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:45.972+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:45.973+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:45.973+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:45.977+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:46.909+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:46.994+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:48.155+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:48.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:47.030504+00:00, run_end_date=2024-09-27 16:36:47.738424+00:00, run_duration=0.70792, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1881, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:45.972310+00:00, queued_by_job_id=1585, pid=332019
[2024-09-27T18:36:48.197+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:21:00+00:00, run_after=2023-09-27 19:22:00+00:00
[2024-09-27T18:36:48.224+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:48.225+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:48.225+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:48.225+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:48.226+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:48.226+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:48.226+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:48.227+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:36:48.227+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:48.230+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:49.164+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:49.249+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:50.490+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:51.423+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:51.509+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:52.949+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:52.949+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:36:52.952+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:49.285731+00:00, run_end_date=2024-09-27 16:36:50.097115+00:00, run_duration=0.811384, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1882, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:48.225832+00:00, queued_by_job_id=1585, pid=332026
[2024-09-27T18:36:52.953+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:51.546639+00:00, run_end_date=2024-09-27 16:36:52.553725+00:00, run_duration=1.007086, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1883, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:36:48.225832+00:00, queued_by_job_id=1585, pid=332033
[2024-09-27T18:36:52.982+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:22:00+00:00, run_after=2023-09-27 19:23:00+00:00
[2024-09-27T18:36:53.041+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:53.042+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:36:53.042+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:36:53.043+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:36:53.043+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:19:00+00:00 [scheduled]>
[2024-09-27T18:36:53.046+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:36:53.047+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:36:53.047+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:53.047+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:36:53.048+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:53.048+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:36:53.049+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:53.052+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:53.986+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:54.072+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:56.015+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:56.945+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:57.029+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:36:58.194+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:36:59.137+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:36:59.224+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:00.621+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:00.622+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:00.622+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:00.625+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:54.108219+00:00, run_end_date=2024-09-27 16:36:55.626892+00:00, run_duration=1.518673, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1884, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:36:53.044858+00:00, queued_by_job_id=1585, pid=332047
[2024-09-27T18:37:00.625+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:57.065716+00:00, run_end_date=2024-09-27 16:36:57.775522+00:00, run_duration=0.709806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1885, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:36:53.044858+00:00, queued_by_job_id=1585, pid=332054
[2024-09-27T18:37:00.625+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:36:59.256549+00:00, run_end_date=2024-09-27 16:37:00.230695+00:00, run_duration=0.974146, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1886, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:36:53.044858+00:00, queued_by_job_id=1585, pid=332067
[2024-09-27T18:37:00.780+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:23:00+00:00, run_after=2023-09-27 19:24:00+00:00
[2024-09-27T18:37:00.825+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:19:00+00:00: scheduled__2023-09-27T19:19:00+00:00, state:running, queued_at: 2024-09-27 16:36:43.472986+00:00. externally triggered: False> successful
[2024-09-27T18:37:00.826+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:19:00+00:00, run_id=scheduled__2023-09-27T19:19:00+00:00, run_start_date=2024-09-27 16:36:43.495459+00:00, run_end_date=2024-09-27 16:37:00.825983+00:00, run_duration=17.330524, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:19:00+00:00, data_interval_end=2023-09-27 19:20:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:37:00.830+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:20:00+00:00, run_after=2023-09-27 19:21:00+00:00
[2024-09-27T18:37:00.838+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
[2024-09-27T18:37:00.839+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:37:00.839+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:37:00.839+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:37:00.839+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
[2024-09-27T18:37:00.840+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:20:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:37:00.841+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:37:00.841+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:00.841+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:37:00.841+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:00.841+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:37:00.841+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:00.844+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:01.773+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:01.859+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T19:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:05.233+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:06.163+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:06.247+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:07.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:08.630+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:08.717+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:10.473+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:10.474+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:10.474+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:10.480+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:06.283827+00:00, run_end_date=2024-09-27 16:37:07.296953+00:00, run_duration=1.013126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1888, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:37:00.839942+00:00, queued_by_job_id=1585, pid=332089
[2024-09-27T18:37:10.481+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:08.748833+00:00, run_end_date=2024-09-27 16:37:10.064906+00:00, run_duration=1.316073, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1889, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:37:00.839942+00:00, queued_by_job_id=1585, pid=332096
[2024-09-27T18:37:10.482+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T19:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:01.895990+00:00, run_end_date=2024-09-27 16:37:04.839523+00:00, run_duration=2.943533, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1887, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:37:00.839942+00:00, queued_by_job_id=1585, pid=332078
[2024-09-27T18:37:10.527+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:21:00+00:00, run_after=2023-09-27 19:22:00+00:00
[2024-09-27T18:37:10.573+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
[2024-09-27T18:37:10.573+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:37:10.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:37:10.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:37:10.575+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:20:00+00:00 [scheduled]>
[2024-09-27T18:37:10.577+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:20:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:37:10.578+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:37:10.578+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:10.579+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:37:10.579+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:10.579+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:37:10.580+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:10.584+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:11.522+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:11.607+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T19:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:12.934+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:13.858+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:13.942+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:15.356+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:16.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:16.371+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:17.844+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:17.844+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:17.845+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:17.851+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:13.979679+00:00, run_end_date=2024-09-27 16:37:14.979552+00:00, run_duration=0.999873, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1891, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:37:10.576155+00:00, queued_by_job_id=1585, pid=332113
[2024-09-27T18:37:17.852+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:16.405584+00:00, run_end_date=2024-09-27 16:37:17.434609+00:00, run_duration=1.029025, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1892, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:37:10.576155+00:00, queued_by_job_id=1585, pid=332121
[2024-09-27T18:37:17.852+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T19:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:11.642955+00:00, run_end_date=2024-09-27 16:37:12.512060+00:00, run_duration=0.869105, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1890, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:37:10.576155+00:00, queued_by_job_id=1585, pid=332103
[2024-09-27T18:37:17.899+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:22:00+00:00, run_after=2023-09-27 19:23:00+00:00
[2024-09-27T18:37:17.930+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:20:00+00:00: scheduled__2023-09-27T19:20:00+00:00, state:running, queued_at: 2024-09-27 16:36:48.194426+00:00. externally triggered: False> successful
[2024-09-27T18:37:17.931+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:20:00+00:00, run_id=scheduled__2023-09-27T19:20:00+00:00, run_start_date=2024-09-27 16:36:48.205124+00:00, run_end_date=2024-09-27 16:37:17.931017+00:00, run_duration=29.725893, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:20:00+00:00, data_interval_end=2023-09-27 19:21:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:37:17.935+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:21:00+00:00, run_after=2023-09-27 19:22:00+00:00
[2024-09-27T18:37:17.949+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
[2024-09-27T18:37:17.949+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:37:17.950+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:37:17.950+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:21:00+00:00 [scheduled]>
[2024-09-27T18:37:17.952+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:21:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:37:17.953+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:37:17.953+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:17.954+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:37:17.954+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:17.958+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:18.895+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:18.980+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T19:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:20.581+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:21.522+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:21.608+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:37:23.021+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:23.022+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:37:23.028+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T19:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:21.645050+00:00, run_end_date=2024-09-27 16:37:22.656356+00:00, run_duration=1.011306, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1894, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:37:17.951372+00:00, queued_by_job_id=1585, pid=332137
[2024-09-27T18:37:23.028+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T19:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:37:19.016851+00:00, run_end_date=2024-09-27 16:37:20.199129+00:00, run_duration=1.182278, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1893, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:37:17.951372+00:00, queued_by_job_id=1585, pid=332128
[2024-09-27T18:37:23.082+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:22:00+00:00, run_after=2023-09-27 19:23:00+00:00
[2024-09-27T18:37:23.106+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 19:21:00+00:00: scheduled__2023-09-27T19:21:00+00:00, state:running, queued_at: 2024-09-27 16:36:52.975656+00:00. externally triggered: False> successful
[2024-09-27T18:37:23.107+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 19:21:00+00:00, run_id=scheduled__2023-09-27T19:21:00+00:00, run_start_date=2024-09-27 16:36:52.999311+00:00, run_end_date=2024-09-27 16:37:23.107349+00:00, run_duration=30.108038, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 19:21:00+00:00, data_interval_end=2023-09-27 19:22:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:37:23.111+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 19:22:00+00:00, run_after=2023-09-27 19:23:00+00:00
[2024-09-27T18:37:23.124+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
[2024-09-27T18:37:23.125+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:37:23.125+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:22:00+00:00 [scheduled]>
[2024-09-27T18:37:23.127+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:22:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:37:23.128+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T19:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:37:23.128+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:23.132+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T19:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:37:24.066+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:37:24.150+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T19:22:00+00:00 [queued]> on host jf-hp
