  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2024-09-27T18:00:09.541+0200] {_client.py:1038} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.11&platform=Linux&arch=x86_64&database=sqlite&db_version=3.41&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2024-09-27T18:00:09.640+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-27 18:00:09 +0200] [320848] [INFO] Starting gunicorn 23.0.0
[2024-09-27 18:00:09 +0200] [320848] [INFO] Listening at: http://[::]:8793 (320848)
[2024-09-27 18:00:09 +0200] [320848] [INFO] Using worker: sync
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-27 18:00:09 +0200] [320849] [INFO] Booting worker with pid: 320849
[2024-09-27T18:00:09.673+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 320850
[2024-09-27T18:00:09.674+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:00:09.678+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T18:00:09.704+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27 18:00:09 +0200] [320851] [INFO] Booting worker with pid: 320851
[2024-09-27T18:00:10.054+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:10.090+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:36:00+00:00: scheduled__2023-09-27T16:36:00+00:00, state:running, queued_at: 2024-09-27 15:59:26.801901+00:00. externally triggered: False> successful
[2024-09-27T18:00:10.091+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:36:00+00:00, run_id=scheduled__2023-09-27T16:36:00+00:00, run_start_date=2024-09-27 15:59:26.811433+00:00, run_end_date=2024-09-27 16:00:10.091194+00:00, run_duration=43.279761, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:36:00+00:00, data_interval_end=2023-09-27 16:37:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:10.093+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:37:00+00:00, run_after=2023-09-27 16:38:00+00:00
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:10.108+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.109+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.113+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:11.049+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:11.133+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:24.302+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:25.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:25.283+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [queued]> on host jf-hp
%3|1727452839.445|FAIL|rdkafka#producer-1| [thrd:jf-hp:9092/0]: jf-hp:9092/0: Failed to connect to broker at [jf-hp]:9092: Invalid argument (after 1ms in state CONNECT)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.828+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:11.169956+00:00, run_end_date=2024-09-27 16:00:23.909924+00:00, run_duration=12.739968, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1231, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320854
[2024-09-27T18:00:40.829+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:25.321124+00:00, run_end_date=2024-09-27 16:00:40.464493+00:00, run_duration=15.143369, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320958
[2024-09-27T18:00:40.858+0200] {job.py:229} INFO - Heartbeat recovered after 31.22 seconds
[2024-09-27T18:00:41.108+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:41.150+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:37:00+00:00: scheduled__2023-09-27T16:37:00+00:00, state:running, queued_at: 2024-09-27 15:59:33.056378+00:00. externally triggered: False> successful
[2024-09-27T18:00:41.151+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:37:00+00:00, run_id=scheduled__2023-09-27T16:37:00+00:00, run_start_date=2024-09-27 15:59:33.074914+00:00, run_end_date=2024-09-27 16:00:41.151364+00:00, run_duration=68.07645, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:37:00+00:00, data_interval_end=2023-09-27 16:38:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:41.156+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:38:00+00:00, run_after=2023-09-27 16:39:00+00:00
[2024-09-27T18:00:41.171+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:41.176+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.176+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:41.177+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.180+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:42.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:42.222+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:43.789+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:44.731+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:44.815+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.375+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:42.258022+00:00, run_end_date=2024-09-27 16:00:43.367019+00:00, run_duration=1.108997, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1233, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320989
[2024-09-27T18:00:46.376+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:44.853399+00:00, run_end_date=2024-09-27 16:00:45.984008+00:00, run_duration=1.130609, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1234, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320996
[2024-09-27T18:00:46.415+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:46.450+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.456+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:47.393+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:47.481+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:49.021+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:49.936+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:50.023+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:51.013+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.014+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.017+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:47.519919+00:00, run_end_date=2024-09-27 16:00:48.638144+00:00, run_duration=1.118225, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1235, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321004
[2024-09-27T18:00:51.018+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:50.059503+00:00, run_end_date=2024-09-27 16:00:50.598692+00:00, run_duration=0.539189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321012
[2024-09-27T18:00:51.041+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:51.068+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:52.009+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:52.097+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:53.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:54.114+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:54.200+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:52.130572+00:00, run_end_date=2024-09-27 16:00:52.775268+00:00, run_duration=0.644696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1237, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321020
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:54.231509+00:00, run_end_date=2024-09-27 16:00:54.696955+00:00, run_duration=0.465446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321028
[2024-09-27T18:00:55.119+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:00:55.138+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:38:00+00:00: scheduled__2023-09-27T16:38:00+00:00, state:running, queued_at: 2024-09-27 16:00:09.963038+00:00. externally triggered: False> successful
[2024-09-27T18:00:55.139+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:38:00+00:00, run_id=scheduled__2023-09-27T16:38:00+00:00, run_start_date=2024-09-27 16:00:10.069389+00:00, run_end_date=2024-09-27 16:00:55.139032+00:00, run_duration=45.069643, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:38:00+00:00, data_interval_end=2023-09-27 16:39:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:55.140+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.149+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:56.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:56.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:56.952+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:57.865+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:57.951+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.994+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:56.223021+00:00, run_end_date=2024-09-27 16:00:56.539323+00:00, run_duration=0.316302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1239, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321035
[2024-09-27T18:00:58.995+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:57.988241+00:00, run_end_date=2024-09-27 16:00:58.590852+00:00, run_duration=0.602611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321043
[2024-09-27T18:00:59.026+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.056+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:39:00+00:00: scheduled__2023-09-27T16:39:00+00:00, state:running, queued_at: 2024-09-27 16:00:41.102400+00:00. externally triggered: False> successful
[2024-09-27T18:00:59.057+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:39:00+00:00, run_id=scheduled__2023-09-27T16:39:00+00:00, run_start_date=2024-09-27 16:00:41.120307+00:00, run_end_date=2024-09-27 16:00:59.057380+00:00, run_duration=17.937073, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:39:00+00:00, data_interval_end=2023-09-27 16:40:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:59.062+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.075+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:59.080+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:59.083+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:00.023+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:00.108+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:01.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:01.089+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:00.144130+00:00, run_end_date=2024-09-27 16:01:00.695583+00:00, run_duration=0.551453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1241, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:59.077213+00:00, queued_by_job_id=1230, pid=321050
[2024-09-27T18:01:01.136+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:01.168+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.171+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:01.172+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:01.172+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:01.177+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:02.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:02.195+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:03.237+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:03.242+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:02.231116+00:00, run_end_date=2024-09-27 16:01:02.810062+00:00, run_duration=0.578946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1242, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:01.170506+00:00, queued_by_job_id=1230, pid=321057
[2024-09-27T18:01:03.275+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:03.334+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.334+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:03.335+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.338+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:04.288+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:04.375+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:05.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:06.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:06.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:07.125+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.126+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:04.412683+00:00, run_end_date=2024-09-27 16:01:04.782143+00:00, run_duration=0.36946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1243, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321064
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:06.206428+00:00, run_end_date=2024-09-27 16:01:06.729709+00:00, run_duration=0.523281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321071
[2024-09-27T18:01:07.181+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:07.207+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:40:00+00:00: scheduled__2023-09-27T16:40:00+00:00, state:running, queued_at: 2024-09-27 16:00:55.116762+00:00. externally triggered: False> successful
[2024-09-27T18:01:07.207+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:40:00+00:00, run_id=scheduled__2023-09-27T16:40:00+00:00, run_start_date=2024-09-27 16:00:55.126133+00:00, run_end_date=2024-09-27 16:01:07.207457+00:00, run_duration=12.081324, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:40:00+00:00, data_interval_end=2023-09-27 16:41:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:07.209+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:07.217+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.221+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:08.160+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:08.245+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:09.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:10.115+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:10.205+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:11.416+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.417+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:10.242243+00:00, run_end_date=2024-09-27 16:01:11.033357+00:00, run_duration=0.791114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1246, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321085
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:08.281207+00:00, run_end_date=2024-09-27 16:01:08.747214+00:00, run_duration=0.466007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1245, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321078
[2024-09-27T18:01:11.684+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.717+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.721+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:12.641+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:12.726+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:14.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:15.028+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:15.116+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:16.371+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:17.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:17.423+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:18.279+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.284+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:17.459928+00:00, run_end_date=2024-09-27 16:01:17.889774+00:00, run_duration=0.429846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1249, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321112
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:15.152411+00:00, run_end_date=2024-09-27 16:01:15.950537+00:00, run_duration=0.798126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1248, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321105
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:12.763874+00:00, run_end_date=2024-09-27 16:01:13.715515+00:00, run_duration=0.951641, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1247, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321094
[2024-09-27T18:01:18.324+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:18.353+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:18.356+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.360+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:19.296+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:19.380+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:20.331+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:21.271+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:21.356+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:22.287+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:23.219+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:23.307+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:24.317+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:25.247+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:25.332+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:25.368857+00:00, run_end_date=2024-09-27 16:01:25.798744+00:00, run_duration=0.429887, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1253, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321142
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:23.343595+00:00, run_end_date=2024-09-27 16:01:23.949111+00:00, run_duration=0.605516, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1252, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321135
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:21.388362+00:00, run_end_date=2024-09-27 16:01:21.845540+00:00, run_duration=0.457178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1251, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321127
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:19.416874+00:00, run_end_date=2024-09-27 16:01:19.929931+00:00, run_duration=0.513057, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1250, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321120
[2024-09-27T18:01:26.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:26.236+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:41:00+00:00: scheduled__2023-09-27T16:41:00+00:00, state:running, queued_at: 2024-09-27 16:01:03.269464+00:00. externally triggered: False> successful
[2024-09-27T18:01:26.236+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:41:00+00:00, run_id=scheduled__2023-09-27T16:41:00+00:00, run_start_date=2024-09-27 16:01:03.293633+00:00, run_end_date=2024-09-27 16:01:26.236543+00:00, run_duration=22.94291, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:41:00+00:00, data_interval_end=2023-09-27 16:42:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:26.238+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.249+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.252+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:27.191+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:27.276+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:28.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:29.004+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:29.091+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:30.474+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:31.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:31.488+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:32.947+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:33.880+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:33.964+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:35.500+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.502+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.508+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:34.000142+00:00, run_end_date=2024-09-27 16:01:35.112254+00:00, run_duration=1.112112, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321171
[2024-09-27T18:01:35.509+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:31.524617+00:00, run_end_date=2024-09-27 16:01:32.552106+00:00, run_duration=1.027489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1256, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321163
[2024-09-27T18:01:35.510+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:29.129724+00:00, run_end_date=2024-09-27 16:01:30.091220+00:00, run_duration=0.961496, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1255, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321156
[2024-09-27T18:01:35.511+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:27.312630+00:00, run_end_date=2024-09-27 16:01:27.667440+00:00, run_duration=0.35481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1254, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321149
[2024-09-27T18:01:35.558+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.596+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:42:00+00:00: scheduled__2023-09-27T16:42:00+00:00, state:running, queued_at: 2024-09-27 16:01:07.174802+00:00. externally triggered: False> successful
[2024-09-27T18:01:35.596+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:42:00+00:00, run_id=scheduled__2023-09-27T16:42:00+00:00, run_start_date=2024-09-27 16:01:07.192486+00:00, run_end_date=2024-09-27 16:01:35.596636+00:00, run_duration=28.40415, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:42:00+00:00, data_interval_end=2023-09-27 16:43:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:35.601+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.615+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.619+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:35.620+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.625+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:36.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:36.660+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:38.191+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:39.130+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:39.216+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:40.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:41.146+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:41.232+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:42.150+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:41.270050+00:00, run_end_date=2024-09-27 16:01:41.768499+00:00, run_duration=0.498449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321193
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:39.252792+00:00, run_end_date=2024-09-27 16:01:39.790672+00:00, run_duration=0.53788, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1259, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321186
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:36.696688+00:00, run_end_date=2024-09-27 16:01:37.776911+00:00, run_duration=1.080223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1258, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321179
[2024-09-27T18:01:42.409+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:42.433+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:43:00+00:00: scheduled__2023-09-27T16:43:00+00:00, state:running, queued_at: 2024-09-27 16:01:11.678717+00:00. externally triggered: False> successful
[2024-09-27T18:01:42.434+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:43:00+00:00, run_id=scheduled__2023-09-27T16:43:00+00:00, run_start_date=2024-09-27 16:01:11.692882+00:00, run_end_date=2024-09-27 16:01:42.434151+00:00, run_duration=30.741269, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:43:00+00:00, data_interval_end=2023-09-27 16:44:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:42.436+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:42.448+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:42.450+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.454+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:42.454+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.458+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:43.389+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:43.473+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:44.960+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:45.899+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:45.983+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:47.400+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:48.351+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:48.436+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:49.445+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.452+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:43.508593+00:00, run_end_date=2024-09-27 16:01:44.541181+00:00, run_duration=1.032588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1261, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321201
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:48.471694+00:00, run_end_date=2024-09-27 16:01:49.059436+00:00, run_duration=0.587742, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321218
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:46.019008+00:00, run_end_date=2024-09-27 16:01:46.997770+00:00, run_duration=0.978762, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1262, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321208
[2024-09-27T18:01:49.500+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.530+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:44:00+00:00: scheduled__2023-09-27T16:44:00+00:00, state:running, queued_at: 2024-09-27 16:01:18.321308+00:00. externally triggered: False> successful
[2024-09-27T18:01:49.531+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:44:00+00:00, run_id=scheduled__2023-09-27T16:44:00+00:00, run_start_date=2024-09-27 16:01:18.330859+00:00, run_end_date=2024-09-27 16:01:49.531464+00:00, run_duration=31.200605, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:44:00+00:00, data_interval_end=2023-09-27 16:45:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:49.536+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.548+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:49.550+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.552+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:49.553+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:49.553+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.554+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:49.554+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.558+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:50.489+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:50.574+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:52.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:52.980+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:53.067+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:54.449+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.450+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.455+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:50.611511+00:00, run_end_date=2024-09-27 16:01:51.610045+00:00, run_duration=0.998534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1264, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321226
[2024-09-27T18:01:54.456+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:53.104035+00:00, run_end_date=2024-09-27 16:01:54.070098+00:00, run_duration=0.966063, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321233
[2024-09-27T18:01:54.481+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.500+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:45:00+00:00: scheduled__2023-09-27T16:45:00+00:00, state:running, queued_at: 2024-09-27 16:01:26.207749+00:00. externally triggered: False> successful
[2024-09-27T18:01:54.500+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:45:00+00:00, run_id=scheduled__2023-09-27T16:45:00+00:00, run_start_date=2024-09-27 16:01:26.217400+00:00, run_end_date=2024-09-27 16:01:54.500299+00:00, run_duration=28.282899, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:45:00+00:00, data_interval_end=2023-09-27 16:46:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:54.502+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.508+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:54.510+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:54.513+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:55.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:55.536+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:56.939+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:56.944+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:55.573830+00:00, run_end_date=2024-09-27 16:01:56.527711+00:00, run_duration=0.953881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1266, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:54.509734+00:00, queued_by_job_id=1230, pid=321240
[2024-09-27T18:01:56.988+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:57.022+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.025+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:57.026+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:57.026+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.030+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.974+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:58.060+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:58.984+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:58.986+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:58.096844+00:00, run_end_date=2024-09-27 16:01:58.620934+00:00, run_duration=0.52409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1267, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:57.024486+00:00, queued_by_job_id=1230, pid=321248
[2024-09-27T18:01:59.009+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:01:59.031+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:46:00+00:00: scheduled__2023-09-27T16:46:00+00:00, state:running, queued_at: 2024-09-27 16:01:42.403863+00:00. externally triggered: False> successful
[2024-09-27T18:01:59.032+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:46:00+00:00, run_id=scheduled__2023-09-27T16:46:00+00:00, run_start_date=2024-09-27 16:01:42.418716+00:00, run_end_date=2024-09-27 16:01:59.032147+00:00, run_duration=16.613431, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:46:00+00:00, data_interval_end=2023-09-27 16:47:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:59.034+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:59.043+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:59.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:00.001+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:00.088+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:00.973+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:00.976+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:00.127374+00:00, run_end_date=2024-09-27 16:02:00.574092+00:00, run_duration=0.446718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1268, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:59.041965+00:00, queued_by_job_id=1230, pid=321255
[2024-09-27T18:02:00.997+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:01.036+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.039+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:01.040+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:01.040+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.044+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:02.063+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:03.024+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:03.026+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:02.099888+00:00, run_end_date=2024-09-27 16:02:02.600638+00:00, run_duration=0.50075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1269, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:01.038262+00:00, queued_by_job_id=1230, pid=321262
[2024-09-27T18:02:03.061+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:03.093+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.098+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:04.037+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:04.120+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:05.127+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:06.077+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:06.164+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:07.042+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.043+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:06.200887+00:00, run_end_date=2024-09-27 16:02:06.635161+00:00, run_duration=0.434274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321276
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:04.156748+00:00, run_end_date=2024-09-27 16:02:04.738813+00:00, run_duration=0.582065, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1270, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321269
[2024-09-27T18:02:07.089+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:07.149+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:07.151+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:07.154+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.155+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:07.155+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:07.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.160+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:08.099+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:08.183+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:09.023+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:09.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:10.073+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:10.997+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:11.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:12.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.222+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.228+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:12.062263+00:00, run_end_date=2024-09-27 16:02:12.819921+00:00, run_duration=0.757658, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1274, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321311
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:08.219782+00:00, run_end_date=2024-09-27 16:02:08.603725+00:00, run_duration=0.383943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1272, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321283
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:10.110512+00:00, run_end_date=2024-09-27 16:02:10.589705+00:00, run_duration=0.479193, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1273, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321304
[2024-09-27T18:02:13.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:13.555+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:47:00+00:00: scheduled__2023-09-27T16:47:00+00:00, state:running, queued_at: 2024-09-27 16:01:59.006507+00:00. externally triggered: False> successful
[2024-09-27T18:02:13.555+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:47:00+00:00, run_id=scheduled__2023-09-27T16:47:00+00:00, run_start_date=2024-09-27 16:01:59.020753+00:00, run_end_date=2024-09-27 16:02:13.555749+00:00, run_duration=14.534996, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:47:00+00:00, data_interval_end=2023-09-27 16:48:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:13.560+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.570+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.574+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:14.507+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:14.592+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:15.711+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:16.671+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:16.758+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:17.734+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:18.650+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:18.735+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.214+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.219+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:16.796629+00:00, run_end_date=2024-09-27 16:02:17.337980+00:00, run_duration=0.541351, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1276, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321332
[2024-09-27T18:02:20.220+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:14.627720+00:00, run_end_date=2024-09-27 16:02:15.304761+00:00, run_duration=0.677041, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1275, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321324
[2024-09-27T18:02:20.221+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:18.771494+00:00, run_end_date=2024-09-27 16:02:19.860212+00:00, run_duration=1.088718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321340
[2024-09-27T18:02:20.260+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:20.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.291+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:21.229+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:21.315+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:22.763+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:23.726+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:23.814+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:25.142+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:26.078+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:26.163+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.362+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.364+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:23.851804+00:00, run_end_date=2024-09-27 16:02:24.767089+00:00, run_duration=0.915285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1279, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321354
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:21.352057+00:00, run_end_date=2024-09-27 16:02:22.348460+00:00, run_duration=0.996403, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1278, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321347
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:26.198707+00:00, run_end_date=2024-09-27 16:02:26.953479+00:00, run_duration=0.754772, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1280, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321361
[2024-09-27T18:02:27.398+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:27.412+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:48:00+00:00: scheduled__2023-09-27T16:48:00+00:00, state:running, queued_at: 2024-09-27 16:02:03.059191+00:00. externally triggered: False> successful
[2024-09-27T18:02:27.412+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:48:00+00:00, run_id=scheduled__2023-09-27T16:48:00+00:00, run_start_date=2024-09-27 16:02:03.069597+00:00, run_end_date=2024-09-27 16:02:27.412540+00:00, run_duration=24.342943, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:48:00+00:00, data_interval_end=2023-09-27 16:49:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:27.414+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:27.421+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:27.423+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:27.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.427+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:28.363+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:28.452+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:29.508+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:30.464+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:30.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:30.584070+00:00, run_end_date=2024-09-27 16:02:31.021926+00:00, run_duration=0.437856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321375
[2024-09-27T18:02:31.424+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:28.490216+00:00, run_end_date=2024-09-27 16:02:29.118875+00:00, run_duration=0.628659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1281, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321368
[2024-09-27T18:02:31.448+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.475+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:49:00+00:00: scheduled__2023-09-27T16:49:00+00:00, state:running, queued_at: 2024-09-27 16:02:07.082712+00:00. externally triggered: False> successful
[2024-09-27T18:02:31.476+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:49:00+00:00, run_id=scheduled__2023-09-27T16:49:00+00:00, run_start_date=2024-09-27 16:02:07.106532+00:00, run_end_date=2024-09-27 16:02:31.476405+00:00, run_duration=24.369873, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:49:00+00:00, data_interval_end=2023-09-27 16:50:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:31.480+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:31.494+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:31.497+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:31.500+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:32.434+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:32.518+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:33.595+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:33.600+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:32.553934+00:00, run_end_date=2024-09-27 16:02:33.167498+00:00, run_duration=0.613564, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1283, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:31.494879+00:00, queued_by_job_id=1230, pid=321382
[2024-09-27T18:02:33.643+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:33.661+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:50:00+00:00: scheduled__2023-09-27T16:50:00+00:00, state:running, queued_at: 2024-09-27 16:02:13.501328+00:00. externally triggered: False> successful
[2024-09-27T18:02:33.662+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:50:00+00:00, run_id=scheduled__2023-09-27T16:50:00+00:00, run_start_date=2024-09-27 16:02:13.520492+00:00, run_end_date=2024-09-27 16:02:33.662059+00:00, run_duration=20.141567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:50:00+00:00, data_interval_end=2023-09-27 16:51:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:33.666+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:34.709+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:34.740+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:34.742+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:35.675+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:35.764+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:36.640+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:36.645+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:35.802059+00:00, run_end_date=2024-09-27 16:02:36.255413+00:00, run_duration=0.453354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1284, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:34.739061+00:00, queued_by_job_id=1230, pid=321391
[2024-09-27T18:02:36.678+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:02:36.727+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:36.729+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.730+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:36.730+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.732+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:37.672+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:37.757+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:38.560+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:39.501+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:39.590+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.578+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:39.626476+00:00, run_end_date=2024-09-27 16:02:40.176226+00:00, run_duration=0.54975, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1286, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321406
[2024-09-27T18:02:40.579+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:37.793102+00:00, run_end_date=2024-09-27 16:02:38.146000+00:00, run_duration=0.352898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1285, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321398
[2024-09-27T18:02:40.616+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:40.648+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.650+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:41.591+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:41.677+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:42.921+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:43.875+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:43.961+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:45.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:46.147+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:46.231+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.352+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.359+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:46.267060+00:00, run_end_date=2024-09-27 16:02:46.939523+00:00, run_duration=0.672463, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1289, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321427
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:41.713006+00:00, run_end_date=2024-09-27 16:02:42.503726+00:00, run_duration=0.79072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1287, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321413
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:43.997504+00:00, run_end_date=2024-09-27 16:02:44.789012+00:00, run_duration=0.791508, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1288, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321420
[2024-09-27T18:02:47.618+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:02:47.680+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.685+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:47.686+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:47.686+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:47.687+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.688+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:48.631+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:48.715+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:50.123+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:51.068+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:51.152+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:52.561+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:53.502+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:53.588+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:55.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:56.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:56.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:57.094+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.096+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.102+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:56.206081+00:00, run_end_date=2024-09-27 16:02:56.671887+00:00, run_duration=0.465806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1293, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321464
[2024-09-27T18:02:57.103+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:51.190075+00:00, run_end_date=2024-09-27 16:02:52.129239+00:00, run_duration=0.939164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1291, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321444
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:48.751318+00:00, run_end_date=2024-09-27 16:02:49.704840+00:00, run_duration=0.953522, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1290, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321437
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:53.624750+00:00, run_end_date=2024-09-27 16:02:54.724797+00:00, run_duration=1.100047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1292, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321457
[2024-09-27T18:02:57.150+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:56:00+00:00, run_after=2023-09-27 16:57:00+00:00
[2024-09-27T18:02:57.202+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:51:00+00:00: scheduled__2023-09-27T16:51:00+00:00, state:running, queued_at: 2024-09-27 16:02:34.703538+00:00. externally triggered: False> successful
[2024-09-27T18:02:57.203+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:51:00+00:00, run_id=scheduled__2023-09-27T16:51:00+00:00, run_start_date=2024-09-27 16:02:34.722773+00:00, run_end_date=2024-09-27 16:02:57.203321+00:00, run_duration=22.480548, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:51:00+00:00, data_interval_end=2023-09-27 16:52:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:57.206+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:57.214+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:57.215+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.219+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:58.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:58.235+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:59.235+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:00.180+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:00.264+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:01.510+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:02.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:02.535+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:03.536+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:04.468+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:04.553+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:05.665+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.673+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:00.300429+00:00, run_end_date=2024-09-27 16:03:01.077587+00:00, run_duration=0.777158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1295, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321484
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:02.571693+00:00, run_end_date=2024-09-27 16:03:03.127994+00:00, run_duration=0.556301, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1296, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321496
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:58.270824+00:00, run_end_date=2024-09-27 16:02:58.823393+00:00, run_duration=0.552569, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1294, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321472
[2024-09-27T18:03:05.675+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:04.591123+00:00, run_end_date=2024-09-27 16:03:05.281462+00:00, run_duration=0.690339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321503
[2024-09-27T18:03:05.725+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.761+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:52:00+00:00: scheduled__2023-09-27T16:52:00+00:00, state:running, queued_at: 2024-09-27 16:02:36.672415+00:00. externally triggered: False> successful
[2024-09-27T18:03:05.762+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:52:00+00:00, run_id=scheduled__2023-09-27T16:52:00+00:00, run_start_date=2024-09-27 16:02:36.695113+00:00, run_end_date=2024-09-27 16:03:05.762096+00:00, run_duration=29.066983, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:52:00+00:00, data_interval_end=2023-09-27 16:53:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:05.766+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.780+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:05.782+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.786+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.787+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:05.787+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.791+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:06.729+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:06.813+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:08.983+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:09.925+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:10.009+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:10.968+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:11.903+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:11.987+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:12.857+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.858+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.858+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:12.864+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:10.044368+00:00, run_end_date=2024-09-27 16:03:10.569530+00:00, run_duration=0.525162, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1299, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321527
[2024-09-27T18:03:12.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:12.023313+00:00, run_end_date=2024-09-27 16:03:12.461247+00:00, run_duration=0.437934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1300, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321535
[2024-09-27T18:03:12.865+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:06.849119+00:00, run_end_date=2024-09-27 16:03:08.566063+00:00, run_duration=1.716944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1298, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:05.783405+00:00, queued_by_job_id=1230, pid=321510
[2024-09-27T18:03:12.900+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:03:12.914+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:53:00+00:00: scheduled__2023-09-27T16:53:00+00:00, state:running, queued_at: 2024-09-27 16:02:40.613989+00:00. externally triggered: False> successful
[2024-09-27T18:03:12.914+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:53:00+00:00, run_id=scheduled__2023-09-27T16:53:00+00:00, run_start_date=2024-09-27 16:02:40.623530+00:00, run_end_date=2024-09-27 16:03:12.914637+00:00, run_duration=32.291107, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:53:00+00:00, data_interval_end=2023-09-27 16:54:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:12.916+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:12.923+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
[2024-09-27T18:03:12.924+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:12.925+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:12.925+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:12.925+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:12.925+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:12.928+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:13.873+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:13.958+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:14.877+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:15.818+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:15.903+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:16.893+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:16.894+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:16.899+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:15.940298+00:00, run_end_date=2024-09-27 16:03:16.478366+00:00, run_duration=0.538068, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1302, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:12.924048+00:00, queued_by_job_id=1230, pid=321557
[2024-09-27T18:03:16.900+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:13.996214+00:00, run_end_date=2024-09-27 16:03:14.480859+00:00, run_duration=0.484645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1301, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:12.924048+00:00, queued_by_job_id=1230, pid=321547
[2024-09-27T18:03:16.929+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:03:16.957+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:54:00+00:00: scheduled__2023-09-27T16:54:00+00:00, state:running, queued_at: 2024-09-27 16:02:47.611960+00:00. externally triggered: False> successful
[2024-09-27T18:03:16.958+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:54:00+00:00, run_id=scheduled__2023-09-27T16:54:00+00:00, run_start_date=2024-09-27 16:02:47.630690+00:00, run_end_date=2024-09-27 16:03:16.957983+00:00, run_duration=29.327293, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:54:00+00:00, data_interval_end=2023-09-27 16:55:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:16.962+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:16.970+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
[2024-09-27T18:03:16.971+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:16.971+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:16.971+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:16.976+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:17.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:17.997+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:18.903+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:18.909+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:18.033561+00:00, run_end_date=2024-09-27 16:03:18.520742+00:00, run_duration=0.487181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1303, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:16.970905+00:00, queued_by_job_id=1230, pid=321564
[2024-09-27T18:03:19.157+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:19.174+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:55:00+00:00: scheduled__2023-09-27T16:55:00+00:00, state:running, queued_at: 2024-09-27 16:02:57.144473+00:00. externally triggered: False> successful
[2024-09-27T18:03:19.174+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:55:00+00:00, run_id=scheduled__2023-09-27T16:55:00+00:00, run_start_date=2024-09-27 16:02:57.163032+00:00, run_end_date=2024-09-27 16:03:19.174770+00:00, run_duration=22.011738, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:55:00+00:00, data_interval_end=2023-09-27 16:56:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:19.176+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:56:00+00:00, run_after=2023-09-27 16:57:00+00:00
[2024-09-27T18:03:19.183+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:19.183+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:19.184+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:19.184+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:19.185+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:19.185+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:19.187+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:20.124+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:20.210+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:21.064+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:21.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:20.245595+00:00, run_end_date=2024-09-27 16:03:20.666926+00:00, run_duration=0.421331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1304, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:19.184311+00:00, queued_by_job_id=1230, pid=321573
[2024-09-27T18:03:21.092+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:21.114+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:21.115+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:21.115+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:21.116+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:21.116+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:21.116+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:21.119+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:22.055+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:22.142+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:23.145+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:23.149+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:22.178762+00:00, run_end_date=2024-09-27 16:03:22.745310+00:00, run_duration=0.566548, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1305, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:21.115742+00:00, queued_by_job_id=1230, pid=321580
[2024-09-27T18:03:23.172+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:23.204+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:23.205+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:23.206+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:23.206+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:23.206+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:23.206+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:23.209+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:24.142+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:24.226+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:25.228+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:26.159+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:26.244+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:27.156+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:27.157+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:27.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:26.280605+00:00, run_end_date=2024-09-27 16:03:26.751778+00:00, run_duration=0.471173, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1307, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:23.205169+00:00, queued_by_job_id=1230, pid=321595
[2024-09-27T18:03:27.160+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:24.261713+00:00, run_end_date=2024-09-27 16:03:24.816252+00:00, run_duration=0.554539, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1306, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:23.205169+00:00, queued_by_job_id=1230, pid=321587
[2024-09-27T18:03:27.197+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:27.229+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:27.230+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>
[2024-09-27T18:03:27.231+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:27.231+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.232+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.232+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:27.232+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:27.235+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:28.165+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:28.249+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:29.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:30.179+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:30.270+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:31.749+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:32.716+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:32.802+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:33.673+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.673+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.674+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:33.679+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:32.842362+00:00, run_end_date=2024-09-27 16:03:33.279610+00:00, run_duration=0.437248, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1310, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321630
[2024-09-27T18:03:33.680+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:30.305539+00:00, run_end_date=2024-09-27 16:03:31.346864+00:00, run_duration=1.041325, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1309, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321623
[2024-09-27T18:03:33.681+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:28.285408+00:00, run_end_date=2024-09-27 16:03:28.855428+00:00, run_duration=0.57002, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1308, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:27.230896+00:00, queued_by_job_id=1230, pid=321602
[2024-09-27T18:03:33.728+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:33.775+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:56:00+00:00: scheduled__2023-09-27T16:56:00+00:00, state:running, queued_at: 2024-09-27 16:03:19.154884+00:00. externally triggered: False> successful
[2024-09-27T18:03:33.775+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:56:00+00:00, run_id=scheduled__2023-09-27T16:56:00+00:00, run_start_date=2024-09-27 16:03:19.163872+00:00, run_end_date=2024-09-27 16:03:33.775825+00:00, run_duration=14.611953, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:56:00+00:00, data_interval_end=2023-09-27 16:57:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:33.780+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:57:00+00:00, run_after=2023-09-27 16:58:00+00:00
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:33.790+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:33.791+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.792+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:33.792+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:33.795+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:34.732+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:34.817+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:35.728+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:36.661+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:36.746+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:38.051+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:38.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:39.072+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:40.065+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.065+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.066+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:40.072+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:34.852581+00:00, run_end_date=2024-09-27 16:03:35.343143+00:00, run_duration=0.490562, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1311, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321638
[2024-09-27T18:03:40.073+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:39.109605+00:00, run_end_date=2024-09-27 16:03:39.664335+00:00, run_duration=0.55473, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1313, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321654
[2024-09-27T18:03:40.073+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:36.782625+00:00, run_end_date=2024-09-27 16:03:37.655222+00:00, run_duration=0.872597, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1312, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:33.791229+00:00, queued_by_job_id=1230, pid=321645
[2024-09-27T18:03:40.122+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:40.163+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:40.164+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:40.165+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.165+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:40.165+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:40.166+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:40.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:41.106+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:41.191+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:42.232+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:43.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:43.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:44.817+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:45.748+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:45.832+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:47.191+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.192+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.192+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:47.198+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:41.226772+00:00, run_end_date=2024-09-27 16:03:41.832417+00:00, run_duration=0.605645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1314, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321661
[2024-09-27T18:03:47.199+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:45.870655+00:00, run_end_date=2024-09-27 16:03:46.773385+00:00, run_duration=0.90273, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1316, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321676
[2024-09-27T18:03:47.200+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:43.293026+00:00, run_end_date=2024-09-27 16:03:44.417799+00:00, run_duration=1.124773, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1315, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:40.164438+00:00, queued_by_job_id=1230, pid=321668
[2024-09-27T18:03:47.242+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:47.273+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:57:00+00:00: scheduled__2023-09-27T16:57:00+00:00, state:running, queued_at: 2024-09-27 16:03:23.170016+00:00. externally triggered: False> successful
[2024-09-27T18:03:47.274+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:57:00+00:00, run_id=scheduled__2023-09-27T16:57:00+00:00, run_start_date=2024-09-27 16:03:23.185504+00:00, run_end_date=2024-09-27 16:03:47.274334+00:00, run_duration=24.08883, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:57:00+00:00, data_interval_end=2023-09-27 16:58:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:47.279+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:58:00+00:00, run_after=2023-09-27 16:59:00+00:00
[2024-09-27T18:03:47.293+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
[2024-09-27T18:03:47.293+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:47.294+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:47.294+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>
[2024-09-27T18:03:47.297+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:47.298+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:47.298+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:47.299+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:47.299+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:47.304+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:48.242+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:48.330+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:49.375+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:50.307+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:50.391+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:51.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:51.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:51.271+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:48.367343+00:00, run_end_date=2024-09-27 16:03:48.971999+00:00, run_duration=0.604656, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1317, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:47.295692+00:00, queued_by_job_id=1230, pid=321684
[2024-09-27T18:03:51.272+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:50.427638+00:00, run_end_date=2024-09-27 16:03:50.871079+00:00, run_duration=0.443441, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1318, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:47.295692+00:00, queued_by_job_id=1230, pid=321692
[2024-09-27T18:03:51.528+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:03:51.566+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:58:00+00:00: scheduled__2023-09-27T16:58:00+00:00, state:running, queued_at: 2024-09-27 16:03:27.194821+00:00. externally triggered: False> successful
[2024-09-27T18:03:51.567+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:58:00+00:00, run_id=scheduled__2023-09-27T16:58:00+00:00, run_start_date=2024-09-27 16:03:27.205174+00:00, run_end_date=2024-09-27 16:03:51.567295+00:00, run_duration=24.362121, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:58:00+00:00, data_interval_end=2023-09-27 16:59:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:51.571+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:59:00+00:00, run_after=2023-09-27 17:00:00+00:00
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:51.581+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>
[2024-09-27T18:03:51.582+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:51.582+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:03:51.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:51.583+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:51.583+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:51.587+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:52.529+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:52.614+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:54.058+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:54.997+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:55.081+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:56.523+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:56.524+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:56.530+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:52.650083+00:00, run_end_date=2024-09-27 16:03:53.637710+00:00, run_duration=0.987627, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1319, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:03:51.582032+00:00, queued_by_job_id=1230, pid=321700
[2024-09-27T18:03:56.530+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:55.117764+00:00, run_end_date=2024-09-27 16:03:56.096587+00:00, run_duration=0.978823, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1320, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:03:51.582032+00:00, queued_by_job_id=1230, pid=321707
[2024-09-27T18:03:56.579+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:56.605+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:59:00+00:00: scheduled__2023-09-27T16:59:00+00:00, state:running, queued_at: 2024-09-27 16:03:33.722171+00:00. externally triggered: False> successful
[2024-09-27T18:03:56.605+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:59:00+00:00, run_id=scheduled__2023-09-27T16:59:00+00:00, run_start_date=2024-09-27 16:03:33.740652+00:00, run_end_date=2024-09-27 16:03:56.605781+00:00, run_duration=22.865129, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:59:00+00:00, data_interval_end=2023-09-27 17:00:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:56.610+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:00:00+00:00, run_after=2023-09-27 17:01:00+00:00
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:56.623+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:56.625+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:56.626+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:56.626+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:56.630+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:57.566+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:57.650+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:59.054+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:59.059+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:57.687170+00:00, run_end_date=2024-09-27 16:03:58.655177+00:00, run_duration=0.968007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1321, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:03:56.624633+00:00, queued_by_job_id=1230, pid=321714
[2024-09-27T18:03:59.086+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:03:59.126+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:59.126+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:59.127+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:03:59.129+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:59.129+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:59.129+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:59.132+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:00.075+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:00.161+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:01.084+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:01.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:00.198572+00:00, run_end_date=2024-09-27 16:04:00.684453+00:00, run_duration=0.485881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1322, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:03:59.127975+00:00, queued_by_job_id=1230, pid=321722
[2024-09-27T18:04:01.111+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:01.161+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:04:01.162+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:01.162+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:01.163+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>
[2024-09-27T18:04:01.165+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:01.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:01.166+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:01.166+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:01.167+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:01.170+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:02.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:02.195+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:03.238+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:04.181+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:04.267+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:05.169+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:05.169+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:05.172+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:04.304658+00:00, run_end_date=2024-09-27 16:04:04.768478+00:00, run_duration=0.46382, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1324, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:01.163971+00:00, queued_by_job_id=1230, pid=321736
[2024-09-27T18:04:05.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:02.230774+00:00, run_end_date=2024-09-27 16:04:02.819570+00:00, run_duration=0.588796, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1323, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:01.163971+00:00, queued_by_job_id=1230, pid=321729
[2024-09-27T18:04:05.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:05.230+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:00:00+00:00: scheduled__2023-09-27T17:00:00+00:00, state:running, queued_at: 2024-09-27 16:03:51.522468+00:00. externally triggered: False> successful
[2024-09-27T18:04:05.231+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:00:00+00:00, run_id=scheduled__2023-09-27T17:00:00+00:00, run_start_date=2024-09-27 16:03:51.539903+00:00, run_end_date=2024-09-27 16:04:05.231061+00:00, run_duration=13.691158, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:00:00+00:00, data_interval_end=2023-09-27 17:01:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:05.232+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:01:00+00:00, run_after=2023-09-27 17:02:00+00:00
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:05.240+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:05.241+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:05.242+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:05.242+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:05.242+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:05.242+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:05.245+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:06.182+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:06.267+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:07.185+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:08.126+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:08.211+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:09.130+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:09.131+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:09.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:06.302517+00:00, run_end_date=2024-09-27 16:04:06.768876+00:00, run_duration=0.466359, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1325, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:05.241066+00:00, queued_by_job_id=1230, pid=321743
[2024-09-27T18:04:09.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:08.246976+00:00, run_end_date=2024-09-27 16:04:08.731690+00:00, run_duration=0.484714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1326, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:05.241066+00:00, queued_by_job_id=1230, pid=321750
[2024-09-27T18:04:09.165+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:09.211+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:09.212+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:09.212+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:09.213+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:09.215+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:09.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:09.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:09.217+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:09.217+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:09.221+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:10.158+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:10.242+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:11.544+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:12.476+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:12.560+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:14.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:14.244+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:14.250+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:10.278284+00:00, run_end_date=2024-09-27 16:04:11.158800+00:00, run_duration=0.880516, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1327, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:09.214316+00:00, queued_by_job_id=1230, pid=321757
[2024-09-27T18:04:14.251+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:12.596437+00:00, run_end_date=2024-09-27 16:04:13.821377+00:00, run_duration=1.22494, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1328, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:09.214316+00:00, queued_by_job_id=1230, pid=321764
[2024-09-27T18:04:14.286+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:14.310+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:14.311+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:14.311+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:14.312+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>
[2024-09-27T18:04:14.314+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:14.315+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:14.315+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:14.315+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:14.316+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:14.319+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:15.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:15.336+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:16.405+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:17.312+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:17.396+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:19.238+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:19.238+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:19.244+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:15.372293+00:00, run_end_date=2024-09-27 16:04:15.997514+00:00, run_duration=0.625221, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1329, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:14.313113+00:00, queued_by_job_id=1230, pid=321777
[2024-09-27T18:04:19.245+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:17.433254+00:00, run_end_date=2024-09-27 16:04:18.843764+00:00, run_duration=1.41051, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:14.313113+00:00, queued_by_job_id=1230, pid=321784
[2024-09-27T18:04:19.291+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:19.335+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:01:00+00:00: scheduled__2023-09-27T17:01:00+00:00, state:running, queued_at: 2024-09-27 16:04:01.108435+00:00. externally triggered: False> successful
[2024-09-27T18:04:19.336+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:01:00+00:00, run_id=scheduled__2023-09-27T17:01:00+00:00, run_start_date=2024-09-27 16:04:01.126953+00:00, run_end_date=2024-09-27 16:04:19.336053+00:00, run_duration=18.2091, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:01:00+00:00, data_interval_end=2023-09-27 17:02:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:19.340+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:02:00+00:00, run_after=2023-09-27 17:03:00+00:00
[2024-09-27T18:04:19.355+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
[2024-09-27T18:04:19.356+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:19.356+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:19.357+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>
[2024-09-27T18:04:19.359+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:19.360+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:19.360+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:19.361+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:19.361+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:19.365+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:20.302+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:20.386+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:21.716+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:22.649+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:22.735+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:24.147+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:24.147+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:24.153+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:20.422176+00:00, run_end_date=2024-09-27 16:04:21.303718+00:00, run_duration=0.881542, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1331, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:19.358220+00:00, queued_by_job_id=1230, pid=321792
[2024-09-27T18:04:24.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:22.772458+00:00, run_end_date=2024-09-27 16:04:23.760327+00:00, run_duration=0.987869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1332, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:19.358220+00:00, queued_by_job_id=1230, pid=321799
[2024-09-27T18:04:24.311+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:24.352+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:02:00+00:00: scheduled__2023-09-27T17:02:00+00:00, state:running, queued_at: 2024-09-27 16:04:05.207406+00:00. externally triggered: False> successful
[2024-09-27T18:04:24.353+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:02:00+00:00, run_id=scheduled__2023-09-27T17:02:00+00:00, run_start_date=2024-09-27 16:04:05.217062+00:00, run_end_date=2024-09-27 16:04:24.353364+00:00, run_duration=19.136302, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:02:00+00:00, data_interval_end=2023-09-27 17:03:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:24.358+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:03:00+00:00, run_after=2023-09-27 17:04:00+00:00
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:24.368+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:24.369+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:24.369+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:24.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:24.370+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:24.370+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:24.373+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:25.306+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:25.390+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:26.310+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:27.243+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:27.329+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:28.371+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:28.372+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:28.377+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:27.365508+00:00, run_end_date=2024-09-27 16:04:27.990839+00:00, run_duration=0.625331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1334, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:24.369049+00:00, queued_by_job_id=1230, pid=321814
[2024-09-27T18:04:28.378+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:25.426667+00:00, run_end_date=2024-09-27 16:04:25.910489+00:00, run_duration=0.483822, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1333, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:24.369049+00:00, queued_by_job_id=1230, pid=321807
[2024-09-27T18:04:28.408+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:28.455+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:28.456+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:28.456+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:28.457+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:28.459+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:28.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:28.460+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:28.460+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:28.461+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:28.464+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:29.426+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:29.516+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:30.526+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:31.423+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:31.512+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:32.428+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:32.429+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:32.435+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:31.550071+00:00, run_end_date=2024-09-27 16:04:32.042463+00:00, run_duration=0.492392, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1336, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:28.458064+00:00, queued_by_job_id=1230, pid=321842
[2024-09-27T18:04:32.435+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:29.552508+00:00, run_end_date=2024-09-27 16:04:30.081959+00:00, run_duration=0.529451, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1335, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:28.458064+00:00, queued_by_job_id=1230, pid=321835
[2024-09-27T18:04:32.486+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:32.528+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:32.529+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>
[2024-09-27T18:04:32.532+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:32.532+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:32.533+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:32.533+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:32.534+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:32.538+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:33.470+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:33.556+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:34.491+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:35.407+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:35.491+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:37.092+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:37.093+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:37.098+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:35.528701+00:00, run_end_date=2024-09-27 16:04:36.668061+00:00, run_duration=1.13936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1338, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:32.530863+00:00, queued_by_job_id=1230, pid=321857
[2024-09-27T18:04:37.099+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:33.592474+00:00, run_end_date=2024-09-27 16:04:34.067912+00:00, run_duration=0.475438, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1337, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:32.530863+00:00, queued_by_job_id=1230, pid=321850
[2024-09-27T18:04:37.132+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:37.176+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:03:00+00:00: scheduled__2023-09-27T17:03:00+00:00, state:running, queued_at: 2024-09-27 16:04:19.285092+00:00. externally triggered: False> successful
[2024-09-27T18:04:37.177+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:03:00+00:00, run_id=scheduled__2023-09-27T17:03:00+00:00, run_start_date=2024-09-27 16:04:19.307910+00:00, run_end_date=2024-09-27 16:04:37.177283+00:00, run_duration=17.869373, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:03:00+00:00, data_interval_end=2023-09-27 17:04:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:37.181+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:04:00+00:00, run_after=2023-09-27 17:05:00+00:00
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:37.190+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:37.191+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:37.192+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:37.192+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:37.192+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:37.195+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:38.130+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:38.214+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:39.103+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:40.052+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:40.137+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:41.187+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:41.188+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:41.193+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:38.249890+00:00, run_end_date=2024-09-27 16:04:38.704003+00:00, run_duration=0.454113, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1339, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:37.191355+00:00, queued_by_job_id=1230, pid=321864
[2024-09-27T18:04:41.194+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:40.175117+00:00, run_end_date=2024-09-27 16:04:40.799953+00:00, run_duration=0.624836, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1340, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:37.191355+00:00, queued_by_job_id=1230, pid=321871
[2024-09-27T18:04:41.234+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:41.261+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:04:00+00:00: scheduled__2023-09-27T17:04:00+00:00, state:running, queued_at: 2024-09-27 16:04:24.305586+00:00. externally triggered: False> successful
[2024-09-27T18:04:41.261+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:04:00+00:00, run_id=scheduled__2023-09-27T17:04:00+00:00, run_start_date=2024-09-27 16:04:24.323633+00:00, run_end_date=2024-09-27 16:04:41.261482+00:00, run_duration=16.937849, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:04:00+00:00, data_interval_end=2023-09-27 17:05:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:41.266+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:05:00+00:00, run_after=2023-09-27 17:06:00+00:00
[2024-09-27T18:04:41.279+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:41.279+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:41.280+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:41.282+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:41.282+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:41.282+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:41.286+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:42.236+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:42.333+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:43.410+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:43.415+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:42.372853+00:00, run_end_date=2024-09-27 16:04:43.018405+00:00, run_duration=0.645552, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1341, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:41.280746+00:00, queued_by_job_id=1230, pid=321878
[2024-09-27T18:04:43.443+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:43.481+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:43.482+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:43.482+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:43.484+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:43.484+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:43.485+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:43.488+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:44.426+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:44.511+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:45.556+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:45.561+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:44.549376+00:00, run_end_date=2024-09-27 16:04:45.136261+00:00, run_duration=0.586885, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1342, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:43.483168+00:00, queued_by_job_id=1230, pid=321885
[2024-09-27T18:04:45.589+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:07:00+00:00, run_after=2023-09-27 17:08:00+00:00
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:45.635+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>
[2024-09-27T18:04:45.636+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:45.637+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:45.637+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:45.637+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:04:45.637+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:45.640+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:46.579+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:46.664+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:47.503+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:48.441+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:48.535+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:49.331+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:49.332+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:49.337+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:48.574115+00:00, run_end_date=2024-09-27 16:04:48.922514+00:00, run_duration=0.348399, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1344, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:04:45.636110+00:00, queued_by_job_id=1230, pid=321899
[2024-09-27T18:04:49.338+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:46.700094+00:00, run_end_date=2024-09-27 16:04:47.073994+00:00, run_duration=0.3739, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1343, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:45.636110+00:00, queued_by_job_id=1230, pid=321892
[2024-09-27T18:04:49.390+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:04:49.432+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:05:00+00:00: scheduled__2023-09-27T17:05:00+00:00, state:running, queued_at: 2024-09-27 16:04:37.125729+00:00. externally triggered: False> successful
[2024-09-27T18:04:49.432+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:05:00+00:00, run_id=scheduled__2023-09-27T17:05:00+00:00, run_start_date=2024-09-27 16:04:37.149710+00:00, run_end_date=2024-09-27 16:04:49.432688+00:00, run_duration=12.282978, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:05:00+00:00, data_interval_end=2023-09-27 17:06:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:04:49.437+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:06:00+00:00, run_after=2023-09-27 17:07:00+00:00
[2024-09-27T18:04:49.451+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:49.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:49.452+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:49.452+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:49.455+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:49.455+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:49.456+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:49.456+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:49.456+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:49.460+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:50.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:50.479+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:52.125+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:53.065+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:53.149+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:54.438+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:54.439+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:04:54.445+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:50.516047+00:00, run_end_date=2024-09-27 16:04:51.728345+00:00, run_duration=1.212298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1345, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:49.453601+00:00, queued_by_job_id=1230, pid=321909
[2024-09-27T18:04:54.446+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:53.186177+00:00, run_end_date=2024-09-27 16:04:54.015282+00:00, run_duration=0.829105, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1346, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:49.453601+00:00, queued_by_job_id=1230, pid=321916
[2024-09-27T18:04:54.605+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:09:00+00:00, run_after=2023-09-27 17:10:00+00:00
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:04:54.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:04:54.640+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:04:54.641+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.641+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:04:54.641+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.642+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:04:54.642+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:54.645+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:55.577+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:55.662+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:56.700+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:57.637+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:04:57.722+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:04:59.017+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:04:59.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:00.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:01.346+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.347+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.347+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:01.353+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:55.696855+00:00, run_end_date=2024-09-27 16:04:56.283883+00:00, run_duration=0.587028, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1347, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321924
[2024-09-27T18:05:01.354+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:04:57.752404+00:00, run_end_date=2024-09-27 16:04:58.622689+00:00, run_duration=0.870285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1348, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321932
[2024-09-27T18:05:01.355+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:00.082315+00:00, run_end_date=2024-09-27 16:05:00.938541+00:00, run_duration=0.856226, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1349, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:04:54.640533+00:00, queued_by_job_id=1230, pid=321939
[2024-09-27T18:05:01.401+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:01.465+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:01.466+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:01.467+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:05:01.467+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>
[2024-09-27T18:05:01.470+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:01.471+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:01.471+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.472+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:01.472+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.472+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:01.473+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.473+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:01.473+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:01.476+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:02.416+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:02.500+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:03.827+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:04.767+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:04.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:06.238+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:07.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:07.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:09.945+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:10.893+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:10.978+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:12.419+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.421+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:06:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:12.427+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:04.887291+00:00, run_end_date=2024-09-27 16:05:05.848649+00:00, run_duration=0.961358, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1351, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321953
[2024-09-27T18:05:12.428+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:07.290743+00:00, run_end_date=2024-09-27 16:05:09.554486+00:00, run_duration=2.263743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1352, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321960
[2024-09-27T18:05:12.429+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:02.535970+00:00, run_end_date=2024-09-27 16:05:03.408084+00:00, run_duration=0.872114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1350, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321946
[2024-09-27T18:05:12.429+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:06:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:11.014989+00:00, run_end_date=2024-09-27 16:05:12.014439+00:00, run_duration=0.99945, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1353, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:01.468927+00:00, queued_by_job_id=1230, pid=321967
[2024-09-27T18:05:12.465+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:05:12.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:12.560+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:06:00+00:00: scheduled__2023-09-27T17:06:00+00:00, state:running, queued_at: 2024-09-27 16:04:45.583421+00:00. externally triggered: False> successful
[2024-09-27T18:05:12.561+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:06:00+00:00, run_id=scheduled__2023-09-27T17:06:00+00:00, run_start_date=2024-09-27 16:04:45.605678+00:00, run_end_date=2024-09-27 16:05:12.561253+00:00, run_duration=26.955575, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:06:00+00:00, data_interval_end=2023-09-27 17:07:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:12.566+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:07:00+00:00, run_after=2023-09-27 17:08:00+00:00
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:12.574+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:12.575+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:05:12.575+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>
[2024-09-27T18:05:12.576+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:12.576+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:12.576+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.577+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:12.577+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:12.581+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:13.513+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:13.600+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:14.891+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:15.821+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:15.905+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:17.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:18.088+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:18.171+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:19.329+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:07:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:20.269+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:20.354+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:07:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:21.263+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:07:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:21.267+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:18.207836+00:00, run_end_date=2024-09-27 16:05:18.928262+00:00, run_duration=0.720426, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1356, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321993
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:07:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:20.389734+00:00, run_end_date=2024-09-27 16:05:20.872924+00:00, run_duration=0.48319, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1357, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=322001
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:15.941664+00:00, run_end_date=2024-09-27 16:05:16.725295+00:00, run_duration=0.783631, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1355, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321986
[2024-09-27T18:05:21.268+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:13.635432+00:00, run_end_date=2024-09-27 16:05:14.473137+00:00, run_duration=0.837705, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1354, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:12.575709+00:00, queued_by_job_id=1230, pid=321976
[2024-09-27T18:05:21.307+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:05:21.324+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:07:00+00:00: scheduled__2023-09-27T17:07:00+00:00, state:running, queued_at: 2024-09-27 16:04:49.384750+00:00. externally triggered: False> successful
[2024-09-27T18:05:21.325+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:07:00+00:00, run_id=scheduled__2023-09-27T17:07:00+00:00, run_start_date=2024-09-27 16:04:49.403385+00:00, run_end_date=2024-09-27 16:05:21.325097+00:00, run_duration=31.921712, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:07:00+00:00, data_interval_end=2023-09-27 17:08:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:21.327+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:08:00+00:00, run_after=2023-09-27 17:09:00+00:00
[2024-09-27T18:05:21.335+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
[2024-09-27T18:05:21.335+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:21.336+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>
[2024-09-27T18:05:21.337+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:21.337+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:21.337+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.338+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:21.338+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.338+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:21.338+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:21.342+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:22.276+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:22.361+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:23.364+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:24.298+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:24.383+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:25.274+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:08:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:26.212+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:26.297+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:08:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:27.289+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.290+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.290+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:08:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:27.296+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:08:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:26.333351+00:00, run_end_date=2024-09-27 16:05:26.898391+00:00, run_duration=0.56504, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1360, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322022
[2024-09-27T18:05:27.297+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:24.419408+00:00, run_end_date=2024-09-27 16:05:24.908390+00:00, run_duration=0.488982, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1359, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322015
[2024-09-27T18:05:27.297+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:22.396334+00:00, run_end_date=2024-09-27 16:05:22.939666+00:00, run_duration=0.543332, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1358, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:21.336774+00:00, queued_by_job_id=1230, pid=322008
[2024-09-27T18:05:27.444+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:27.487+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:08:00+00:00: scheduled__2023-09-27T17:08:00+00:00, state:running, queued_at: 2024-09-27 16:04:54.599257+00:00. externally triggered: False> successful
[2024-09-27T18:05:27.488+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:08:00+00:00, run_id=scheduled__2023-09-27T17:08:00+00:00, run_start_date=2024-09-27 16:04:54.617561+00:00, run_end_date=2024-09-27 16:05:27.488237+00:00, run_duration=32.870676, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:08:00+00:00, data_interval_end=2023-09-27 17:09:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:27.492+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:09:00+00:00, run_after=2023-09-27 17:10:00+00:00
[2024-09-27T18:05:27.507+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
[2024-09-27T18:05:27.507+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:27.508+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:27.508+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:27.509+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>
[2024-09-27T18:05:27.511+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:27.512+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:27.512+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.513+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:27.513+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.513+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:27.514+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:27.518+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:28.458+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:28.542+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:29.630+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:30.599+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:30.690+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:31.503+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:09:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:32.456+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:32.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:09:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:33.536+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:09:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:33.543+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:09:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:32.583916+00:00, run_end_date=2024-09-27 16:05:33.143325+00:00, run_duration=0.559409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1363, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322078
[2024-09-27T18:05:33.544+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:30.731992+00:00, run_end_date=2024-09-27 16:05:31.142127+00:00, run_duration=0.410135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1362, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322071
[2024-09-27T18:05:33.545+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:28.580955+00:00, run_end_date=2024-09-27 16:05:29.224861+00:00, run_duration=0.643906, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1361, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:27.510121+00:00, queued_by_job_id=1230, pid=322050
[2024-09-27T18:05:33.594+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:33.610+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:09:00+00:00: scheduled__2023-09-27T17:09:00+00:00, state:running, queued_at: 2024-09-27 16:05:01.395036+00:00. externally triggered: False> successful
[2024-09-27T18:05:33.610+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:09:00+00:00, run_id=scheduled__2023-09-27T17:09:00+00:00, run_start_date=2024-09-27 16:05:01.414159+00:00, run_end_date=2024-09-27 16:05:33.610393+00:00, run_duration=32.196234, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:09:00+00:00, data_interval_end=2023-09-27 17:10:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:33.612+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:10:00+00:00, run_after=2023-09-27 17:11:00+00:00
[2024-09-27T18:05:33.618+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:33.619+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>
[2024-09-27T18:05:33.620+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:33.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:33.620+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:33.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:33.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:33.624+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:34.556+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:34.643+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:36.000+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:36.931+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:37.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:10:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:38.006+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:38.007+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:10:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:38.012+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:10:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:37.054928+00:00, run_end_date=2024-09-27 16:05:37.625245+00:00, run_duration=0.570317, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1365, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:33.619732+00:00, queued_by_job_id=1230, pid=322097
[2024-09-27T18:05:38.013+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:34.678686+00:00, run_end_date=2024-09-27 16:05:35.622274+00:00, run_duration=0.943588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1364, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:33.619732+00:00, queued_by_job_id=1230, pid=322086
[2024-09-27T18:05:38.045+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:38.075+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:10:00+00:00: scheduled__2023-09-27T17:10:00+00:00, state:running, queued_at: 2024-09-27 16:05:12.501405+00:00. externally triggered: False> successful
[2024-09-27T18:05:38.076+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:10:00+00:00, run_id=scheduled__2023-09-27T17:10:00+00:00, run_start_date=2024-09-27 16:05:12.519862+00:00, run_end_date=2024-09-27 16:05:38.076459+00:00, run_duration=25.556597, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:10:00+00:00, data_interval_end=2023-09-27 17:11:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:38.081+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:11:00+00:00, run_after=2023-09-27 17:12:00+00:00
[2024-09-27T18:05:38.093+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:38.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:38.094+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:38.096+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:38.097+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:38.097+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:38.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:39.044+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:39.131+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:40.049+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:40.054+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:39.168107+00:00, run_end_date=2024-09-27 16:05:39.683428+00:00, run_duration=0.515321, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1366, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:38.095507+00:00, queued_by_job_id=1230, pid=322127
[2024-09-27T18:05:40.090+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:40.106+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:40.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:40.107+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>
[2024-09-27T18:05:40.108+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:40.108+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:40.108+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:40.111+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:11:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:41.053+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:41.140+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:11:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:42.086+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:11:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:42.090+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:11:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:41.175746+00:00, run_end_date=2024-09-27 16:05:41.678683+00:00, run_duration=0.502937, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1367, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:40.107540+00:00, queued_by_job_id=1230, pid=322137
[2024-09-27T18:05:42.121+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:42.160+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:11:00+00:00: scheduled__2023-09-27T17:11:00+00:00, state:running, queued_at: 2024-09-27 16:05:27.441893+00:00. externally triggered: False> successful
[2024-09-27T18:05:42.161+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:11:00+00:00, run_id=scheduled__2023-09-27T17:11:00+00:00, run_start_date=2024-09-27 16:05:27.455171+00:00, run_end_date=2024-09-27 16:05:42.161049+00:00, run_duration=14.705878, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:11:00+00:00, data_interval_end=2023-09-27 17:12:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:42.165+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:12:00+00:00, run_after=2023-09-27 17:13:00+00:00
[2024-09-27T18:05:42.179+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:42.180+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:42.180+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:42.182+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:42.183+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:42.184+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:42.188+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:43.162+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:43.254+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:44.137+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:44.142+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:43.295822+00:00, run_end_date=2024-09-27 16:05:43.713516+00:00, run_duration=0.417694, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1368, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:42.181454+00:00, queued_by_job_id=1230, pid=322158
[2024-09-27T18:05:44.168+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:44.206+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:44.207+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:44.207+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:44.209+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:44.210+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:44.210+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:44.214+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:45.169+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:45.255+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:46.219+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:46.225+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:45.291235+00:00, run_end_date=2024-09-27 16:05:45.786829+00:00, run_duration=0.495594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1369, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:44.208562+00:00, queued_by_job_id=1230, pid=322166
[2024-09-27T18:05:46.263+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:14:00+00:00, run_after=2023-09-27 17:15:00+00:00
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:46.295+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:46.297+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:46.297+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:46.297+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:46.301+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:47.251+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:47.336+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:48.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:49.037+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:49.120+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:49.918+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:49.919+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:49.925+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:49.156214+00:00, run_end_date=2024-09-27 16:05:49.495324+00:00, run_duration=0.33911, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1371, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:46.296297+00:00, queued_by_job_id=1230, pid=322194
[2024-09-27T18:05:49.926+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:47.373798+00:00, run_end_date=2024-09-27 16:05:47.730848+00:00, run_duration=0.35705, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1370, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:46.296297+00:00, queued_by_job_id=1230, pid=322186
[2024-09-27T18:05:49.967+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:50.006+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:50.008+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:50.008+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.008+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:05:50.009+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.011+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:50.960+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:51.044+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:52.640+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:53.579+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:53.664+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:54.866+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:12:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:55.790+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:55.874+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:12:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:57.068+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.069+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.069+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:12:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:05:57.075+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:51.081800+00:00, run_end_date=2024-09-27 16:05:52.276958+00:00, run_duration=1.195158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1372, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322202
[2024-09-27T18:05:57.076+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:12:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:55.911232+00:00, run_end_date=2024-09-27 16:05:56.655537+00:00, run_duration=0.744305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1374, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322216
[2024-09-27T18:05:57.077+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:53.700865+00:00, run_end_date=2024-09-27 16:05:54.435959+00:00, run_duration=0.735094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1373, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:50.007390+00:00, queued_by_job_id=1230, pid=322209
[2024-09-27T18:05:57.126+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:05:57.174+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:12:00+00:00: scheduled__2023-09-27T17:12:00+00:00, state:running, queued_at: 2024-09-27 16:05:42.115792+00:00. externally triggered: False> successful
[2024-09-27T18:05:57.174+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:12:00+00:00, run_id=scheduled__2023-09-27T17:12:00+00:00, run_start_date=2024-09-27 16:05:42.138392+00:00, run_end_date=2024-09-27 16:05:57.174568+00:00, run_duration=15.036176, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:12:00+00:00, data_interval_end=2023-09-27 17:13:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:05:57.179+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:13:00+00:00, run_after=2023-09-27 17:14:00+00:00
[2024-09-27T18:05:57.192+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:05:57.193+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:05:57.193+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:05:57.194+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:05:57.194+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:05:57.197+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:05:57.197+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:05:57.197+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.198+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:05:57.198+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.198+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:05:57.199+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:57.202+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:05:58.134+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:05:58.219+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:05:59.777+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:00.761+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:00.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:01.891+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:02.805+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:02.891+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:03.824+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.824+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.825+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:03.830+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:00.887693+00:00, run_end_date=2024-09-27 16:06:01.460657+00:00, run_duration=0.572964, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1376, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322232
[2024-09-27T18:06:03.831+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:02.931089+00:00, run_end_date=2024-09-27 16:06:03.393375+00:00, run_duration=0.462286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1377, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322239
[2024-09-27T18:06:03.832+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:05:58.256155+00:00, run_end_date=2024-09-27 16:05:59.344750+00:00, run_duration=1.088595, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1375, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:05:57.195473+00:00, queued_by_job_id=1230, pid=322225
[2024-09-27T18:06:03.978+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:04.011+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:04.012+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>
[2024-09-27T18:06:04.013+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:04.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.015+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:04.015+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:04.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:05.067+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:06.126+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:07.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:07.182+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:08.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:09.056+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:09.144+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:10.087+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:13:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:11.100+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:11.191+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:13:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:11.968+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.968+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.969+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.969+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:13:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:11.975+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:09.184018+00:00, run_end_date=2024-09-27 16:06:09.673775+00:00, run_duration=0.489757, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1380, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322261
[2024-09-27T18:06:11.975+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:13:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:11.229256+00:00, run_end_date=2024-09-27 16:06:11.547940+00:00, run_duration=0.318684, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1381, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322268
[2024-09-27T18:06:11.976+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:05.103968+00:00, run_end_date=2024-09-27 16:06:05.766222+00:00, run_duration=0.662254, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1378, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322247
[2024-09-27T18:06:11.977+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:07.218412+00:00, run_end_date=2024-09-27 16:06:07.700197+00:00, run_duration=0.481785, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1379, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:04.013088+00:00, queued_by_job_id=1230, pid=322254
[2024-09-27T18:06:12.025+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:12.056+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:13:00+00:00: scheduled__2023-09-27T17:13:00+00:00, state:running, queued_at: 2024-09-27 16:05:46.257167+00:00. externally triggered: False> successful
[2024-09-27T18:06:12.056+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:13:00+00:00, run_id=scheduled__2023-09-27T17:13:00+00:00, run_start_date=2024-09-27 16:05:46.274070+00:00, run_end_date=2024-09-27 16:06:12.056543+00:00, run_duration=25.782473, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:13:00+00:00, data_interval_end=2023-09-27 17:14:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:12.058+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:14:00+00:00, run_after=2023-09-27 17:15:00+00:00
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:12.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:12.067+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:12.068+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.068+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:12.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:12.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:13.065+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:13.160+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:13.911+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:14.887+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:14.981+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:15.758+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:16.710+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:16.798+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:17.751+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:14:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:18.717+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:18.802+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:14:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:19.700+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.701+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.701+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.702+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:14:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:19.707+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:13.199065+00:00, run_end_date=2024-09-27 16:06:13.522928+00:00, run_duration=0.323863, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1382, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322276
[2024-09-27T18:06:19.708+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:14:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:18.837871+00:00, run_end_date=2024-09-27 16:06:19.267727+00:00, run_duration=0.429856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1385, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322302
[2024-09-27T18:06:19.709+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:15.017011+00:00, run_end_date=2024-09-27 16:06:15.335420+00:00, run_duration=0.318409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1383, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322285
[2024-09-27T18:06:19.710+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:16.840703+00:00, run_end_date=2024-09-27 16:06:17.337026+00:00, run_duration=0.496323, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1384, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:12.067541+00:00, queued_by_job_id=1230, pid=322294
[2024-09-27T18:06:19.753+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:06:19.788+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:14:00+00:00: scheduled__2023-09-27T17:14:00+00:00, state:running, queued_at: 2024-09-27 16:05:49.959863+00:00. externally triggered: False> successful
[2024-09-27T18:06:19.789+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:14:00+00:00, run_id=scheduled__2023-09-27T17:14:00+00:00, run_start_date=2024-09-27 16:05:49.983993+00:00, run_end_date=2024-09-27 16:06:19.789076+00:00, run_duration=29.805083, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:14:00+00:00, data_interval_end=2023-09-27 17:15:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:19.793+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:15:00+00:00, run_after=2023-09-27 17:16:00+00:00
[2024-09-27T18:06:19.806+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
[2024-09-27T18:06:19.807+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:19.807+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:19.808+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:19.808+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>
[2024-09-27T18:06:19.811+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:19.812+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:19.812+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.812+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:19.813+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.813+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:19.813+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:19.817+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:20.766+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:20.851+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:21.590+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:22.562+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:22.651+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:24.027+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:24.972+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:25.058+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:15:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:26.173+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:15:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:26.180+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:20.889038+00:00, run_end_date=2024-09-27 16:06:21.198726+00:00, run_duration=0.309688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1386, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322309
[2024-09-27T18:06:26.181+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:22.688306+00:00, run_end_date=2024-09-27 16:06:23.624340+00:00, run_duration=0.936034, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1387, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322316
[2024-09-27T18:06:26.182+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:15:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:25.094527+00:00, run_end_date=2024-09-27 16:06:25.775800+00:00, run_duration=0.681273, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1388, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:19.809812+00:00, queued_by_job_id=1230, pid=322323
[2024-09-27T18:06:26.235+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:06:26.265+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:15:00+00:00: scheduled__2023-09-27T17:15:00+00:00, state:running, queued_at: 2024-09-27 16:05:57.120307+00:00. externally triggered: False> successful
[2024-09-27T18:06:26.265+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:15:00+00:00, run_id=scheduled__2023-09-27T17:15:00+00:00, run_start_date=2024-09-27 16:05:57.139110+00:00, run_end_date=2024-09-27 16:06:26.265751+00:00, run_duration=29.126641, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:15:00+00:00, data_interval_end=2023-09-27 17:16:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:26.270+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:16:00+00:00, run_after=2023-09-27 17:17:00+00:00
[2024-09-27T18:06:26.283+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
[2024-09-27T18:06:26.283+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:26.284+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:26.284+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>
[2024-09-27T18:06:26.286+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:26.287+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:26.287+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:26.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:26.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:26.292+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:27.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:27.311+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:28.234+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:16:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:29.186+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:29.276+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:16:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:30.338+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:30.339+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:16:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:30.344+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:27.346769+00:00, run_end_date=2024-09-27 16:06:27.825457+00:00, run_duration=0.478688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1389, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:26.285439+00:00, queued_by_job_id=1230, pid=322330
[2024-09-27T18:06:30.345+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:16:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:29.318407+00:00, run_end_date=2024-09-27 16:06:29.903811+00:00, run_duration=0.585404, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1390, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:26.285439+00:00, queued_by_job_id=1230, pid=322337
[2024-09-27T18:06:30.376+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:30.406+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:16:00+00:00: scheduled__2023-09-27T17:16:00+00:00, state:running, queued_at: 2024-09-27 16:06:03.976169+00:00. externally triggered: False> successful
[2024-09-27T18:06:30.407+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:16:00+00:00, run_id=scheduled__2023-09-27T17:16:00+00:00, run_start_date=2024-09-27 16:06:03.987159+00:00, run_end_date=2024-09-27 16:06:30.407475+00:00, run_duration=26.420316, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:16:00+00:00, data_interval_end=2023-09-27 17:17:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:30.411+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:17:00+00:00, run_after=2023-09-27 17:18:00+00:00
[2024-09-27T18:06:30.423+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
[2024-09-27T18:06:30.424+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:30.424+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>
[2024-09-27T18:06:30.426+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:30.427+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:30.427+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:30.431+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:17:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:31.364+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:31.448+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:17:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:32.281+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:17:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:32.286+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:17:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:31.484146+00:00, run_end_date=2024-09-27 16:06:31.905246+00:00, run_duration=0.4211, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1391, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:30.425450+00:00, queued_by_job_id=1230, pid=322344
[2024-09-27T18:06:32.323+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:32.340+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:17:00+00:00: scheduled__2023-09-27T17:17:00+00:00, state:running, queued_at: 2024-09-27 16:06:12.020170+00:00. externally triggered: False> successful
[2024-09-27T18:06:32.341+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:17:00+00:00, run_id=scheduled__2023-09-27T17:17:00+00:00, run_start_date=2024-09-27 16:06:12.034176+00:00, run_end_date=2024-09-27 16:06:32.341272+00:00, run_duration=20.307096, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:17:00+00:00, data_interval_end=2023-09-27 17:18:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:32.345+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:18:00+00:00, run_after=2023-09-27 17:19:00+00:00
[2024-09-27T18:06:33.385+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:19:00+00:00, run_after=2023-09-27 17:20:00+00:00
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:33.428+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:33.429+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:33.429+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:33.429+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:33.432+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:34.365+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:34.449+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:36.044+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:36.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:34.484702+00:00, run_end_date=2024-09-27 16:06:35.616415+00:00, run_duration=1.131713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1392, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:33.428900+00:00, queued_by_job_id=1230, pid=322352
[2024-09-27T18:06:36.189+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:06:36.239+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:36.239+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:36.240+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:36.240+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:36.242+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:36.243+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:36.243+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:36.244+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:36.244+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:36.248+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:37.186+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:37.272+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:38.479+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:39.414+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:39.498+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:41.060+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:41.061+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:41.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:39.534447+00:00, run_end_date=2024-09-27 16:06:40.630070+00:00, run_duration=1.095623, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1394, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:36.241386+00:00, queued_by_job_id=1230, pid=322368
[2024-09-27T18:06:41.067+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:37.307987+00:00, run_end_date=2024-09-27 16:06:38.069646+00:00, run_duration=0.761659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1393, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:36.241386+00:00, queued_by_job_id=1230, pid=322360
[2024-09-27T18:06:41.121+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:21:00+00:00, run_after=2023-09-27 17:22:00+00:00
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:41.151+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:41.152+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.153+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:41.153+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:41.156+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:42.094+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:42.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:43.383+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:44.322+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:44.406+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:45.612+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:46.549+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:46.633+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:47.979+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.980+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.980+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:47.986+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:46.669693+00:00, run_end_date=2024-09-27 16:06:47.599347+00:00, run_duration=0.929654, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1397, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322389
[2024-09-27T18:06:47.987+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:44.441679+00:00, run_end_date=2024-09-27 16:06:45.227831+00:00, run_duration=0.786152, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1396, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322382
[2024-09-27T18:06:47.988+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:42.214696+00:00, run_end_date=2024-09-27 16:06:42.987812+00:00, run_duration=0.773116, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1395, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:41.152140+00:00, queued_by_job_id=1230, pid=322375
[2024-09-27T18:06:48.039+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:48.082+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:48.083+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:48.083+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:48.084+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>
[2024-09-27T18:06:48.087+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:48.087+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:48.087+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.088+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:48.088+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.089+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:48.089+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.089+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:48.090+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:48.094+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:49.029+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:49.113+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:50.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:51.097+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:51.181+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:52.375+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:53.284+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:53.368+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:54.448+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:18:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:55.385+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:55.469+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:18:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:56.382+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.383+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.383+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.384+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:18:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:06:56.390+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:18:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:55.505301+00:00, run_end_date=2024-09-27 16:06:56.023265+00:00, run_duration=0.517964, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1401, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322420
[2024-09-27T18:06:56.391+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:53.406632+00:00, run_end_date=2024-09-27 16:06:54.069817+00:00, run_duration=0.663185, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1400, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322413
[2024-09-27T18:06:56.392+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:49.148626+00:00, run_end_date=2024-09-27 16:06:49.748203+00:00, run_duration=0.599577, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1398, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322397
[2024-09-27T18:06:56.392+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:51.216408+00:00, run_end_date=2024-09-27 16:06:51.964029+00:00, run_duration=0.747621, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1399, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:48.085316+00:00, queued_by_job_id=1230, pid=322404
[2024-09-27T18:06:56.440+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:06:56.492+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:18:00+00:00: scheduled__2023-09-27T17:18:00+00:00, state:running, queued_at: 2024-09-27 16:06:33.378757+00:00. externally triggered: False> successful
[2024-09-27T18:06:56.492+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:18:00+00:00, run_id=scheduled__2023-09-27T17:18:00+00:00, run_start_date=2024-09-27 16:06:33.402973+00:00, run_end_date=2024-09-27 16:06:56.492898+00:00, run_duration=23.089925, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:18:00+00:00, data_interval_end=2023-09-27 17:19:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:06:56.497+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:19:00+00:00, run_after=2023-09-27 17:20:00+00:00
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:06:56.505+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:06:56.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:06:56.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:06:56.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:06:56.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:56.511+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:57.445+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:57.529+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:06:58.422+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:06:59.327+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:06:59.411+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:00.308+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:01.244+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:01.329+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:02.322+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:19:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:03.237+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:03.323+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:19:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:04.387+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:19:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:04.395+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:57.565982+00:00, run_end_date=2024-09-27 16:06:58.054510+00:00, run_duration=0.488528, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1402, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322427
[2024-09-27T18:07:04.396+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:19:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:03.359596+00:00, run_end_date=2024-09-27 16:07:03.989756+00:00, run_duration=0.63016, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1405, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322451
[2024-09-27T18:07:04.397+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:06:59.447724+00:00, run_end_date=2024-09-27 16:06:59.908939+00:00, run_duration=0.461215, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1403, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322435
[2024-09-27T18:07:04.397+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:01.360582+00:00, run_end_date=2024-09-27 16:07:01.896717+00:00, run_duration=0.536135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1404, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:06:56.506426+00:00, queued_by_job_id=1230, pid=322444
[2024-09-27T18:07:04.444+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:07:04.483+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:19:00+00:00: scheduled__2023-09-27T17:19:00+00:00, state:running, queued_at: 2024-09-27 16:06:36.183037+00:00. externally triggered: False> successful
[2024-09-27T18:07:04.484+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:19:00+00:00, run_id=scheduled__2023-09-27T17:19:00+00:00, run_start_date=2024-09-27 16:06:36.200652+00:00, run_end_date=2024-09-27 16:07:04.483932+00:00, run_duration=28.28328, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:19:00+00:00, data_interval_end=2023-09-27 17:20:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:04.488+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:20:00+00:00, run_after=2023-09-27 17:21:00+00:00
[2024-09-27T18:07:04.502+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
[2024-09-27T18:07:04.502+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:04.503+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>
[2024-09-27T18:07:04.506+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:04.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:04.507+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.507+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:04.508+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.508+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:04.509+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:04.512+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:05.442+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:05.527+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:07.055+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:07.989+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:08.074+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:09.516+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:10.457+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:10.542+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:20:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:11.652+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.652+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.653+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:20:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:11.659+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:05.564468+00:00, run_end_date=2024-09-27 16:07:06.652463+00:00, run_duration=1.087995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1406, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322458
[2024-09-27T18:07:11.660+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:08.111615+00:00, run_end_date=2024-09-27 16:07:09.112150+00:00, run_duration=1.000535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1407, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322466
[2024-09-27T18:07:11.660+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:20:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:10.579402+00:00, run_end_date=2024-09-27 16:07:11.254871+00:00, run_duration=0.675469, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1408, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:04.504992+00:00, queued_by_job_id=1230, pid=322473
[2024-09-27T18:07:11.812+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:24:00+00:00, run_after=2023-09-27 17:25:00+00:00
[2024-09-27T18:07:11.835+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:20:00+00:00: scheduled__2023-09-27T17:20:00+00:00, state:running, queued_at: 2024-09-27 16:06:41.115630+00:00. externally triggered: False> successful
[2024-09-27T18:07:11.835+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:20:00+00:00, run_id=scheduled__2023-09-27T17:20:00+00:00, run_start_date=2024-09-27 16:06:41.130110+00:00, run_end_date=2024-09-27 16:07:11.835912+00:00, run_duration=30.705802, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:20:00+00:00, data_interval_end=2023-09-27 17:21:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:11.837+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:21:00+00:00, run_after=2023-09-27 17:22:00+00:00
[2024-09-27T18:07:11.845+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
[2024-09-27T18:07:11.845+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:11.846+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>
[2024-09-27T18:07:11.847+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:11.847+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:11.847+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.848+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:11.848+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.848+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:11.848+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:11.851+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:12.787+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:12.871+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:13.952+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:14.889+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:14.974+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:15.854+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:21:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:16.797+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:16.882+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:21:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:17.912+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.913+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.913+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:21:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:17.919+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:15.010286+00:00, run_end_date=2024-09-27 16:07:15.480132+00:00, run_duration=0.469846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1410, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322491
[2024-09-27T18:07:17.920+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:12.906925+00:00, run_end_date=2024-09-27 16:07:13.526688+00:00, run_duration=0.619763, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1409, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322482
[2024-09-27T18:07:17.920+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:21:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:16.917646+00:00, run_end_date=2024-09-27 16:07:17.546806+00:00, run_duration=0.62916, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1411, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:11.846726+00:00, queued_by_job_id=1230, pid=322500
[2024-09-27T18:07:17.961+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:07:17.990+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:21:00+00:00: scheduled__2023-09-27T17:21:00+00:00, state:running, queued_at: 2024-09-27 16:06:48.033610+00:00. externally triggered: False> successful
[2024-09-27T18:07:17.991+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:21:00+00:00, run_id=scheduled__2023-09-27T17:21:00+00:00, run_start_date=2024-09-27 16:06:48.052005+00:00, run_end_date=2024-09-27 16:07:17.991482+00:00, run_duration=29.939477, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:21:00+00:00, data_interval_end=2023-09-27 17:22:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:17.996+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:22:00+00:00, run_after=2023-09-27 17:23:00+00:00
[2024-09-27T18:07:18.009+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
[2024-09-27T18:07:18.009+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:18.010+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:18.010+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>
[2024-09-27T18:07:18.012+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:18.013+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:18.013+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.014+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:18.014+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:18.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:19.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:20.005+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:22:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:20.960+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:21.046+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:22:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:21.964+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:21.965+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:22:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:21.970+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:22:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:21.084047+00:00, run_end_date=2024-09-27 16:07:21.561213+00:00, run_duration=0.477166, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1413, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:18.011493+00:00, queued_by_job_id=1230, pid=322515
[2024-09-27T18:07:21.971+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:19.082046+00:00, run_end_date=2024-09-27 16:07:19.610619+00:00, run_duration=0.528573, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1412, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:18.011493+00:00, queued_by_job_id=1230, pid=322508
[2024-09-27T18:07:22.001+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:07:22.032+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:22:00+00:00: scheduled__2023-09-27T17:22:00+00:00, state:running, queued_at: 2024-09-27 16:06:56.434500+00:00. externally triggered: False> successful
[2024-09-27T18:07:22.032+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:22:00+00:00, run_id=scheduled__2023-09-27T17:22:00+00:00, run_start_date=2024-09-27 16:06:56.451884+00:00, run_end_date=2024-09-27 16:07:22.032648+00:00, run_duration=25.580764, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:22:00+00:00, data_interval_end=2023-09-27 17:23:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:22.036+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:23:00+00:00, run_after=2023-09-27 17:24:00+00:00
[2024-09-27T18:07:22.048+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:22.049+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:22.049+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:22.051+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:22.051+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:22.052+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:22.055+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:22.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:23.072+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:23.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:23.910+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:23.108986+00:00, run_end_date=2024-09-27 16:07:23.485581+00:00, run_duration=0.376595, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1414, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:22.050298+00:00, queued_by_job_id=1230, pid=322523
[2024-09-27T18:07:23.950+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:24:00+00:00, run_after=2023-09-27 17:25:00+00:00
[2024-09-27T18:07:23.968+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:23.968+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:23.969+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>
[2024-09-27T18:07:23.970+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:23.970+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:23.970+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:23.974+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:23:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:24.905+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:24.990+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:23:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:25.900+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:23:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:25.903+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:23:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:25.027028+00:00, run_end_date=2024-09-27 16:07:25.496688+00:00, run_duration=0.46966, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1415, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:23.969445+00:00, queued_by_job_id=1230, pid=322530
[2024-09-27T18:07:25.926+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:25:00+00:00, run_after=2023-09-27 17:26:00+00:00
[2024-09-27T18:07:25.951+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:23:00+00:00: scheduled__2023-09-27T17:23:00+00:00, state:running, queued_at: 2024-09-27 16:07:11.810159+00:00. externally triggered: False> successful
[2024-09-27T18:07:25.951+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:23:00+00:00, run_id=scheduled__2023-09-27T17:23:00+00:00, run_start_date=2024-09-27 16:07:11.819992+00:00, run_end_date=2024-09-27 16:07:25.951566+00:00, run_duration=14.131574, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:23:00+00:00, data_interval_end=2023-09-27 17:24:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:25.953+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:24:00+00:00, run_after=2023-09-27 17:25:00+00:00
[2024-09-27T18:07:25.960+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:25.960+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:25.960+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:25.961+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:25.962+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:25.962+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:25.964+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:26.901+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:26.986+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:28.026+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:28.030+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:27.022730+00:00, run_end_date=2024-09-27 16:07:27.631610+00:00, run_duration=0.60888, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1416, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:25.961174+00:00, queued_by_job_id=1230, pid=322538
[2024-09-27T18:07:28.057+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:25:00+00:00, run_after=2023-09-27 17:26:00+00:00
[2024-09-27T18:07:28.080+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:28.080+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:28.080+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:28.081+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:28.081+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:28.081+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:28.085+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:29.018+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:29.103+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:30.127+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:30.129+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:29.138943+00:00, run_end_date=2024-09-27 16:07:29.700666+00:00, run_duration=0.561723, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1417, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:28.080797+00:00, queued_by_job_id=1230, pid=322545
[2024-09-27T18:07:30.175+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:26:00+00:00, run_after=2023-09-27 17:27:00+00:00
[2024-09-27T18:07:30.202+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:30.202+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:30.202+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:30.202+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:30.203+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:25:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:30.203+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:30.204+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:30.204+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:30.204+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:30.207+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:31.132+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:31.217+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:32.129+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:33.054+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:33.140+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:34.139+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:34.140+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:34.143+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:33.177795+00:00, run_end_date=2024-09-27 16:07:33.775558+00:00, run_duration=0.597763, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1419, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:30.203053+00:00, queued_by_job_id=1230, pid=322573
[2024-09-27T18:07:34.143+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:31.254039+00:00, run_end_date=2024-09-27 16:07:31.738211+00:00, run_duration=0.484172, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1418, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:30.203053+00:00, queued_by_job_id=1230, pid=322566
[2024-09-27T18:07:34.169+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:27:00+00:00, run_after=2023-09-27 17:28:00+00:00
[2024-09-27T18:07:34.202+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:34.203+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:34.203+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:34.203+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:34.203+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:24:00+00:00 [scheduled]>
[2024-09-27T18:07:34.204+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:25:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:24:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:34.205+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:34.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:34.205+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:34.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:34.205+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:34.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:34.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:35.143+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:35.227+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:36.123+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:37.059+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:37.145+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:38.149+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:24:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:39.086+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:39.170+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:24:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:40.210+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:40.211+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:40.211+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:24:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:40.214+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:35.264052+00:00, run_end_date=2024-09-27 16:07:35.728567+00:00, run_duration=0.464515, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1420, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:34.204041+00:00, queued_by_job_id=1230, pid=322581
[2024-09-27T18:07:40.214+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:24:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:39.207115+00:00, run_end_date=2024-09-27 16:07:39.849813+00:00, run_duration=0.642698, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1422, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:34.204041+00:00, queued_by_job_id=1230, pid=322595
[2024-09-27T18:07:40.215+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:37.182057+00:00, run_end_date=2024-09-27 16:07:37.762822+00:00, run_duration=0.580765, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1421, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:34.204041+00:00, queued_by_job_id=1230, pid=322588
[2024-09-27T18:07:40.251+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:28:00+00:00, run_after=2023-09-27 17:29:00+00:00
[2024-09-27T18:07:40.276+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:24:00+00:00: scheduled__2023-09-27T17:24:00+00:00, state:running, queued_at: 2024-09-27 16:07:25.924034+00:00. externally triggered: False> successful
[2024-09-27T18:07:40.276+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:24:00+00:00, run_id=scheduled__2023-09-27T17:24:00+00:00, run_start_date=2024-09-27 16:07:25.939625+00:00, run_end_date=2024-09-27 16:07:40.276295+00:00, run_duration=14.33667, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:24:00+00:00, data_interval_end=2023-09-27 17:25:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:40.278+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:25:00+00:00, run_after=2023-09-27 17:26:00+00:00
[2024-09-27T18:07:40.285+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
[2024-09-27T18:07:40.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:40.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:40.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:40.286+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
[2024-09-27T18:07:40.287+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:27:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:25:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:40.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:40.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:40.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:40.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:40.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:40.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:40.291+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:41.228+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:41.313+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:42.188+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:43.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:43.207+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:44.290+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:45.233+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:45.319+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:46.199+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:46.199+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:46.199+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:46.202+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:43.243874+00:00, run_end_date=2024-09-27 16:07:43.875369+00:00, run_duration=0.631495, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1424, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:40.286970+00:00, queued_by_job_id=1230, pid=322609
[2024-09-27T18:07:46.203+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:45.355172+00:00, run_end_date=2024-09-27 16:07:45.832028+00:00, run_duration=0.476856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1425, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:40.286970+00:00, queued_by_job_id=1230, pid=322616
[2024-09-27T18:07:46.203+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:41.343668+00:00, run_end_date=2024-09-27 16:07:41.821633+00:00, run_duration=0.477965, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1423, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:40.286970+00:00, queued_by_job_id=1230, pid=322602
[2024-09-27T18:07:46.351+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:29:00+00:00, run_after=2023-09-27 17:30:00+00:00
[2024-09-27T18:07:46.384+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
[2024-09-27T18:07:46.384+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:46.384+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:46.384+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:46.385+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:07:46.385+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:25:00+00:00 [scheduled]>
[2024-09-27T18:07:46.386+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:28:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:27:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:26:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:25:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:46.386+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:46.386+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:46.387+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:46.387+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:46.387+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:46.387+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:46.387+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:46.387+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:46.390+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:47.330+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:47.415+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:48.353+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:49.289+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:49.374+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:50.335+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:51.269+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:51.354+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:52.549+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:53.484+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:53.569+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:25:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:55.292+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:55.292+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:55.293+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:55.293+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:25:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:07:55.299+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:47.451462+00:00, run_end_date=2024-09-27 16:07:47.943917+00:00, run_duration=0.492455, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1426, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:46.385636+00:00, queued_by_job_id=1230, pid=322624
[2024-09-27T18:07:55.300+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:51.386069+00:00, run_end_date=2024-09-27 16:07:52.128150+00:00, run_duration=0.742081, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1428, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:46.385636+00:00, queued_by_job_id=1230, pid=322639
[2024-09-27T18:07:55.301+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:25:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:53.607144+00:00, run_end_date=2024-09-27 16:07:54.904028+00:00, run_duration=1.296884, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1429, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:46.385636+00:00, queued_by_job_id=1230, pid=322648
[2024-09-27T18:07:55.302+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:49.411828+00:00, run_end_date=2024-09-27 16:07:49.935758+00:00, run_duration=0.52393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1427, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:46.385636+00:00, queued_by_job_id=1230, pid=322632
[2024-09-27T18:07:55.356+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:30:00+00:00, run_after=2023-09-27 17:31:00+00:00
[2024-09-27T18:07:55.407+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:25:00+00:00: scheduled__2023-09-27T17:25:00+00:00, state:running, queued_at: 2024-09-27 16:07:30.168866+00:00. externally triggered: False> successful
[2024-09-27T18:07:55.408+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:25:00+00:00, run_id=scheduled__2023-09-27T17:25:00+00:00, run_start_date=2024-09-27 16:07:30.182786+00:00, run_end_date=2024-09-27 16:07:55.408456+00:00, run_duration=25.22567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:25:00+00:00, data_interval_end=2023-09-27 17:26:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:07:55.413+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:26:00+00:00, run_after=2023-09-27 17:27:00+00:00
[2024-09-27T18:07:55.421+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
[2024-09-27T18:07:55.421+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:07:55.421+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:07:55.421+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:07:55.421+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:07:55.422+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:26:00+00:00 [scheduled]>
[2024-09-27T18:07:55.423+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:28:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:27:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:26:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:07:55.423+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:07:55.423+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:55.423+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:07:55.423+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:55.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:07:55.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:55.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:07:55.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:55.429+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:56.362+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:56.448+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:07:58.388+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:07:59.321+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:07:59.407+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:00.529+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:01.457+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:01.541+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:02.985+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:26:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:03.921+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:04.006+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:26:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:05.077+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:05.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:05.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:05.079+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:26:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:05.085+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:56.484957+00:00, run_end_date=2024-09-27 16:07:57.978917+00:00, run_duration=1.49396, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1430, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:07:55.422487+00:00, queued_by_job_id=1230, pid=322655
[2024-09-27T18:08:05.086+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:26:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:04.042783+00:00, run_end_date=2024-09-27 16:08:04.670495+00:00, run_duration=0.627712, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1433, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:07:55.422487+00:00, queued_by_job_id=1230, pid=322698
[2024-09-27T18:08:05.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:07:59.443820+00:00, run_end_date=2024-09-27 16:08:00.129445+00:00, run_duration=0.685625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1431, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:07:55.422487+00:00, queued_by_job_id=1230, pid=322663
[2024-09-27T18:08:05.087+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:01.577975+00:00, run_end_date=2024-09-27 16:08:02.588118+00:00, run_duration=1.010143, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1432, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:07:55.422487+00:00, queued_by_job_id=1230, pid=322675
[2024-09-27T18:08:05.132+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:27:00+00:00, run_after=2023-09-27 17:28:00+00:00
[2024-09-27T18:08:05.169+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:26:00+00:00: scheduled__2023-09-27T17:26:00+00:00, state:running, queued_at: 2024-09-27 16:07:34.166748+00:00. externally triggered: False> successful
[2024-09-27T18:08:05.169+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:26:00+00:00, run_id=scheduled__2023-09-27T17:26:00+00:00, run_start_date=2024-09-27 16:07:34.180868+00:00, run_end_date=2024-09-27 16:08:05.169674+00:00, run_duration=30.988806, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:26:00+00:00, data_interval_end=2023-09-27 17:27:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:05.174+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:27:00+00:00, run_after=2023-09-27 17:28:00+00:00
[2024-09-27T18:08:05.187+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
[2024-09-27T18:08:05.188+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:05.188+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:05.189+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:08:05.189+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:27:00+00:00 [scheduled]>
[2024-09-27T18:08:05.192+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:28:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:27:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:05.192+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:05.193+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:05.193+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:05.194+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:05.194+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:05.194+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:05.198+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:06.133+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:06.217+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:07.214+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:08.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:08.234+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:09.152+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:27:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:10.088+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:10.173+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:27:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:11.128+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:11.129+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:11.129+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:27:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:11.136+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:06.253071+00:00, run_end_date=2024-09-27 16:08:06.789897+00:00, run_duration=0.536826, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1434, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:05.190693+00:00, queued_by_job_id=1230, pid=322708
[2024-09-27T18:08:11.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:08.269777+00:00, run_end_date=2024-09-27 16:08:08.733339+00:00, run_duration=0.463562, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1435, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:05.190693+00:00, queued_by_job_id=1230, pid=322736
[2024-09-27T18:08:11.137+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:27:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:10.212431+00:00, run_end_date=2024-09-27 16:08:10.784365+00:00, run_duration=0.571934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1436, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:05.190693+00:00, queued_by_job_id=1230, pid=322746
[2024-09-27T18:08:11.184+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:28:00+00:00, run_after=2023-09-27 17:29:00+00:00
[2024-09-27T18:08:11.214+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:27:00+00:00: scheduled__2023-09-27T17:27:00+00:00, state:running, queued_at: 2024-09-27 16:07:40.248659+00:00. externally triggered: False> successful
[2024-09-27T18:08:11.214+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:27:00+00:00, run_id=scheduled__2023-09-27T17:27:00+00:00, run_start_date=2024-09-27 16:07:40.259134+00:00, run_end_date=2024-09-27 16:08:11.214691+00:00, run_duration=30.955557, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:27:00+00:00, data_interval_end=2023-09-27 17:28:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:11.219+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:28:00+00:00, run_after=2023-09-27 17:29:00+00:00
[2024-09-27T18:08:11.233+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
[2024-09-27T18:08:11.233+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:11.234+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:11.234+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:28:00+00:00 [scheduled]>
[2024-09-27T18:08:11.237+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:29:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:28:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:11.237+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:11.238+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:11.238+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:11.238+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:11.242+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:12.176+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:12.261+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:13.460+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:28:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:14.395+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:14.480+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:28:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:15.268+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:15.269+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:28:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:15.275+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:12.297076+00:00, run_end_date=2024-09-27 16:08:13.039853+00:00, run_duration=0.742777, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1437, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:11.235641+00:00, queued_by_job_id=1230, pid=322753
[2024-09-27T18:08:15.275+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:28:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:14.515627+00:00, run_end_date=2024-09-27 16:08:14.880582+00:00, run_duration=0.364955, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1438, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:11.235641+00:00, queued_by_job_id=1230, pid=322766
[2024-09-27T18:08:15.306+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:29:00+00:00, run_after=2023-09-27 17:30:00+00:00
[2024-09-27T18:08:15.336+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:28:00+00:00: scheduled__2023-09-27T17:28:00+00:00, state:running, queued_at: 2024-09-27 16:07:46.348594+00:00. externally triggered: False> successful
[2024-09-27T18:08:15.337+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:28:00+00:00, run_id=scheduled__2023-09-27T17:28:00+00:00, run_start_date=2024-09-27 16:07:46.358822+00:00, run_end_date=2024-09-27 16:08:15.336964+00:00, run_duration=28.978142, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:28:00+00:00, data_interval_end=2023-09-27 17:29:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:15.341+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:29:00+00:00, run_after=2023-09-27 17:30:00+00:00
[2024-09-27T18:08:15.354+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
[2024-09-27T18:08:15.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:15.355+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:29:00+00:00 [scheduled]>
[2024-09-27T18:08:15.357+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:29:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:15.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:15.358+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:15.361+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:29:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:16.294+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:16.378+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:29:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:17.327+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:29:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:17.332+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:29:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:16.410228+00:00, run_end_date=2024-09-27 16:08:16.904649+00:00, run_duration=0.494421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1439, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:15.355856+00:00, queued_by_job_id=1230, pid=322777
[2024-09-27T18:08:17.489+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:31:00+00:00, run_after=2023-09-27 17:32:00+00:00
[2024-09-27T18:08:17.524+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:29:00+00:00: scheduled__2023-09-27T17:29:00+00:00, state:running, queued_at: 2024-09-27 16:07:55.349621+00:00. externally triggered: False> successful
[2024-09-27T18:08:17.525+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:29:00+00:00, run_id=scheduled__2023-09-27T17:29:00+00:00, run_start_date=2024-09-27 16:07:55.367709+00:00, run_end_date=2024-09-27 16:08:17.525510+00:00, run_duration=22.157801, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:29:00+00:00, data_interval_end=2023-09-27 17:30:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:17.530+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:30:00+00:00, run_after=2023-09-27 17:31:00+00:00
[2024-09-27T18:08:17.544+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:17.544+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:17.545+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:17.547+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:17.547+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:08:17.547+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:17.551+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:18.488+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:18.573+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:19.901+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:19.904+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:18.609042+00:00, run_end_date=2024-09-27 16:08:19.487727+00:00, run_duration=0.878685, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1440, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:08:17.545747+00:00, queued_by_job_id=1230, pid=322786
[2024-09-27T18:08:19.929+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:31:00+00:00, run_after=2023-09-27 17:32:00+00:00
[2024-09-27T18:08:19.949+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:19.949+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:19.949+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:19.950+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:19.950+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:19.950+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:19.953+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:20.885+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:20.970+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:21.766+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:21.771+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:21.005511+00:00, run_end_date=2024-09-27 16:08:21.365538+00:00, run_duration=0.360027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1441, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:19.950007+00:00, queued_by_job_id=1230, pid=322802
[2024-09-27T18:08:21.805+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:32:00+00:00, run_after=2023-09-27 17:33:00+00:00
[2024-09-27T18:08:21.836+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:21.837+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:21.837+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:21.837+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:21.838+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:31:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:21.838+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:08:21.838+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:21.839+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:21.839+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:21.842+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:22.772+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:22.856+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:24.824+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:25.763+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:25.849+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:26.854+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:26.854+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:26.859+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:22.891983+00:00, run_end_date=2024-09-27 16:08:24.409055+00:00, run_duration=1.517072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1442, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:08:21.837876+00:00, queued_by_job_id=1230, pid=322809
[2024-09-27T18:08:26.859+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:25.884443+00:00, run_end_date=2024-09-27 16:08:26.486627+00:00, run_duration=0.602184, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1443, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:21.837876+00:00, queued_by_job_id=1230, pid=322816
[2024-09-27T18:08:26.896+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:33:00+00:00, run_after=2023-09-27 17:34:00+00:00
[2024-09-27T18:08:26.946+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:26.946+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:26.946+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:26.947+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:08:26.947+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:30:00+00:00 [scheduled]>
[2024-09-27T18:08:26.950+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:32:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:31:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:30:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:26.951+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:08:26.951+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:26.951+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:26.952+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:26.952+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:26.952+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:26.956+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:27.900+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:27.985+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:28.903+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:29.852+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:29.944+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:30.756+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:31.687+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:31.771+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:30:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:32.735+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:32.735+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:32.736+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:30:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:32.742+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:29.977482+00:00, run_end_date=2024-09-27 16:08:30.331179+00:00, run_duration=0.353697, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1445, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:26.948833+00:00, queued_by_job_id=1230, pid=322845
[2024-09-27T18:08:32.743+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:30:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:31.808366+00:00, run_end_date=2024-09-27 16:08:32.314795+00:00, run_duration=0.506429, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1446, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:26.948833+00:00, queued_by_job_id=1230, pid=322854
[2024-09-27T18:08:32.743+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:28.020142+00:00, run_end_date=2024-09-27 16:08:28.484775+00:00, run_duration=0.464633, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1444, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:08:26.948833+00:00, queued_by_job_id=1230, pid=322826
[2024-09-27T18:08:32.795+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:34:00+00:00, run_after=2023-09-27 17:35:00+00:00
[2024-09-27T18:08:32.841+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:30:00+00:00: scheduled__2023-09-27T17:30:00+00:00, state:running, queued_at: 2024-09-27 16:08:17.482892+00:00. externally triggered: False> successful
[2024-09-27T18:08:32.842+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:30:00+00:00, run_id=scheduled__2023-09-27T17:30:00+00:00, run_start_date=2024-09-27 16:08:17.500597+00:00, run_end_date=2024-09-27 16:08:32.842322+00:00, run_duration=15.341725, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:30:00+00:00, data_interval_end=2023-09-27 17:31:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:32.846+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:31:00+00:00, run_after=2023-09-27 17:32:00+00:00
[2024-09-27T18:08:32.856+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
[2024-09-27T18:08:32.857+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:32.857+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:32.857+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:08:32.857+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
[2024-09-27T18:08:32.858+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:33:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:32:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:31:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:32.859+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:08:32.859+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:32.859+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:32.859+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:32.859+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:32.859+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:32.864+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:33.800+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:33.885+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:34.781+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:35.728+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:35.814+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:36.630+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:37.598+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:37.686+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:38.810+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:38.810+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:38.811+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:38.817+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:37.726832+00:00, run_end_date=2024-09-27 16:08:38.418765+00:00, run_duration=0.691933, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1449, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:32.857988+00:00, queued_by_job_id=1230, pid=322876
[2024-09-27T18:08:38.818+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:33.920977+00:00, run_end_date=2024-09-27 16:08:34.375778+00:00, run_duration=0.454801, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1447, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:08:32.857988+00:00, queued_by_job_id=1230, pid=322862
[2024-09-27T18:08:38.819+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:35.850310+00:00, run_end_date=2024-09-27 16:08:36.202518+00:00, run_duration=0.352208, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1448, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:32.857988+00:00, queued_by_job_id=1230, pid=322869
[2024-09-27T18:08:38.861+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:32:00+00:00, run_after=2023-09-27 17:33:00+00:00
[2024-09-27T18:08:38.907+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
[2024-09-27T18:08:38.908+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:38.908+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:38.909+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:08:38.909+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:31:00+00:00 [scheduled]>
[2024-09-27T18:08:38.912+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:33:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:32:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:31:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:38.912+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:38.913+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:38.913+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:38.914+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:38.914+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:38.914+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:38.918+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:39.878+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:39.962+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:42.906+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:43.843+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:43.928+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:45.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:31:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:46.021+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:46.106+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:31:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:47.138+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:47.138+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:47.139+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:31:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:47.143+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:31:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:46.142286+00:00, run_end_date=2024-09-27 16:08:46.740803+00:00, run_duration=0.598517, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1452, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:38.910662+00:00, queued_by_job_id=1230, pid=322898
[2024-09-27T18:08:47.143+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:39.998771+00:00, run_end_date=2024-09-27 16:08:42.535853+00:00, run_duration=2.537082, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1450, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:38.910662+00:00, queued_by_job_id=1230, pid=322883
[2024-09-27T18:08:47.143+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:43.964472+00:00, run_end_date=2024-09-27 16:08:44.671411+00:00, run_duration=0.706939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1451, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:38.910662+00:00, queued_by_job_id=1230, pid=322891
[2024-09-27T18:08:47.178+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:33:00+00:00, run_after=2023-09-27 17:34:00+00:00
[2024-09-27T18:08:47.192+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:31:00+00:00: scheduled__2023-09-27T17:31:00+00:00, state:running, queued_at: 2024-09-27 16:08:21.798718+00:00. externally triggered: False> successful
[2024-09-27T18:08:47.193+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:31:00+00:00, run_id=scheduled__2023-09-27T17:31:00+00:00, run_start_date=2024-09-27 16:08:21.817770+00:00, run_end_date=2024-09-27 16:08:47.192981+00:00, run_duration=25.375211, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:31:00+00:00, data_interval_end=2023-09-27 17:32:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:47.194+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:32:00+00:00, run_after=2023-09-27 17:33:00+00:00
[2024-09-27T18:08:47.203+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
[2024-09-27T18:08:47.203+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:47.203+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:47.204+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:32:00+00:00 [scheduled]>
[2024-09-27T18:08:47.205+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:33:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:32:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:47.205+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:47.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:47.205+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:47.205+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:47.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:48.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:48.234+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:49.395+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:32:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:50.344+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:50.433+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:32:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:51.326+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:51.327+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:32:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:51.333+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:48.271327+00:00, run_end_date=2024-09-27 16:08:49.000060+00:00, run_duration=0.728733, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1453, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:47.204373+00:00, queued_by_job_id=1230, pid=322905
[2024-09-27T18:08:51.333+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:32:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:50.471197+00:00, run_end_date=2024-09-27 16:08:50.919810+00:00, run_duration=0.448613, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1454, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:47.204373+00:00, queued_by_job_id=1230, pid=322913
[2024-09-27T18:08:51.470+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:35:00+00:00, run_after=2023-09-27 17:36:00+00:00
[2024-09-27T18:08:51.492+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:32:00+00:00: scheduled__2023-09-27T17:32:00+00:00, state:running, queued_at: 2024-09-27 16:08:26.893941+00:00. externally triggered: False> successful
[2024-09-27T18:08:51.493+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:32:00+00:00, run_id=scheduled__2023-09-27T17:32:00+00:00, run_start_date=2024-09-27 16:08:26.904863+00:00, run_end_date=2024-09-27 16:08:51.493179+00:00, run_duration=24.588316, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:32:00+00:00, data_interval_end=2023-09-27 17:33:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:51.495+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:33:00+00:00, run_after=2023-09-27 17:34:00+00:00
[2024-09-27T18:08:51.504+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
[2024-09-27T18:08:51.504+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:51.504+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:08:51.504+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:33:00+00:00 [scheduled]>
[2024-09-27T18:08:51.506+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:34:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:33:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:51.506+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:08:51.506+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:51.506+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:08:51.506+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:51.509+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:52.464+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:52.548+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:54.019+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:33:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:54.928+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:55.013+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:33:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:56.443+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:56.443+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:33:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:56.450+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:33:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:55.051243+00:00, run_end_date=2024-09-27 16:08:56.064200+00:00, run_duration=1.012957, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1456, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:08:51.505317+00:00, queued_by_job_id=1230, pid=322933
[2024-09-27T18:08:56.450+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:52.584097+00:00, run_end_date=2024-09-27 16:08:53.606239+00:00, run_duration=1.022142, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1455, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:08:51.505317+00:00, queued_by_job_id=1230, pid=322921
[2024-09-27T18:08:56.496+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:34:00+00:00, run_after=2023-09-27 17:35:00+00:00
[2024-09-27T18:08:56.522+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:33:00+00:00: scheduled__2023-09-27T17:33:00+00:00, state:running, queued_at: 2024-09-27 16:08:32.789542+00:00. externally triggered: False> successful
[2024-09-27T18:08:56.523+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:33:00+00:00, run_id=scheduled__2023-09-27T17:33:00+00:00, run_start_date=2024-09-27 16:08:32.807144+00:00, run_end_date=2024-09-27 16:08:56.523452+00:00, run_duration=23.716308, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:33:00+00:00, data_interval_end=2023-09-27 17:34:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:08:56.528+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:34:00+00:00, run_after=2023-09-27 17:35:00+00:00
[2024-09-27T18:08:56.541+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:08:56.541+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:56.542+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:08:56.544+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:34:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:56.544+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:08:56.545+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:56.548+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:57.476+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:08:57.560+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:08:59.002+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:08:59.008+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:08:57.596408+00:00, run_end_date=2024-09-27 16:08:58.591280+00:00, run_duration=0.994872, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1457, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:08:56.543092+00:00, queued_by_job_id=1230, pid=322940
[2024-09-27T18:08:59.035+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:35:00+00:00, run_after=2023-09-27 17:36:00+00:00
[2024-09-27T18:08:59.073+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:08:59.074+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:08:59.074+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:08:59.076+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:34:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:08:59.077+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:08:59.077+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:08:59.081+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:00.019+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:00.105+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:01.224+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:01.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:00.141491+00:00, run_end_date=2024-09-27 16:09:00.819655+00:00, run_duration=0.678164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1458, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:08:59.075558+00:00, queued_by_job_id=1230, pid=322948
[2024-09-27T18:09:01.262+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:36:00+00:00, run_after=2023-09-27 17:37:00+00:00
[2024-09-27T18:09:01.298+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:09:01.298+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:01.298+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:01.298+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:34:00+00:00 [scheduled]>
[2024-09-27T18:09:01.299+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:35:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:34:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:01.300+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:01.300+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:01.300+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:01.300+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:01.303+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:02.237+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:02.321+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:03.247+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:34:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:04.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:04.284+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:34:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:05.315+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:05.316+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:34:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:05.318+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:34:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:04.320029+00:00, run_end_date=2024-09-27 16:09:04.924990+00:00, run_duration=0.604961, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1460, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:01.299077+00:00, queued_by_job_id=1230, pid=322962
[2024-09-27T18:09:05.319+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:02.357429+00:00, run_end_date=2024-09-27 16:09:02.816411+00:00, run_duration=0.458982, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1459, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:01.299077+00:00, queued_by_job_id=1230, pid=322955
[2024-09-27T18:09:05.356+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:37:00+00:00, run_after=2023-09-27 17:38:00+00:00
[2024-09-27T18:09:05.390+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:34:00+00:00: scheduled__2023-09-27T17:34:00+00:00, state:running, queued_at: 2024-09-27 16:08:51.468018+00:00. externally triggered: False> successful
[2024-09-27T18:09:05.391+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:34:00+00:00, run_id=scheduled__2023-09-27T17:34:00+00:00, run_start_date=2024-09-27 16:08:51.479487+00:00, run_end_date=2024-09-27 16:09:05.391314+00:00, run_duration=13.911827, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:34:00+00:00, data_interval_end=2023-09-27 17:35:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:05.395+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:35:00+00:00, run_after=2023-09-27 17:36:00+00:00
[2024-09-27T18:09:05.409+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:05.410+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:05.410+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:05.410+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:05.413+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:35:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:05.413+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:05.413+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:05.414+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:05.414+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:05.417+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:06.318+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:06.402+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:07.278+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:08.217+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:08.301+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:09.300+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:09.301+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:09.305+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:06.433768+00:00, run_end_date=2024-09-27 16:09:06.877864+00:00, run_duration=0.444096, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1461, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:05.411658+00:00, queued_by_job_id=1230, pid=322969
[2024-09-27T18:09:09.305+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:08.337204+00:00, run_end_date=2024-09-27 16:09:08.908208+00:00, run_duration=0.571004, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1462, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:05.411658+00:00, queued_by_job_id=1230, pid=322976
[2024-09-27T18:09:09.326+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:36:00+00:00, run_after=2023-09-27 17:37:00+00:00
[2024-09-27T18:09:09.352+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:09.352+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:09.352+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:09.353+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:09.354+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:35:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:09.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:09.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:09.354+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:09.354+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:09.358+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:10.290+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:10.375+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:11.373+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:12.311+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:12.395+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:13.472+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:13.473+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:13.479+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:10.410534+00:00, run_end_date=2024-09-27 16:09:10.974695+00:00, run_duration=0.564161, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1463, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:09.353456+00:00, queued_by_job_id=1230, pid=322983
[2024-09-27T18:09:13.480+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:12.431679+00:00, run_end_date=2024-09-27 16:09:13.070318+00:00, run_duration=0.638639, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1464, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:09.353456+00:00, queued_by_job_id=1230, pid=322990
[2024-09-27T18:09:13.523+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:37:00+00:00, run_after=2023-09-27 17:38:00+00:00
[2024-09-27T18:09:13.563+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:13.563+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:13.563+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:13.564+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:35:00+00:00 [scheduled]>
[2024-09-27T18:09:13.566+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:36:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:35:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:13.567+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:13.567+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:13.568+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:13.568+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:13.572+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:14.514+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:14.599+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:16.118+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:17.050+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:17.135+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:35:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:18.608+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:18.609+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:35:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:18.614+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:14.635258+00:00, run_end_date=2024-09-27 16:09:15.733312+00:00, run_duration=1.098054, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1465, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:13.565303+00:00, queued_by_job_id=1230, pid=322999
[2024-09-27T18:09:18.615+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:35:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:17.172436+00:00, run_end_date=2024-09-27 16:09:18.191403+00:00, run_duration=1.018967, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1466, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:13.565303+00:00, queued_by_job_id=1230, pid=323008
[2024-09-27T18:09:18.668+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:38:00+00:00, run_after=2023-09-27 17:39:00+00:00
[2024-09-27T18:09:18.706+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:35:00+00:00: scheduled__2023-09-27T17:35:00+00:00, state:running, queued_at: 2024-09-27 16:09:01.256264+00:00. externally triggered: False> successful
[2024-09-27T18:09:18.707+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:35:00+00:00, run_id=scheduled__2023-09-27T17:35:00+00:00, run_start_date=2024-09-27 16:09:01.279642+00:00, run_end_date=2024-09-27 16:09:18.707291+00:00, run_duration=17.427649, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:35:00+00:00, data_interval_end=2023-09-27 17:36:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:18.712+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:36:00+00:00, run_after=2023-09-27 17:37:00+00:00
[2024-09-27T18:09:18.725+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
[2024-09-27T18:09:18.725+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:18.725+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:18.725+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:36:00+00:00 [scheduled]>
[2024-09-27T18:09:18.726+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:37:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:36:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:18.727+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:18.727+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:18.727+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:18.727+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:18.730+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:19.630+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:19.714+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:21.362+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:36:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:22.334+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:22.421+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:36:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:23.344+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:23.344+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:36:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:23.349+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:36:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:22.458469+00:00, run_end_date=2024-09-27 16:09:22.980164+00:00, run_duration=0.521695, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1468, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:18.726241+00:00, queued_by_job_id=1230, pid=323024
[2024-09-27T18:09:23.350+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:19.749783+00:00, run_end_date=2024-09-27 16:09:20.955565+00:00, run_duration=1.205782, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1467, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:18.726241+00:00, queued_by_job_id=1230, pid=323016
[2024-09-27T18:09:23.490+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:39:00+00:00, run_after=2023-09-27 17:40:00+00:00
[2024-09-27T18:09:23.514+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:36:00+00:00: scheduled__2023-09-27T17:36:00+00:00, state:running, queued_at: 2024-09-27 16:09:05.354115+00:00. externally triggered: False> successful
[2024-09-27T18:09:23.515+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:36:00+00:00, run_id=scheduled__2023-09-27T17:36:00+00:00, run_start_date=2024-09-27 16:09:05.363485+00:00, run_end_date=2024-09-27 16:09:23.515144+00:00, run_duration=18.151659, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:36:00+00:00, data_interval_end=2023-09-27 17:37:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:23.517+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:37:00+00:00, run_after=2023-09-27 17:38:00+00:00
[2024-09-27T18:09:23.525+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:23.525+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:23.525+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:23.525+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:23.527+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:23.527+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:23.527+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:23.527+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:23.527+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:23.530+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:24.470+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:24.554+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:25.670+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:26.577+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:26.661+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:27.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:27.905+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:27.908+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:24.585220+00:00, run_end_date=2024-09-27 16:09:25.264357+00:00, run_duration=0.679137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1469, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:23.526325+00:00, queued_by_job_id=1230, pid=323141
[2024-09-27T18:09:27.908+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:26.697164+00:00, run_end_date=2024-09-27 16:09:27.485976+00:00, run_duration=0.788812, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1470, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:23.526325+00:00, queued_by_job_id=1230, pid=323151
[2024-09-27T18:09:27.945+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:38:00+00:00, run_after=2023-09-27 17:39:00+00:00
[2024-09-27T18:09:27.966+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:27.967+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:27.967+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:27.967+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:27.968+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:27.968+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:27.968+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:27.969+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:27.969+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:27.972+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:28.906+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:28.990+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:30.042+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:30.974+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:31.059+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:32.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:32.538+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:32.543+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:29.026271+00:00, run_end_date=2024-09-27 16:09:29.663437+00:00, run_duration=0.637166, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1471, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:27.967702+00:00, queued_by_job_id=1230, pid=323162
[2024-09-27T18:09:32.544+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:31.094428+00:00, run_end_date=2024-09-27 16:09:32.122538+00:00, run_duration=1.02811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1472, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:27.967702+00:00, queued_by_job_id=1230, pid=323172
[2024-09-27T18:09:32.576+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:39:00+00:00, run_after=2023-09-27 17:40:00+00:00
[2024-09-27T18:09:32.620+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:32.621+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:32.621+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:32.622+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:37:00+00:00 [scheduled]>
[2024-09-27T18:09:32.624+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:32.625+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:32.625+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:32.626+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:32.626+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:32.629+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:33.571+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:33.656+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:35.104+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:36.012+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:36.098+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:37:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:37.988+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:37.988+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:37.994+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:33.692657+00:00, run_end_date=2024-09-27 16:09:34.678789+00:00, run_duration=0.986132, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1473, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:32.623161+00:00, queued_by_job_id=1230, pid=323200
[2024-09-27T18:09:37.995+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:36.136660+00:00, run_end_date=2024-09-27 16:09:37.552124+00:00, run_duration=1.415464, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1474, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:32.623161+00:00, queued_by_job_id=1230, pid=323207
[2024-09-27T18:09:38.054+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:40:00+00:00, run_after=2023-09-27 17:41:00+00:00
[2024-09-27T18:09:38.094+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:37:00+00:00: scheduled__2023-09-27T17:37:00+00:00, state:running, queued_at: 2024-09-27 16:09:18.661873+00:00. externally triggered: False> successful
[2024-09-27T18:09:38.095+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:37:00+00:00, run_id=scheduled__2023-09-27T17:37:00+00:00, run_start_date=2024-09-27 16:09:18.680192+00:00, run_end_date=2024-09-27 16:09:38.095241+00:00, run_duration=19.415049, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:37:00+00:00, data_interval_end=2023-09-27 17:38:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:38.100+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:38:00+00:00, run_after=2023-09-27 17:39:00+00:00
[2024-09-27T18:09:38.113+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
[2024-09-27T18:09:38.114+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:38.114+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:38.115+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:38:00+00:00 [scheduled]>
[2024-09-27T18:09:38.117+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:38.118+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:38.118+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:38.118+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:38.119+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:38.122+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:39.062+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:39.148+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:40.350+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:41.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:41.371+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:42.806+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:42.806+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:42.812+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:41.404381+00:00, run_end_date=2024-09-27 16:09:42.381551+00:00, run_duration=0.97717, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1476, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:38.115951+00:00, queued_by_job_id=1230, pid=323221
[2024-09-27T18:09:42.813+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:39.184749+00:00, run_end_date=2024-09-27 16:09:39.932157+00:00, run_duration=0.747408, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1475, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:38.115951+00:00, queued_by_job_id=1230, pid=323214
[2024-09-27T18:09:42.843+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:39:00+00:00, run_after=2023-09-27 17:40:00+00:00
[2024-09-27T18:09:42.861+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:38:00+00:00: scheduled__2023-09-27T17:38:00+00:00, state:running, queued_at: 2024-09-27 16:09:23.483129+00:00. externally triggered: False> successful
[2024-09-27T18:09:42.861+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:38:00+00:00, run_id=scheduled__2023-09-27T17:38:00+00:00, run_start_date=2024-09-27 16:09:23.499230+00:00, run_end_date=2024-09-27 16:09:42.861414+00:00, run_duration=19.362184, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:38:00+00:00, data_interval_end=2023-09-27 17:39:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:42.863+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:39:00+00:00, run_after=2023-09-27 17:40:00+00:00
[2024-09-27T18:09:42.870+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:42.870+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:42.870+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:42.871+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:42.871+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:42.871+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:42.874+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:43.824+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:43.909+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:44.870+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:44.873+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:43.946777+00:00, run_end_date=2024-09-27 16:09:44.445097+00:00, run_duration=0.49832, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1477, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:42.870715+00:00, queued_by_job_id=1230, pid=323230
[2024-09-27T18:09:44.906+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:40:00+00:00, run_after=2023-09-27 17:41:00+00:00
[2024-09-27T18:09:44.925+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:44.925+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:44.925+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:44.926+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:44.926+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:44.927+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:44.930+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:45.879+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:45.966+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:46.926+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:46.932+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:46.005230+00:00, run_end_date=2024-09-27 16:09:46.513504+00:00, run_duration=0.508274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1478, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:44.926050+00:00, queued_by_job_id=1230, pid=323237
[2024-09-27T18:09:46.956+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:41:00+00:00, run_after=2023-09-27 17:42:00+00:00
[2024-09-27T18:09:47.005+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:47.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:47.006+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:47.007+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:39:00+00:00 [scheduled]>
[2024-09-27T18:09:47.009+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:47.009+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:47.009+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:47.010+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:09:47.010+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:47.014+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:47.953+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:48.037+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:49.006+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:49.944+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:50.028+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:50.901+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:50.901+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:50.907+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:50.064715+00:00, run_end_date=2024-09-27 16:09:50.480837+00:00, run_duration=0.416122, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1480, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:09:47.007903+00:00, queued_by_job_id=1230, pid=323252
[2024-09-27T18:09:50.908+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:48.072819+00:00, run_end_date=2024-09-27 16:09:48.628158+00:00, run_duration=0.555339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1479, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:47.007903+00:00, queued_by_job_id=1230, pid=323244
[2024-09-27T18:09:50.956+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:42:00+00:00, run_after=2023-09-27 17:43:00+00:00
[2024-09-27T18:09:50.998+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:39:00+00:00: scheduled__2023-09-27T17:39:00+00:00, state:running, queued_at: 2024-09-27 16:09:38.047824+00:00. externally triggered: False> successful
[2024-09-27T18:09:50.998+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:39:00+00:00, run_id=scheduled__2023-09-27T17:39:00+00:00, run_start_date=2024-09-27 16:09:38.065660+00:00, run_end_date=2024-09-27 16:09:50.998739+00:00, run_duration=12.933079, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:39:00+00:00, data_interval_end=2023-09-27 17:40:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:09:51.003+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:40:00+00:00, run_after=2023-09-27 17:41:00+00:00
[2024-09-27T18:09:51.017+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:09:51.018+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:51.018+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:51.019+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:09:51.021+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:51.021+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:51.022+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:51.022+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:51.022+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:51.026+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:51.972+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:52.057+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:52.869+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:53.819+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:53.908+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:55.055+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:55.056+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:09:55.061+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:53.947331+00:00, run_end_date=2024-09-27 16:09:54.654578+00:00, run_duration=0.707247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1482, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:51.019976+00:00, queued_by_job_id=1230, pid=323267
[2024-09-27T18:09:55.062+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:52.092763+00:00, run_end_date=2024-09-27 16:09:52.463052+00:00, run_duration=0.370289, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1481, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:51.019976+00:00, queued_by_job_id=1230, pid=323259
[2024-09-27T18:09:55.202+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:43:00+00:00, run_after=2023-09-27 17:44:00+00:00
[2024-09-27T18:09:55.259+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:09:55.260+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:09:55.260+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:09:55.260+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:09:55.261+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:09:55.264+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:09:55.264+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:09:55.265+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:55.265+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:09:55.265+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:55.266+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:09:55.266+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:55.270+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:56.221+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:56.313+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:57.268+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:09:58.203+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:09:58.287+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:09:59.495+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:00.460+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:00.553+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:01.518+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:01.518+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:01.518+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:01.524+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:56.351249+00:00, run_end_date=2024-09-27 16:09:56.874840+00:00, run_duration=0.523591, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1483, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:09:55.262405+00:00, queued_by_job_id=1230, pid=323275
[2024-09-27T18:10:01.525+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:00.594209+00:00, run_end_date=2024-09-27 16:10:01.099553+00:00, run_duration=0.505344, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1485, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:09:55.262405+00:00, queued_by_job_id=1230, pid=323290
[2024-09-27T18:10:01.526+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:09:58.324032+00:00, run_end_date=2024-09-27 16:09:59.065333+00:00, run_duration=0.741301, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1484, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:09:55.262405+00:00, queued_by_job_id=1230, pid=323283
[2024-09-27T18:10:01.574+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:44:00+00:00, run_after=2023-09-27 17:45:00+00:00
[2024-09-27T18:10:01.637+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:10:01.637+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:01.638+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:01.638+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:10:01.639+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:10:01.639+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:40:00+00:00 [scheduled]>
[2024-09-27T18:10:01.642+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:01.643+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:01.643+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:01.644+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:01.644+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:01.644+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:01.645+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:01.645+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:01.645+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:01.649+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:02.610+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:02.700+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:03.451+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:04.372+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:04.461+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:05.281+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:06.216+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:06.303+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:07.187+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:08.112+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:08.199+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:09.264+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:09.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:09.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:09.265+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:09.269+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:04.500462+00:00, run_end_date=2024-09-27 16:10:04.819767+00:00, run_duration=0.319305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1487, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:01.640793+00:00, queued_by_job_id=1230, pid=323306
[2024-09-27T18:10:09.269+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:06.341376+00:00, run_end_date=2024-09-27 16:10:06.783379+00:00, run_duration=0.442003, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1488, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:01.640793+00:00, queued_by_job_id=1230, pid=323313
[2024-09-27T18:10:09.269+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:08.238443+00:00, run_end_date=2024-09-27 16:10:08.847997+00:00, run_duration=0.609554, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1489, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:01.640793+00:00, queued_by_job_id=1230, pid=323320
[2024-09-27T18:10:09.270+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:02.737737+00:00, run_end_date=2024-09-27 16:10:03.039553+00:00, run_duration=0.301816, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1486, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:01.640793+00:00, queued_by_job_id=1230, pid=323299
[2024-09-27T18:10:09.315+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:45:00+00:00, run_after=2023-09-27 17:46:00+00:00
[2024-09-27T18:10:09.347+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:40:00+00:00: scheduled__2023-09-27T17:40:00+00:00, state:running, queued_at: 2024-09-27 16:09:46.953461+00:00. externally triggered: False> successful
[2024-09-27T18:10:09.347+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:40:00+00:00, run_id=scheduled__2023-09-27T17:40:00+00:00, run_start_date=2024-09-27 16:09:46.971405+00:00, run_end_date=2024-09-27 16:10:09.347601+00:00, run_duration=22.376196, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:40:00+00:00, data_interval_end=2023-09-27 17:41:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:09.350+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:41:00+00:00, run_after=2023-09-27 17:42:00+00:00
[2024-09-27T18:10:09.359+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
[2024-09-27T18:10:09.359+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:09.360+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:09.360+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:10:09.360+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:10:09.360+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:41:00+00:00 [scheduled]>
[2024-09-27T18:10:09.361+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:09.362+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:09.362+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:09.362+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:09.362+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:09.362+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:09.363+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:09.363+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:09.363+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:09.366+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:10.310+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:10.398+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:11.440+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:12.406+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:12.496+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:13.367+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:14.308+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:14.395+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:15.308+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:16.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:16.374+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:17.149+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:17.149+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:17.150+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:17.150+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:17.156+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:14.432594+00:00, run_end_date=2024-09-27 16:10:14.910228+00:00, run_duration=0.477634, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1492, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:09.361002+00:00, queued_by_job_id=1230, pid=323344
[2024-09-27T18:10:17.157+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:16.405522+00:00, run_end_date=2024-09-27 16:10:16.730478+00:00, run_duration=0.324956, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1493, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:09.361002+00:00, queued_by_job_id=1230, pid=323353
[2024-09-27T18:10:17.158+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:10.437719+00:00, run_end_date=2024-09-27 16:10:11.046989+00:00, run_duration=0.60927, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1490, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:09.361002+00:00, queued_by_job_id=1230, pid=323327
[2024-09-27T18:10:17.158+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:12.535250+00:00, run_end_date=2024-09-27 16:10:12.983688+00:00, run_duration=0.448438, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1491, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:09.361002+00:00, queued_by_job_id=1230, pid=323334
[2024-09-27T18:10:17.182+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:10:17.213+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:42:00+00:00, run_after=2023-09-27 17:43:00+00:00
[2024-09-27T18:10:17.231+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:41:00+00:00: scheduled__2023-09-27T17:41:00+00:00, state:running, queued_at: 2024-09-27 16:09:50.950342+00:00. externally triggered: False> successful
[2024-09-27T18:10:17.231+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:41:00+00:00, run_id=scheduled__2023-09-27T17:41:00+00:00, run_start_date=2024-09-27 16:09:50.969443+00:00, run_end_date=2024-09-27 16:10:17.231465+00:00, run_duration=26.262022, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:41:00+00:00, data_interval_end=2023-09-27 17:42:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:17.233+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:42:00+00:00, run_after=2023-09-27 17:43:00+00:00
[2024-09-27T18:10:17.241+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
[2024-09-27T18:10:17.241+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:17.241+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:17.241+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:10:17.242+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:42:00+00:00 [scheduled]>
[2024-09-27T18:10:17.243+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:42:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:17.243+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:17.243+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:17.243+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:17.244+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:17.244+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:17.244+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:17.247+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:18.194+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:18.281+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:19.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:20.025+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:20.115+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:20.978+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:21.929+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:22.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:22.951+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:22.951+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:22.952+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:22.958+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:22.055378+00:00, run_end_date=2024-09-27 16:10:22.529751+00:00, run_duration=0.474373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1496, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:17.242526+00:00, queued_by_job_id=1230, pid=323375
[2024-09-27T18:10:22.959+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:18.316919+00:00, run_end_date=2024-09-27 16:10:18.657328+00:00, run_duration=0.340409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1494, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:17.242526+00:00, queued_by_job_id=1230, pid=323360
[2024-09-27T18:10:22.960+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:20.153873+00:00, run_end_date=2024-09-27 16:10:20.535839+00:00, run_duration=0.381966, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1495, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:17.242526+00:00, queued_by_job_id=1230, pid=323368
[2024-09-27T18:10:23.005+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:43:00+00:00, run_after=2023-09-27 17:44:00+00:00
[2024-09-27T18:10:23.036+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:42:00+00:00: scheduled__2023-09-27T17:42:00+00:00, state:running, queued_at: 2024-09-27 16:09:55.195796+00:00. externally triggered: False> successful
[2024-09-27T18:10:23.036+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:42:00+00:00, run_id=scheduled__2023-09-27T17:42:00+00:00, run_start_date=2024-09-27 16:09:55.214456+00:00, run_end_date=2024-09-27 16:10:23.036894+00:00, run_duration=27.822438, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:42:00+00:00, data_interval_end=2023-09-27 17:43:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:23.041+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:43:00+00:00, run_after=2023-09-27 17:44:00+00:00
[2024-09-27T18:10:23.054+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
[2024-09-27T18:10:23.054+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:23.055+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:23.055+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:43:00+00:00 [scheduled]>
[2024-09-27T18:10:23.058+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:23.058+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:23.059+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:23.059+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:23.059+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:23.063+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:24.031+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:24.117+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:25.293+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:26.226+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:26.313+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:27.387+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:27.388+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:27.393+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:24.154650+00:00, run_end_date=2024-09-27 16:10:24.852751+00:00, run_duration=0.698101, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1497, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:23.056703+00:00, queued_by_job_id=1230, pid=323382
[2024-09-27T18:10:27.393+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:26.350912+00:00, run_end_date=2024-09-27 16:10:26.990279+00:00, run_duration=0.639367, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1498, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:23.056703+00:00, queued_by_job_id=1230, pid=323389
[2024-09-27T18:10:27.526+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:46:00+00:00, run_after=2023-09-27 17:47:00+00:00
[2024-09-27T18:10:27.548+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:43:00+00:00: scheduled__2023-09-27T17:43:00+00:00, state:running, queued_at: 2024-09-27 16:10:01.568321+00:00. externally triggered: False> successful
[2024-09-27T18:10:27.549+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:43:00+00:00, run_id=scheduled__2023-09-27T17:43:00+00:00, run_start_date=2024-09-27 16:10:01.585713+00:00, run_end_date=2024-09-27 16:10:27.549144+00:00, run_duration=25.963431, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:43:00+00:00, data_interval_end=2023-09-27 17:44:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:27.551+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:44:00+00:00, run_after=2023-09-27 17:45:00+00:00
[2024-09-27T18:10:27.559+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
[2024-09-27T18:10:27.559+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:27.560+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:27.560+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:44:00+00:00 [scheduled]>
[2024-09-27T18:10:27.561+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:27.561+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:27.561+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:27.562+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:27.562+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:27.565+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:28.536+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:28.627+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:29.518+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:30.511+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:30.598+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:31.358+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:31.358+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:31.361+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:30.638202+00:00, run_end_date=2024-09-27 16:10:30.965539+00:00, run_duration=0.327337, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1500, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:27.560656+00:00, queued_by_job_id=1230, pid=323418
[2024-09-27T18:10:31.361+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:28.662962+00:00, run_end_date=2024-09-27 16:10:29.098536+00:00, run_duration=0.435574, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1499, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:27.560656+00:00, queued_by_job_id=1230, pid=323397
[2024-09-27T18:10:31.396+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:45:00+00:00, run_after=2023-09-27 17:46:00+00:00
[2024-09-27T18:10:31.420+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:44:00+00:00: scheduled__2023-09-27T17:44:00+00:00, state:running, queued_at: 2024-09-27 16:10:09.309700+00:00. externally triggered: False> successful
[2024-09-27T18:10:31.421+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:44:00+00:00, run_id=scheduled__2023-09-27T17:44:00+00:00, run_start_date=2024-09-27 16:10:09.324001+00:00, run_end_date=2024-09-27 16:10:31.421109+00:00, run_duration=22.097108, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:44:00+00:00, data_interval_end=2023-09-27 17:45:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:31.423+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:45:00+00:00, run_after=2023-09-27 17:46:00+00:00
[2024-09-27T18:10:31.429+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:31.430+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:31.430+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:31.431+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:31.431+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:31.431+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:31.434+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:32.386+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:32.492+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:33.296+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:33.301+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:32.537581+00:00, run_end_date=2024-09-27 16:10:32.876070+00:00, run_duration=0.338489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1501, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:31.430493+00:00, queued_by_job_id=1230, pid=323425
[2024-09-27T18:10:33.337+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:46:00+00:00, run_after=2023-09-27 17:47:00+00:00
[2024-09-27T18:10:33.376+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:33.376+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:33.377+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:33.378+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:33.379+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:33.379+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:33.383+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:34.327+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:34.412+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:35.179+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:35.184+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:34.448554+00:00, run_end_date=2024-09-27 16:10:34.816272+00:00, run_duration=0.367718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1502, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:33.377806+00:00, queued_by_job_id=1230, pid=323433
[2024-09-27T18:10:35.217+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:47:00+00:00, run_after=2023-09-27 17:48:00+00:00
[2024-09-27T18:10:35.269+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:35.270+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:35.270+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:35.271+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:45:00+00:00 [scheduled]>
[2024-09-27T18:10:35.273+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:35.274+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:35.274+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:35.274+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:35.275+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:35.278+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:36.229+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:36.314+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:37.276+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:38.213+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:38.298+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:39.331+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:39.331+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:39.335+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:36.350335+00:00, run_end_date=2024-09-27 16:10:36.866876+00:00, run_duration=0.516541, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1503, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:35.272101+00:00, queued_by_job_id=1230, pid=323440
[2024-09-27T18:10:39.335+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:38.335567+00:00, run_end_date=2024-09-27 16:10:38.926906+00:00, run_duration=0.591339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1504, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:35.272101+00:00, queued_by_job_id=1230, pid=323447
[2024-09-27T18:10:39.376+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:48:00+00:00, run_after=2023-09-27 17:49:00+00:00
[2024-09-27T18:10:39.399+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:45:00+00:00: scheduled__2023-09-27T17:45:00+00:00, state:running, queued_at: 2024-09-27 16:10:27.520572+00:00. externally triggered: False> successful
[2024-09-27T18:10:39.399+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:45:00+00:00, run_id=scheduled__2023-09-27T17:45:00+00:00, run_start_date=2024-09-27 16:10:27.533518+00:00, run_end_date=2024-09-27 16:10:39.399387+00:00, run_duration=11.865869, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:45:00+00:00, data_interval_end=2023-09-27 17:46:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:39.401+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:46:00+00:00, run_after=2023-09-27 17:47:00+00:00
[2024-09-27T18:10:39.409+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:39.409+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:39.409+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:39.409+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:39.410+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:39.411+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:39.411+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:39.411+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:39.411+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:39.414+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:40.350+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:40.435+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:41.486+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:42.425+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:42.510+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:43.591+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:43.592+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:43.597+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:42.546976+00:00, run_end_date=2024-09-27 16:10:43.167425+00:00, run_duration=0.620449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1506, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:39.410296+00:00, queued_by_job_id=1230, pid=323461
[2024-09-27T18:10:43.598+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:40.471271+00:00, run_end_date=2024-09-27 16:10:41.115794+00:00, run_duration=0.644523, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1505, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:39.410296+00:00, queued_by_job_id=1230, pid=323454
[2024-09-27T18:10:43.628+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:47:00+00:00, run_after=2023-09-27 17:48:00+00:00
[2024-09-27T18:10:43.673+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:43.674+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:43.674+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:43.675+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:43.677+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:43.677+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:43.678+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:43.678+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:43.678+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:43.682+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:44.619+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:44.704+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:45.748+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:46.707+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:46.792+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:47.655+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:47.656+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:47.661+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:46.829091+00:00, run_end_date=2024-09-27 16:10:47.271027+00:00, run_duration=0.441936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1508, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:43.675938+00:00, queued_by_job_id=1230, pid=323476
[2024-09-27T18:10:47.662+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:44.740501+00:00, run_end_date=2024-09-27 16:10:45.354560+00:00, run_duration=0.614059, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1507, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:43.675938+00:00, queued_by_job_id=1230, pid=323468
[2024-09-27T18:10:47.700+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:48:00+00:00, run_after=2023-09-27 17:49:00+00:00
[2024-09-27T18:10:47.719+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:47.719+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:47.720+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:47.720+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:46:00+00:00 [scheduled]>
[2024-09-27T18:10:47.721+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:47:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:47.721+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:47.721+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:47.721+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:47.722+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:47.724+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:48.694+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:48.785+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:49.625+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:50.565+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:50.650+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:51.522+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:51.522+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:51.528+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:50.700165+00:00, run_end_date=2024-09-27 16:10:51.152029+00:00, run_duration=0.451864, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1510, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:47.720670+00:00, queued_by_job_id=1230, pid=323516
[2024-09-27T18:10:51.529+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:48.823595+00:00, run_end_date=2024-09-27 16:10:49.195266+00:00, run_duration=0.371671, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1509, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:47.720670+00:00, queued_by_job_id=1230, pid=323484
[2024-09-27T18:10:51.564+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:49:00+00:00, run_after=2023-09-27 17:50:00+00:00
[2024-09-27T18:10:51.607+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:46:00+00:00: scheduled__2023-09-27T17:46:00+00:00, state:running, queued_at: 2024-09-27 16:10:35.210970+00:00. externally triggered: False> successful
[2024-09-27T18:10:51.608+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:46:00+00:00, run_id=scheduled__2023-09-27T17:46:00+00:00, run_start_date=2024-09-27 16:10:35.234700+00:00, run_end_date=2024-09-27 16:10:51.608121+00:00, run_duration=16.373421, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:46:00+00:00, data_interval_end=2023-09-27 17:47:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:51.612+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:47:00+00:00, run_after=2023-09-27 17:48:00+00:00
[2024-09-27T18:10:51.625+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
[2024-09-27T18:10:51.626+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:51.626+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:51.627+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:47:00+00:00 [scheduled]>
[2024-09-27T18:10:51.629+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:51.630+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:51.630+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:51.631+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:10:51.631+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:51.635+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:52.555+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:52.642+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:53.373+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:54.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:54.422+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:55.290+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:55.291+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:55.296+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:54.457901+00:00, run_end_date=2024-09-27 16:10:54.896498+00:00, run_duration=0.438597, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1512, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:10:51.628156+00:00, queued_by_job_id=1230, pid=323538
[2024-09-27T18:10:55.297+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:52.680815+00:00, run_end_date=2024-09-27 16:10:52.996012+00:00, run_duration=0.315197, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1511, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:51.628156+00:00, queued_by_job_id=1230, pid=323529
[2024-09-27T18:10:55.344+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:48:00+00:00, run_after=2023-09-27 17:49:00+00:00
[2024-09-27T18:10:55.370+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:47:00+00:00: scheduled__2023-09-27T17:47:00+00:00, state:running, queued_at: 2024-09-27 16:10:39.373912+00:00. externally triggered: False> successful
[2024-09-27T18:10:55.370+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:47:00+00:00, run_id=scheduled__2023-09-27T17:47:00+00:00, run_start_date=2024-09-27 16:10:39.383738+00:00, run_end_date=2024-09-27 16:10:55.370781+00:00, run_duration=15.987043, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:47:00+00:00, data_interval_end=2023-09-27 17:48:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:10:55.375+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:48:00+00:00, run_after=2023-09-27 17:49:00+00:00
[2024-09-27T18:10:55.388+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:10:55.388+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:55.389+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:10:55.391+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:55.391+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:10:55.391+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:55.395+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:56.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:56.420+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:57.498+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:10:57.503+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:56.451979+00:00, run_end_date=2024-09-27 16:10:57.083809+00:00, run_duration=0.63183, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1513, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:10:55.389791+00:00, queued_by_job_id=1230, pid=323545
[2024-09-27T18:10:57.644+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:50:00+00:00, run_after=2023-09-27 17:51:00+00:00
[2024-09-27T18:10:57.693+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:10:57.694+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:10:57.694+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:10:57.695+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:10:57.697+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:10:57.698+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:10:57.698+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:57.699+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:10:57.699+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:57.703+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:10:58.646+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:10:58.732+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:10:59.935+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:00.888+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:00.972+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:01.930+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:01.931+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:01.936+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:10:58.768265+00:00, run_end_date=2024-09-27 16:10:59.520359+00:00, run_duration=0.752094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1514, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:10:57.695933+00:00, queued_by_job_id=1230, pid=323554
[2024-09-27T18:11:01.937+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:01.008715+00:00, run_end_date=2024-09-27 16:11:01.522911+00:00, run_duration=0.514196, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1515, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:10:57.695933+00:00, queued_by_job_id=1230, pid=323563
[2024-09-27T18:11:01.987+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:51:00+00:00, run_after=2023-09-27 17:52:00+00:00
[2024-09-27T18:11:02.045+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:11:02.046+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:02.046+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:02.046+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:02.047+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:48:00+00:00 [scheduled]>
[2024-09-27T18:11:02.050+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:02.050+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:02.051+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:02.051+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:02.051+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:02.052+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:02.052+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:02.056+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:02.981+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:03.066+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:04.618+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:05.573+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:05.657+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:07.022+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:07.930+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:08.014+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:09.098+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:09.098+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:09.099+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:09.105+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:05.693162+00:00, run_end_date=2024-09-27 16:11:06.623802+00:00, run_duration=0.93064, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1517, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:02.048307+00:00, queued_by_job_id=1230, pid=323577
[2024-09-27T18:11:09.106+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:03.102863+00:00, run_end_date=2024-09-27 16:11:04.216677+00:00, run_duration=1.113814, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1516, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:02.048307+00:00, queued_by_job_id=1230, pid=323570
[2024-09-27T18:11:09.106+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:08.052499+00:00, run_end_date=2024-09-27 16:11:08.726044+00:00, run_duration=0.673545, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1518, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:02.048307+00:00, queued_by_job_id=1230, pid=323584
[2024-09-27T18:11:09.162+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:52:00+00:00, run_after=2023-09-27 17:53:00+00:00
[2024-09-27T18:11:09.211+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:48:00+00:00: scheduled__2023-09-27T17:48:00+00:00, state:running, queued_at: 2024-09-27 16:10:51.558623+00:00. externally triggered: False> successful
[2024-09-27T18:11:09.211+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:48:00+00:00, run_id=scheduled__2023-09-27T17:48:00+00:00, run_start_date=2024-09-27 16:10:51.581589+00:00, run_end_date=2024-09-27 16:11:09.211851+00:00, run_duration=17.630262, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:48:00+00:00, data_interval_end=2023-09-27 17:49:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:09.216+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:49:00+00:00, run_after=2023-09-27 17:50:00+00:00
[2024-09-27T18:11:09.230+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
[2024-09-27T18:11:09.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:09.230+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:09.231+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:09.231+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
[2024-09-27T18:11:09.233+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:09.233+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:09.233+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:09.234+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:09.234+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:09.234+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:09.234+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:09.237+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:10.190+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:10.275+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:11.366+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:12.275+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:12.359+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:13.240+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:14.174+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:14.259+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:15.702+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:15.703+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:15.703+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:15.709+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:14.296061+00:00, run_end_date=2024-09-27 16:11:15.282077+00:00, run_duration=0.986016, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1521, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:09.232588+00:00, queued_by_job_id=1230, pid=323606
[2024-09-27T18:11:15.710+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:12.395372+00:00, run_end_date=2024-09-27 16:11:12.822980+00:00, run_duration=0.427608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1520, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:09.232588+00:00, queued_by_job_id=1230, pid=323598
[2024-09-27T18:11:15.711+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:10.311775+00:00, run_end_date=2024-09-27 16:11:10.924927+00:00, run_duration=0.613152, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1519, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:09.232588+00:00, queued_by_job_id=1230, pid=323591
[2024-09-27T18:11:15.754+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:50:00+00:00, run_after=2023-09-27 17:51:00+00:00
[2024-09-27T18:11:15.800+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
[2024-09-27T18:11:15.800+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:15.801+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:15.801+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:15.802+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:49:00+00:00 [scheduled]>
[2024-09-27T18:11:15.804+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:15.805+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:15.805+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:15.806+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:15.806+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:15.806+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:15.807+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:15.811+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:16.746+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:16.831+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:17.831+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:18.772+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:18.857+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:20.300+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:21.267+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:21.354+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:22.742+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:22.742+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:22.742+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:22.749+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:21.386544+00:00, run_end_date=2024-09-27 16:11:22.349242+00:00, run_duration=0.962698, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1524, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:15.803148+00:00, queued_by_job_id=1230, pid=323630
[2024-09-27T18:11:22.750+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:18.892661+00:00, run_end_date=2024-09-27 16:11:19.891961+00:00, run_duration=0.9993, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1523, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:15.803148+00:00, queued_by_job_id=1230, pid=323623
[2024-09-27T18:11:22.750+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:16.867064+00:00, run_end_date=2024-09-27 16:11:17.433633+00:00, run_duration=0.566569, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1522, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:15.803148+00:00, queued_by_job_id=1230, pid=323615
[2024-09-27T18:11:22.798+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:51:00+00:00, run_after=2023-09-27 17:52:00+00:00
[2024-09-27T18:11:22.829+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:49:00+00:00: scheduled__2023-09-27T17:49:00+00:00, state:running, queued_at: 2024-09-27 16:10:57.638566+00:00. externally triggered: False> successful
[2024-09-27T18:11:22.830+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:49:00+00:00, run_id=scheduled__2023-09-27T17:49:00+00:00, run_start_date=2024-09-27 16:10:57.656987+00:00, run_end_date=2024-09-27 16:11:22.830212+00:00, run_duration=25.173225, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:49:00+00:00, data_interval_end=2023-09-27 17:50:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:22.835+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:50:00+00:00, run_after=2023-09-27 17:51:00+00:00
[2024-09-27T18:11:22.848+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
[2024-09-27T18:11:22.849+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:22.849+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:22.850+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:50:00+00:00 [scheduled]>
[2024-09-27T18:11:22.852+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:51:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:50:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:22.853+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:22.853+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:22.854+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:22.854+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:22.859+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:23.791+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:23.877+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:24.995+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:25.932+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:26.016+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:27.537+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:27.538+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:27.543+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:26.052775+00:00, run_end_date=2024-09-27 16:11:27.146564+00:00, run_duration=1.093789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1526, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:22.851048+00:00, queued_by_job_id=1230, pid=323644
[2024-09-27T18:11:27.544+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:23.912942+00:00, run_end_date=2024-09-27 16:11:24.603167+00:00, run_duration=0.690225, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1525, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:22.851048+00:00, queued_by_job_id=1230, pid=323637
[2024-09-27T18:11:27.575+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:51:00+00:00, run_after=2023-09-27 17:52:00+00:00
[2024-09-27T18:11:27.603+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:50:00+00:00: scheduled__2023-09-27T17:50:00+00:00, state:running, queued_at: 2024-09-27 16:11:01.981075+00:00. externally triggered: False> successful
[2024-09-27T18:11:27.603+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:50:00+00:00, run_id=scheduled__2023-09-27T17:50:00+00:00, run_start_date=2024-09-27 16:11:02.000146+00:00, run_end_date=2024-09-27 16:11:27.603820+00:00, run_duration=25.603674, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:50:00+00:00, data_interval_end=2023-09-27 17:51:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:27.608+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:51:00+00:00, run_after=2023-09-27 17:52:00+00:00
[2024-09-27T18:11:27.621+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
[2024-09-27T18:11:27.621+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:27.622+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:51:00+00:00 [scheduled]>
[2024-09-27T18:11:27.624+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:27.624+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:27.625+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:27.628+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:28.564+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:28.648+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:29.792+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:29.796+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:28.684749+00:00, run_end_date=2024-09-27 16:11:29.417703+00:00, run_duration=0.732954, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1527, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:27.623052+00:00, queued_by_job_id=1230, pid=323651
[2024-09-27T18:11:29.947+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:53:00+00:00, run_after=2023-09-27 17:54:00+00:00
[2024-09-27T18:11:29.982+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:51:00+00:00: scheduled__2023-09-27T17:51:00+00:00, state:running, queued_at: 2024-09-27 16:11:09.155831+00:00. externally triggered: False> successful
[2024-09-27T18:11:29.983+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:51:00+00:00, run_id=scheduled__2023-09-27T17:51:00+00:00, run_start_date=2024-09-27 16:11:09.174200+00:00, run_end_date=2024-09-27 16:11:29.982935+00:00, run_duration=20.808735, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:51:00+00:00, data_interval_end=2023-09-27 17:52:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:29.987+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:52:00+00:00, run_after=2023-09-27 17:53:00+00:00
[2024-09-27T18:11:29.995+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:29.995+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:29.995+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:29.996+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:29.997+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:29.997+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:30.000+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:30.934+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:31.019+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:31.898+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:31.904+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:31.054791+00:00, run_end_date=2024-09-27 16:11:31.492673+00:00, run_duration=0.437882, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1528, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:29.996197+00:00, queued_by_job_id=1230, pid=323659
[2024-09-27T18:11:31.933+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:53:00+00:00, run_after=2023-09-27 17:54:00+00:00
[2024-09-27T18:11:31.972+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:31.972+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:31.973+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:31.975+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:31.975+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:31.975+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:31.979+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:32.909+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:32.993+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:33.995+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:34.000+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:33.029958+00:00, run_end_date=2024-09-27 16:11:33.562791+00:00, run_duration=0.532833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1529, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:31.973761+00:00, queued_by_job_id=1230, pid=323666
[2024-09-27T18:11:34.037+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:54:00+00:00, run_after=2023-09-27 17:55:00+00:00
[2024-09-27T18:11:34.091+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:34.092+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:34.092+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:34.093+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:34.095+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:34.096+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:34.096+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:34.096+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:34.097+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:34.101+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:35.011+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:35.097+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:36.096+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:37.034+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:37.119+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:38.599+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:38.600+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:38.605+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:37.156184+00:00, run_end_date=2024-09-27 16:11:38.195045+00:00, run_duration=1.038861, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1531, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:34.094110+00:00, queued_by_job_id=1230, pid=323681
[2024-09-27T18:11:38.605+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:35.132684+00:00, run_end_date=2024-09-27 16:11:35.700834+00:00, run_duration=0.56815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1530, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:34.094110+00:00, queued_by_job_id=1230, pid=323674
[2024-09-27T18:11:38.652+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:55:00+00:00, run_after=2023-09-27 17:56:00+00:00
[2024-09-27T18:11:38.686+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:38.686+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:38.686+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:38.687+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:38.687+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:52:00+00:00 [scheduled]>
[2024-09-27T18:11:38.688+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:38.688+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:38.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:38.688+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:38.689+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:38.689+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:38.689+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:38.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:39.601+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:39.687+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:40.527+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:41.467+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:41.552+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:43.036+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:43.973+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:44.058+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:45.173+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:45.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:45.174+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:45.180+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:44.094620+00:00, run_end_date=2024-09-27 16:11:44.784066+00:00, run_duration=0.689446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1534, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:38.687687+00:00, queued_by_job_id=1230, pid=323702
[2024-09-27T18:11:45.181+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:41.588187+00:00, run_end_date=2024-09-27 16:11:42.624077+00:00, run_duration=1.03589, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1533, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:38.687687+00:00, queued_by_job_id=1230, pid=323695
[2024-09-27T18:11:45.182+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:39.723505+00:00, run_end_date=2024-09-27 16:11:40.109357+00:00, run_duration=0.385852, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1532, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:38.687687+00:00, queued_by_job_id=1230, pid=323688
[2024-09-27T18:11:45.248+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:56:00+00:00, run_after=2023-09-27 17:57:00+00:00
[2024-09-27T18:11:45.295+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:52:00+00:00: scheduled__2023-09-27T17:52:00+00:00, state:running, queued_at: 2024-09-27 16:11:29.941121+00:00. externally triggered: False> successful
[2024-09-27T18:11:45.296+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:52:00+00:00, run_id=scheduled__2023-09-27T17:52:00+00:00, run_start_date=2024-09-27 16:11:29.959864+00:00, run_end_date=2024-09-27 16:11:45.296568+00:00, run_duration=15.336704, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:52:00+00:00, data_interval_end=2023-09-27 17:53:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:45.301+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:53:00+00:00, run_after=2023-09-27 17:54:00+00:00
[2024-09-27T18:11:45.310+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
[2024-09-27T18:11:45.310+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:45.310+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:45.310+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:45.310+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
[2024-09-27T18:11:45.311+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:11:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:45.312+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:45.312+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:45.315+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:46.248+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:46.332+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:47.329+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:48.264+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:48.348+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:49.379+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:50.313+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:50.397+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:51.232+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:51.232+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:51.233+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:51.239+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:46.364926+00:00, run_end_date=2024-09-27 16:11:46.935660+00:00, run_duration=0.570734, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1535, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:11:45.311148+00:00, queued_by_job_id=1230, pid=323709
[2024-09-27T18:11:51.240+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:50.434348+00:00, run_end_date=2024-09-27 16:11:50.829706+00:00, run_duration=0.395358, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1537, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:45.311148+00:00, queued_by_job_id=1230, pid=323724
[2024-09-27T18:11:51.240+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:48.384981+00:00, run_end_date=2024-09-27 16:11:48.966810+00:00, run_duration=0.581829, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1536, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:45.311148+00:00, queued_by_job_id=1230, pid=323716
[2024-09-27T18:11:51.284+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:54:00+00:00, run_after=2023-09-27 17:55:00+00:00
[2024-09-27T18:11:51.331+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
[2024-09-27T18:11:51.332+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:51.332+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:51.332+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:11:51.333+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:53:00+00:00 [scheduled]>
[2024-09-27T18:11:51.336+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:51.336+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:11:51.337+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:51.337+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:51.337+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:51.338+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:51.338+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:51.342+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:52.272+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:52.356+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:53.355+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:54.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:54.370+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:55.244+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:56.181+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:56.266+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:57.498+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:57.499+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:57.499+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:11:57.506+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:52.391602+00:00, run_end_date=2024-09-27 16:11:52.955191+00:00, run_duration=0.563589, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1538, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:11:51.334442+00:00, queued_by_job_id=1230, pid=323731
[2024-09-27T18:11:57.506+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:56.302501+00:00, run_end_date=2024-09-27 16:11:57.084904+00:00, run_duration=0.782403, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1540, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:51.334442+00:00, queued_by_job_id=1230, pid=323747
[2024-09-27T18:11:57.507+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:54.406258+00:00, run_end_date=2024-09-27 16:11:54.823330+00:00, run_duration=0.417072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1539, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:51.334442+00:00, queued_by_job_id=1230, pid=323738
[2024-09-27T18:11:57.554+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:55:00+00:00, run_after=2023-09-27 17:56:00+00:00
[2024-09-27T18:11:57.584+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:53:00+00:00: scheduled__2023-09-27T17:53:00+00:00, state:running, queued_at: 2024-09-27 16:11:34.031074+00:00. externally triggered: False> successful
[2024-09-27T18:11:57.585+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:53:00+00:00, run_id=scheduled__2023-09-27T17:53:00+00:00, run_start_date=2024-09-27 16:11:34.054860+00:00, run_end_date=2024-09-27 16:11:57.585386+00:00, run_duration=23.530526, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:53:00+00:00, data_interval_end=2023-09-27 17:54:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:11:57.590+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:54:00+00:00, run_after=2023-09-27 17:55:00+00:00
[2024-09-27T18:11:57.603+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
[2024-09-27T18:11:57.603+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:11:57.604+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:11:57.604+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:54:00+00:00 [scheduled]>
[2024-09-27T18:11:57.607+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:54:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:11:57.607+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:11:57.608+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:57.608+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:11:57.608+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:57.612+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:11:58.545+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:11:58.629+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:11:59.949+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:00.886+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:00.970+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:02.407+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:02.408+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:02.413+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:11:58.666745+00:00, run_end_date=2024-09-27 16:11:59.537775+00:00, run_duration=0.87103, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1541, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:11:57.605603+00:00, queued_by_job_id=1230, pid=323755
[2024-09-27T18:12:02.414+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:01.006560+00:00, run_end_date=2024-09-27 16:12:01.996886+00:00, run_duration=0.990326, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1542, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:11:57.605603+00:00, queued_by_job_id=1230, pid=323762
[2024-09-27T18:12:02.559+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:57:00+00:00, run_after=2023-09-27 17:58:00+00:00
[2024-09-27T18:12:02.599+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:54:00+00:00: scheduled__2023-09-27T17:54:00+00:00, state:running, queued_at: 2024-09-27 16:11:38.646892+00:00. externally triggered: False> successful
[2024-09-27T18:12:02.600+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:54:00+00:00, run_id=scheduled__2023-09-27T17:54:00+00:00, run_start_date=2024-09-27 16:11:38.663774+00:00, run_end_date=2024-09-27 16:12:02.600037+00:00, run_duration=23.936263, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:54:00+00:00, data_interval_end=2023-09-27 17:55:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:02.604+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:55:00+00:00, run_after=2023-09-27 17:56:00+00:00
[2024-09-27T18:12:02.613+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
[2024-09-27T18:12:02.613+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:02.613+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:02.613+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:55:00+00:00 [scheduled]>
[2024-09-27T18:12:02.614+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:56:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:55:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:02.615+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:02.615+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:02.615+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:02.615+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:02.618+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:03.553+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:03.637+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:05.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:05.981+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:06.065+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:07.496+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:07.497+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:07.503+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:06.100629+00:00, run_end_date=2024-09-27 16:12:07.082934+00:00, run_duration=0.982305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1544, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:02.614305+00:00, queued_by_job_id=1230, pid=323777
[2024-09-27T18:12:07.503+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:03.673314+00:00, run_end_date=2024-09-27 16:12:04.607516+00:00, run_duration=0.934202, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1543, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:02.614305+00:00, queued_by_job_id=1230, pid=323770
[2024-09-27T18:12:07.547+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:56:00+00:00, run_after=2023-09-27 17:57:00+00:00
[2024-09-27T18:12:07.574+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:55:00+00:00: scheduled__2023-09-27T17:55:00+00:00, state:running, queued_at: 2024-09-27 16:11:45.242263+00:00. externally triggered: False> successful
[2024-09-27T18:12:07.574+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:55:00+00:00, run_id=scheduled__2023-09-27T17:55:00+00:00, run_start_date=2024-09-27 16:11:45.260356+00:00, run_end_date=2024-09-27 16:12:07.574559+00:00, run_duration=22.314203, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:55:00+00:00, data_interval_end=2023-09-27 17:56:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:07.579+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:56:00+00:00, run_after=2023-09-27 17:57:00+00:00
[2024-09-27T18:12:07.591+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:07.592+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:07.592+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:07.594+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:07.595+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:07.595+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:07.600+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:08.536+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:08.620+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:09.827+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:09.832+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:08.656103+00:00, run_end_date=2024-09-27 16:12:09.409305+00:00, run_duration=0.753202, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1545, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:07.593516+00:00, queued_by_job_id=1230, pid=323784
[2024-09-27T18:12:09.864+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:57:00+00:00, run_after=2023-09-27 17:58:00+00:00
[2024-09-27T18:12:09.903+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:09.904+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:09.904+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:09.906+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:09.907+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:09.907+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:09.911+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:10.848+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:10.932+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:12.211+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:12.217+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:10.968232+00:00, run_end_date=2024-09-27 16:12:11.810967+00:00, run_duration=0.842735, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1546, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:09.905582+00:00, queued_by_job_id=1230, pid=323791
[2024-09-27T18:12:12.250+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:58:00+00:00, run_after=2023-09-27 17:59:00+00:00
[2024-09-27T18:12:12.296+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:12.296+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:12.297+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:12.297+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:56:00+00:00 [scheduled]>
[2024-09-27T18:12:12.298+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:57:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:56:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:12.298+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:12.298+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:12.298+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:12.298+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:12.301+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:13.237+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:13.322+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:14.402+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:56:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:15.335+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:15.419+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:56:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:16.851+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:16.851+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:56:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:16.857+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:13.358577+00:00, run_end_date=2024-09-27 16:12:13.981832+00:00, run_duration=0.623255, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1547, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:12.297507+00:00, queued_by_job_id=1230, pid=323801
[2024-09-27T18:12:16.858+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:56:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:15.455228+00:00, run_end_date=2024-09-27 16:12:16.441550+00:00, run_duration=0.986322, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1548, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:12.297507+00:00, queued_by_job_id=1230, pid=323810
[2024-09-27T18:12:16.907+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:59:00+00:00, run_after=2023-09-27 18:00:00+00:00
[2024-09-27T18:12:16.950+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:56:00+00:00: scheduled__2023-09-27T17:56:00+00:00, state:running, queued_at: 2024-09-27 16:12:02.553019+00:00. externally triggered: False> successful
[2024-09-27T18:12:16.951+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:56:00+00:00, run_id=scheduled__2023-09-27T17:56:00+00:00, run_start_date=2024-09-27 16:12:02.572319+00:00, run_end_date=2024-09-27 16:12:16.951132+00:00, run_duration=14.378813, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:56:00+00:00, data_interval_end=2023-09-27 17:57:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:16.955+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:57:00+00:00, run_after=2023-09-27 17:58:00+00:00
[2024-09-27T18:12:16.970+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:16.970+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:16.971+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:16.971+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:16.974+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:16.974+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:16.975+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:16.975+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:16.975+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:16.979+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:17.908+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:17.993+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:19.113+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:20.048+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:20.132+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:21.171+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:21.172+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:21.175+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:20.168494+00:00, run_end_date=2024-09-27 16:12:20.741543+00:00, run_duration=0.573049, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1550, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:16.972644+00:00, queued_by_job_id=1230, pid=323827
[2024-09-27T18:12:21.175+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:18.029423+00:00, run_end_date=2024-09-27 16:12:18.693597+00:00, run_duration=0.664174, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1549, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:16.972644+00:00, queued_by_job_id=1230, pid=323819
[2024-09-27T18:12:21.200+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:58:00+00:00, run_after=2023-09-27 17:59:00+00:00
[2024-09-27T18:12:21.226+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:21.226+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:21.226+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:21.226+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:21.227+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:21.228+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:21.228+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:21.228+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:21.228+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:21.231+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:22.163+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:22.247+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:23.285+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:24.194+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:24.278+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:25.756+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:25.757+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:25.762+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:24.314212+00:00, run_end_date=2024-09-27 16:12:25.350654+00:00, run_duration=1.036442, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1552, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:21.227263+00:00, queued_by_job_id=1230, pid=323841
[2024-09-27T18:12:25.763+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:22.283223+00:00, run_end_date=2024-09-27 16:12:22.892803+00:00, run_duration=0.60958, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1551, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:21.227263+00:00, queued_by_job_id=1230, pid=323834
[2024-09-27T18:12:25.810+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:59:00+00:00, run_after=2023-09-27 18:00:00+00:00
[2024-09-27T18:12:25.844+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:25.844+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:25.844+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:25.844+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:57:00+00:00 [scheduled]>
[2024-09-27T18:12:25.846+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:58:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:57:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:25.846+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:25.846+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:25.846+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:25.846+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:25.850+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:26.781+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:26.866+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:28.549+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:57:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:29.479+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:29.563+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:57:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:31.003+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:31.003+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:57:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:31.008+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:57:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:29.599533+00:00, run_end_date=2024-09-27 16:12:30.575495+00:00, run_duration=0.975962, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1554, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:25.845319+00:00, queued_by_job_id=1230, pid=323855
[2024-09-27T18:12:31.009+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:26.901560+00:00, run_end_date=2024-09-27 16:12:28.117594+00:00, run_duration=1.216034, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1553, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:25.845319+00:00, queued_by_job_id=1230, pid=323848
[2024-09-27T18:12:31.057+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:00:00+00:00, run_after=2023-09-27 18:01:00+00:00
[2024-09-27T18:12:31.097+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:57:00+00:00: scheduled__2023-09-27T17:57:00+00:00, state:running, queued_at: 2024-09-27 16:12:12.243865+00:00. externally triggered: False> successful
[2024-09-27T18:12:31.097+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:57:00+00:00, run_id=scheduled__2023-09-27T17:57:00+00:00, run_start_date=2024-09-27 16:12:12.266337+00:00, run_end_date=2024-09-27 16:12:31.097718+00:00, run_duration=18.831381, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:57:00+00:00, data_interval_end=2023-09-27 17:58:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:31.102+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:58:00+00:00, run_after=2023-09-27 17:59:00+00:00
[2024-09-27T18:12:31.111+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
[2024-09-27T18:12:31.111+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:31.111+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:31.111+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:58:00+00:00 [scheduled]>
[2024-09-27T18:12:31.112+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:59:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:58:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:31.113+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:31.113+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:31.113+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:31.113+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:31.116+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:32.054+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:32.138+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T17:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:33.153+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:58:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:34.113+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:34.198+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:58:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:35.045+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:35.046+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:58:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:35.052+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:58:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:34.235184+00:00, run_end_date=2024-09-27 16:12:34.653664+00:00, run_duration=0.41848, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1556, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:31.112064+00:00, queued_by_job_id=1230, pid=323884
[2024-09-27T18:12:35.053+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T17:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:32.174846+00:00, run_end_date=2024-09-27 16:12:32.725561+00:00, run_duration=0.550715, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1555, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:31.112064+00:00, queued_by_job_id=1230, pid=323876
[2024-09-27T18:12:35.198+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:01:00+00:00, run_after=2023-09-27 18:02:00+00:00
[2024-09-27T18:12:35.221+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:58:00+00:00: scheduled__2023-09-27T17:58:00+00:00, state:running, queued_at: 2024-09-27 16:12:16.901209+00:00. externally triggered: False> successful
[2024-09-27T18:12:35.222+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:58:00+00:00, run_id=scheduled__2023-09-27T17:58:00+00:00, run_start_date=2024-09-27 16:12:16.919896+00:00, run_end_date=2024-09-27 16:12:35.222034+00:00, run_duration=18.302138, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:58:00+00:00, data_interval_end=2023-09-27 17:59:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:35.223+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 17:59:00+00:00, run_after=2023-09-27 18:00:00+00:00
[2024-09-27T18:12:35.232+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:35.232+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:35.232+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:35.232+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:35.234+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:35.234+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:35.234+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:35.234+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:35.234+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:35.237+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:36.196+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:36.284+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:37.454+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:38.405+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:38.492+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T17:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:39.495+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:39.495+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:39.501+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:36.322034+00:00, run_end_date=2024-09-27 16:12:37.027546+00:00, run_duration=0.705512, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1557, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:35.233353+00:00, queued_by_job_id=1230, pid=323894
[2024-09-27T18:12:39.502+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T17:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:38.530148+00:00, run_end_date=2024-09-27 16:12:39.085606+00:00, run_duration=0.555458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1558, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:35.233353+00:00, queued_by_job_id=1230, pid=323901
[2024-09-27T18:12:39.552+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:00:00+00:00, run_after=2023-09-27 18:01:00+00:00
[2024-09-27T18:12:39.594+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:39.595+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:39.595+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:39.596+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:39.598+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:39.599+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:39.599+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:39.600+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:39.600+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:39.604+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:40.535+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:40.621+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:41.854+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:42.775+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:42.860+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T17:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:43.988+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:43.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:43.994+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:40.659589+00:00, run_end_date=2024-09-27 16:12:41.407048+00:00, run_duration=0.747459, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1559, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:39.597134+00:00, queued_by_job_id=1230, pid=323908
[2024-09-27T18:12:43.995+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T17:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:42.897220+00:00, run_end_date=2024-09-27 16:12:43.565470+00:00, run_duration=0.66825, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1560, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:39.597134+00:00, queued_by_job_id=1230, pid=323915
[2024-09-27T18:12:44.022+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:01:00+00:00, run_after=2023-09-27 18:02:00+00:00
[2024-09-27T18:12:44.065+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:44.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:44.066+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:44.067+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:59:00+00:00 [scheduled]>
[2024-09-27T18:12:44.069+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:00:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:59:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:44.070+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:44.070+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:44.071+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:44.071+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:44.075+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:45.042+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:45.129+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:46.643+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T17:59:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:47.545+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:47.629+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T17:59:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:48.821+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:48.822+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T17:59:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:48.827+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:45.166621+00:00, run_end_date=2024-09-27 16:12:46.249215+00:00, run_duration=1.082594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1561, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:44.068208+00:00, queued_by_job_id=1230, pid=323923
[2024-09-27T18:12:48.828+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T17:59:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:47.664879+00:00, run_end_date=2024-09-27 16:12:48.400436+00:00, run_duration=0.735557, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1562, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:44.068208+00:00, queued_by_job_id=1230, pid=323933
[2024-09-27T18:12:48.888+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:02:00+00:00, run_after=2023-09-27 18:03:00+00:00
[2024-09-27T18:12:48.907+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 17:59:00+00:00: scheduled__2023-09-27T17:59:00+00:00, state:running, queued_at: 2024-09-27 16:12:31.050677+00:00. externally triggered: False> successful
[2024-09-27T18:12:48.908+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 17:59:00+00:00, run_id=scheduled__2023-09-27T17:59:00+00:00, run_start_date=2024-09-27 16:12:31.069514+00:00, run_end_date=2024-09-27 16:12:48.908150+00:00, run_duration=17.838636, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 17:59:00+00:00, data_interval_end=2023-09-27 18:00:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:48.910+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:00:00+00:00, run_after=2023-09-27 18:01:00+00:00
[2024-09-27T18:12:48.923+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
[2024-09-27T18:12:48.924+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:48.924+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:48.925+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:00:00+00:00 [scheduled]>
[2024-09-27T18:12:48.927+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:01:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:48.928+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:48.928+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:48.928+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:48.929+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:48.933+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:49.864+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:49.949+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:51.274+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:52.211+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:52.297+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:00:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:53.721+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:53.722+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:00:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:53.727+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:49.986692+00:00, run_end_date=2024-09-27 16:12:50.846666+00:00, run_duration=0.859974, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1563, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:48.925915+00:00, queued_by_job_id=1230, pid=323941
[2024-09-27T18:12:53.728+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:00:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:52.335187+00:00, run_end_date=2024-09-27 16:12:53.319544+00:00, run_duration=0.984357, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1564, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:48.925915+00:00, queued_by_job_id=1230, pid=323948
[2024-09-27T18:12:53.754+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:01:00+00:00, run_after=2023-09-27 18:02:00+00:00
[2024-09-27T18:12:53.785+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:00:00+00:00: scheduled__2023-09-27T18:00:00+00:00, state:running, queued_at: 2024-09-27 16:12:35.192060+00:00. externally triggered: False> successful
[2024-09-27T18:12:53.786+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:00:00+00:00, run_id=scheduled__2023-09-27T18:00:00+00:00, run_start_date=2024-09-27 16:12:35.207531+00:00, run_end_date=2024-09-27 16:12:53.786387+00:00, run_duration=18.578856, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:00:00+00:00, data_interval_end=2023-09-27 18:01:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:12:53.791+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:01:00+00:00, run_after=2023-09-27 18:02:00+00:00
[2024-09-27T18:12:53.803+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:53.804+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:53.804+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:53.806+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:53.807+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:12:53.807+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:53.811+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:54.746+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:54.830+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:56.194+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:56.199+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:54.866311+00:00, run_end_date=2024-09-27 16:12:55.777768+00:00, run_duration=0.911457, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1565, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:12:53.805432+00:00, queued_by_job_id=1230, pid=323963
[2024-09-27T18:12:56.247+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:02:00+00:00, run_after=2023-09-27 18:03:00+00:00
[2024-09-27T18:12:56.281+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:56.281+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:56.282+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:56.284+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:56.284+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:12:56.285+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:56.288+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:57.233+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:57.319+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:12:58.222+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:12:58.227+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:57.355197+00:00, run_end_date=2024-09-27 16:12:57.823859+00:00, run_duration=0.468662, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1566, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:12:56.282804+00:00, queued_by_job_id=1230, pid=323971
[2024-09-27T18:12:58.259+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:03:00+00:00, run_after=2023-09-27 18:04:00+00:00
[2024-09-27T18:12:58.308+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:58.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:12:58.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:12:58.308+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:01:00+00:00 [scheduled]>
[2024-09-27T18:12:58.309+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:02:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:01:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:12:58.310+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:12:58.310+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:58.310+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:12:58.310+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:58.313+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:12:59.247+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:12:59.332+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:00.492+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:01:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:01.433+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:01.519+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:01:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:02.591+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:02.591+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:01:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:02.596+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:01:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:01.555310+00:00, run_end_date=2024-09-27 16:13:02.181298+00:00, run_duration=0.625988, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1568, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:12:58.309173+00:00, queued_by_job_id=1230, pid=323986
[2024-09-27T18:13:02.597+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:12:59.368781+00:00, run_end_date=2024-09-27 16:13:00.086389+00:00, run_duration=0.717608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1567, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:12:58.309173+00:00, queued_by_job_id=1230, pid=323979
[2024-09-27T18:13:02.645+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:04:00+00:00, run_after=2023-09-27 18:05:00+00:00
[2024-09-27T18:13:02.666+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:01:00+00:00: scheduled__2023-09-27T18:01:00+00:00, state:running, queued_at: 2024-09-27 16:12:48.884473+00:00. externally triggered: False> successful
[2024-09-27T18:13:02.666+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:01:00+00:00, run_id=scheduled__2023-09-27T18:01:00+00:00, run_start_date=2024-09-27 16:12:48.895242+00:00, run_end_date=2024-09-27 16:13:02.666635+00:00, run_duration=13.771393, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:01:00+00:00, data_interval_end=2023-09-27 18:02:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:13:02.668+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:02:00+00:00, run_after=2023-09-27 18:03:00+00:00
[2024-09-27T18:13:02.676+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:02.676+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:13:02.676+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:13:02.677+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:02.678+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:03:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:13:02.678+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:13:02.678+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:02.678+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:13:02.678+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:02.681+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:03.613+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:03.698+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:04.777+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:05.710+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:05.805+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:07.531+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:07.532+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:07.538+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:03.734587+00:00, run_end_date=2024-09-27 16:13:04.367040+00:00, run_duration=0.632453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1569, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:13:02.677372+00:00, queued_by_job_id=1230, pid=323993
[2024-09-27T18:13:07.539+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:05.844096+00:00, run_end_date=2024-09-27 16:13:07.135087+00:00, run_duration=1.290991, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1570, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:13:02.677372+00:00, queued_by_job_id=1230, pid=324000
[2024-09-27T18:13:07.679+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:05:00+00:00, run_after=2023-09-27 18:06:00+00:00
[2024-09-27T18:13:07.736+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:07.737+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:13:07.737+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:13:07.737+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:13:07.738+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:07.740+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:03:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:13:07.741+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:13:07.741+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:07.742+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:13:07.742+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:07.743+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:13:07.743+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:07.746+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:08.653+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:08.738+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:10.119+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:11.060+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:11.146+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:12.153+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:13.087+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:13.172+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:14.209+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:14.209+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:14.210+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:14.216+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:11.182733+00:00, run_end_date=2024-09-27 16:13:11.756222+00:00, run_duration=0.573489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1572, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:13:07.739313+00:00, queued_by_job_id=1230, pid=324015
[2024-09-27T18:13:14.217+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:08.773863+00:00, run_end_date=2024-09-27 16:13:09.707297+00:00, run_duration=0.933434, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1571, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:13:07.739313+00:00, queued_by_job_id=1230, pid=324008
[2024-09-27T18:13:14.217+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:13.208903+00:00, run_end_date=2024-09-27 16:13:13.804883+00:00, run_duration=0.59598, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1573, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:13:07.739313+00:00, queued_by_job_id=1230, pid=324023
[2024-09-27T18:13:14.275+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:06:00+00:00, run_after=2023-09-27 18:07:00+00:00
[2024-09-27T18:13:14.308+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:14.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:13:14.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:13:14.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:13:14.308+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:13:14.309+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:02:00+00:00 [scheduled]>
[2024-09-27T18:13:14.310+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:03:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:02:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:13:14.310+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:13:14.310+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:14.310+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:13:14.311+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:14.311+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:13:14.311+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:14.311+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:13:14.311+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:14.314+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:15.248+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:15.333+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:16.493+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:17.434+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:17.519+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:18.500+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:19.486+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:19.572+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:20.463+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:02:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:21.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:21.479+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:02:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:22.468+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:22.469+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:22.469+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:22.469+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:02:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:13:22.472+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T18:03:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:19.608897+00:00, run_end_date=2024-09-27 16:13:20.057312+00:00, run_duration=0.448415, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1576, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:13:14.309577+00:00, queued_by_job_id=1230, pid=324066
[2024-09-27T18:13:22.472+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T18:04:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:17.555762+00:00, run_end_date=2024-09-27 16:13:18.109658+00:00, run_duration=0.553896, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1575, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:13:14.309577+00:00, queued_by_job_id=1230, pid=324044
[2024-09-27T18:13:22.472+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T18:05:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:15.369351+00:00, run_end_date=2024-09-27 16:13:16.064676+00:00, run_duration=0.695325, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1574, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:13:14.309577+00:00, queued_by_job_id=1230, pid=324034
[2024-09-27T18:13:22.473+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T18:02:00+00:00, map_index=-1, run_start_date=2024-09-27 16:13:21.516466+00:00, run_end_date=2024-09-27 16:13:22.086442+00:00, run_duration=0.569976, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1577, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:13:14.309577+00:00, queued_by_job_id=1230, pid=324073
[2024-09-27T18:13:22.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:07:00+00:00, run_after=2023-09-27 18:08:00+00:00
[2024-09-27T18:13:22.535+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 18:02:00+00:00: scheduled__2023-09-27T18:02:00+00:00, state:running, queued_at: 2024-09-27 16:12:58.253383+00:00. externally triggered: False> successful
[2024-09-27T18:13:22.535+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 18:02:00+00:00, run_id=scheduled__2023-09-27T18:02:00+00:00, run_start_date=2024-09-27 16:12:58.276558+00:00, run_end_date=2024-09-27 16:13:22.535353+00:00, run_duration=24.258795, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 18:02:00+00:00, data_interval_end=2023-09-27 18:03:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:13:22.537+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 18:03:00+00:00, run_after=2023-09-27 18:04:00+00:00
[2024-09-27T18:13:22.550+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
[2024-09-27T18:13:22.551+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:13:22.551+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:13:22.552+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:13:22.552+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:13:22.552+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:06:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:05:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:04:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:03:00+00:00 [scheduled]>
[2024-09-27T18:13:22.556+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:06:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:05:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:04:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:03:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:13:22.556+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T18:06:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:13:22.557+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:22.557+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T18:05:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:13:22.557+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:22.558+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T18:04:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:13:22.558+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:22.558+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T18:03:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:13:22.559+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:22.563+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:23.482+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:23.568+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:06:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:24.490+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:25.423+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:25.508+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:05:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:26.509+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:27.421+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:27.506+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:04:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:28.500+0200] {scheduler_job_runner.py:260} INFO - Exiting gracefully upon receiving signal 15
[2024-09-27T18:13:28.632+0200] {process_utils.py:132} INFO - Sending 15 to group 320850. PIDs of all processes in the group: []
[2024-09-27T18:13:28.632+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 320850
[2024-09-27T18:13:28.633+0200] {process_utils.py:101} INFO - Sending the signal 15 to process 320850 as process group is missing.
[2024-09-27T18:13:28.633+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T18:06:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:29.568+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:29.653+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T18:06:00+00:00 [success]> on host jf-hp
[2024-09-27T18:13:29.986+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T18:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:30.886+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:30.971+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T18:05:00+00:00 [success]> on host jf-hp
[2024-09-27T18:13:31.301+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T18:04:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:32.207+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:32.292+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T18:04:00+00:00 [success]> on host jf-hp
[2024-09-27T18:13:32.629+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T18:03:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:13:33.570+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:13:33.656+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T18:03:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:13:34.482+0200] {process_utils.py:132} INFO - Sending 15 to group 320850. PIDs of all processes in the group: []
[2024-09-27T18:13:34.482+0200] {process_utils.py:87} INFO - Sending the signal 15 to group 320850
[2024-09-27T18:13:34.483+0200] {process_utils.py:101} INFO - Sending the signal 15 to process 320850 as process group is missing.
[2024-09-27T18:13:34.483+0200] {scheduler_job_runner.py:1014} INFO - Exited execute loop
[2024-09-27 18:13:34 +0200] [320848] [INFO] Handling signal: term
[2024-09-27 18:13:34 +0200] [320849] [INFO] Worker exiting (pid: 320849)
[2024-09-27 18:13:34 +0200] [320851] [INFO] Worker exiting (pid: 320851)
[2024-09-27 18:13:34 +0200] [320848] [INFO] Shutting down: Master
