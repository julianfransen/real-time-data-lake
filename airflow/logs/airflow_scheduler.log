  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2024-09-27T18:00:09.541+0200] {_client.py:1038} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.11&platform=Linux&arch=x86_64&database=sqlite&db_version=3.41&executor=SequentialExecutor "HTTP/1.1 200 OK"
[2024-09-27T18:00:09.640+0200] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-27 18:00:09 +0200] [320848] [INFO] Starting gunicorn 23.0.0
[2024-09-27 18:00:09 +0200] [320848] [INFO] Listening at: http://[::]:8793 (320848)
[2024-09-27 18:00:09 +0200] [320848] [INFO] Using worker: sync
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-27T18:00:09.668+0200] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-27 18:00:09 +0200] [320849] [INFO] Booting worker with pid: 320849
[2024-09-27T18:00:09.673+0200] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 320850
[2024-09-27T18:00:09.674+0200] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-27T18:00:09.678+0200] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-27T18:00:09.704+0200] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-27 18:00:09 +0200] [320851] [INFO] Booting worker with pid: 320851
[2024-09-27T18:00:10.054+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:10.090+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:36:00+00:00: scheduled__2023-09-27T16:36:00+00:00, state:running, queued_at: 2024-09-27 15:59:26.801901+00:00. externally triggered: False> successful
[2024-09-27T18:00:10.091+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:36:00+00:00, run_id=scheduled__2023-09-27T16:36:00+00:00, run_start_date=2024-09-27 15:59:26.811433+00:00, run_end_date=2024-09-27 16:00:10.091194+00:00, run_duration=43.279761, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:36:00+00:00, data_interval_end=2023-09-27 16:37:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:10.093+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:37:00+00:00, run_after=2023-09-27 16:38:00+00:00
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:10.107+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:10.108+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>
[2024-09-27T18:00:10.109+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.110+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:10.110+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:10.113+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:11.049+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:11.133+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:24.302+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:37:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:25.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:25.283+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:37:00+00:00 [queued]> on host jf-hp
%3|1727452839.445|FAIL|rdkafka#producer-1| [thrd:jf-hp:9092/0]: jf-hp:9092/0: Failed to connect to broker at [jf-hp]:9092: Invalid argument (after 1ms in state CONNECT)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.817+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:37:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:40.828+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:11.169956+00:00, run_end_date=2024-09-27 16:00:23.909924+00:00, run_duration=12.739968, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1231, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320854
[2024-09-27T18:00:40.829+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:37:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:25.321124+00:00, run_end_date=2024-09-27 16:00:40.464493+00:00, run_duration=15.143369, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:10.108588+00:00, queued_by_job_id=1230, pid=320958
[2024-09-27T18:00:40.858+0200] {job.py:229} INFO - Heartbeat recovered after 31.22 seconds
[2024-09-27T18:00:41.108+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:41.150+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:37:00+00:00: scheduled__2023-09-27T16:37:00+00:00, state:running, queued_at: 2024-09-27 15:59:33.056378+00:00. externally triggered: False> successful
[2024-09-27T18:00:41.151+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:37:00+00:00, run_id=scheduled__2023-09-27T16:37:00+00:00, run_start_date=2024-09-27 15:59:33.074914+00:00, run_end_date=2024-09-27 16:00:41.151364+00:00, run_duration=68.07645, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:37:00+00:00, data_interval_end=2023-09-27 16:38:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:41.156+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:38:00+00:00, run_after=2023-09-27 16:39:00+00:00
[2024-09-27T18:00:41.171+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:41.172+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:41.175+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:41.176+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.176+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:41.177+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:41.180+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:42.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:42.222+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:43.789+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:44.731+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:44.815+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.369+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:46.375+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:42.258022+00:00, run_end_date=2024-09-27 16:00:43.367019+00:00, run_duration=1.108997, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1233, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320989
[2024-09-27T18:00:46.376+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:44.853399+00:00, run_end_date=2024-09-27 16:00:45.984008+00:00, run_duration=1.130609, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1234, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:41.173830+00:00, queued_by_job_id=1230, pid=320996
[2024-09-27T18:00:46.415+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:46.450+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:46.451+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:46.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:46.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:46.456+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:47.393+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:47.481+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:49.021+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:49.936+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:50.023+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:51.013+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.014+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:51.017+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:47.519919+00:00, run_end_date=2024-09-27 16:00:48.638144+00:00, run_duration=1.118225, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1235, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321004
[2024-09-27T18:00:51.018+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:50.059503+00:00, run_end_date=2024-09-27 16:00:50.598692+00:00, run_duration=0.539189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:46.451852+00:00, queued_by_job_id=1230, pid=321012
[2024-09-27T18:00:51.041+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:51.067+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:51.068+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.069+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:51.069+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:51.073+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:52.009+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:52.097+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:53.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:38:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:54.114+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:54.200+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:38:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.081+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:38:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:52.130572+00:00, run_end_date=2024-09-27 16:00:52.775268+00:00, run_duration=0.644696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1237, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321020
[2024-09-27T18:00:55.084+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:38:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:54.231509+00:00, run_end_date=2024-09-27 16:00:54.696955+00:00, run_duration=0.465446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:51.068425+00:00, queued_by_job_id=1230, pid=321028
[2024-09-27T18:00:55.119+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:00:55.138+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:38:00+00:00: scheduled__2023-09-27T16:38:00+00:00, state:running, queued_at: 2024-09-27 16:00:09.963038+00:00. externally triggered: False> successful
[2024-09-27T18:00:55.139+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:38:00+00:00, run_id=scheduled__2023-09-27T16:38:00+00:00, run_start_date=2024-09-27 16:00:10.069389+00:00, run_end_date=2024-09-27 16:00:55.139032+00:00, run_duration=45.069643, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:38:00+00:00, data_interval_end=2023-09-27 16:39:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:55.140+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:39:00+00:00, run_after=2023-09-27 16:40:00+00:00
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:00:55.148+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>
[2024-09-27T18:00:55.149+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.150+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:00:55.150+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:55.155+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:56.095+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:56.179+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:56.952+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:39:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:57.865+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:00:57.951+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:39:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.989+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:39:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:00:58.994+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:56.223021+00:00, run_end_date=2024-09-27 16:00:56.539323+00:00, run_duration=0.316302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1239, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321035
[2024-09-27T18:00:58.995+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:39:00+00:00, map_index=-1, run_start_date=2024-09-27 16:00:57.988241+00:00, run_end_date=2024-09-27 16:00:58.590852+00:00, run_duration=0.602611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:00:55.149095+00:00, queued_by_job_id=1230, pid=321043
[2024-09-27T18:00:59.026+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.056+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:39:00+00:00: scheduled__2023-09-27T16:39:00+00:00, state:running, queued_at: 2024-09-27 16:00:41.102400+00:00. externally triggered: False> successful
[2024-09-27T18:00:59.057+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:39:00+00:00, run_id=scheduled__2023-09-27T16:39:00+00:00, run_start_date=2024-09-27 16:00:41.120307+00:00, run_end_date=2024-09-27 16:00:59.057380+00:00, run_duration=17.937073, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:39:00+00:00, data_interval_end=2023-09-27 16:40:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:00:59.062+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:40:00+00:00, run_after=2023-09-27 16:41:00+00:00
[2024-09-27T18:00:59.075+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:00:59.076+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:00:59.079+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:00:59.080+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:00:59.083+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:00.023+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:00.108+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:01.078+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:01.089+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:00.144130+00:00, run_end_date=2024-09-27 16:01:00.695583+00:00, run_duration=0.551453, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1241, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:00:59.077213+00:00, queued_by_job_id=1230, pid=321050
[2024-09-27T18:01:01.136+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:01.168+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:01.169+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:01.171+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:01.172+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:01.172+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:01.177+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:02.110+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:02.195+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:03.237+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:03.242+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:02.231116+00:00, run_end_date=2024-09-27 16:01:02.810062+00:00, run_duration=0.578946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1242, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:01.170506+00:00, queued_by_job_id=1230, pid=321057
[2024-09-27T18:01:03.275+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.329+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:03.330+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:03.333+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:03.334+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.334+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:03.335+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:03.338+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:04.288+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:04.375+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:05.154+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:06.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:06.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:40:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:07.125+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.126+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:40:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:04.412683+00:00, run_end_date=2024-09-27 16:01:04.782143+00:00, run_duration=0.36946, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1243, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321064
[2024-09-27T18:01:07.132+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:40:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:06.206428+00:00, run_end_date=2024-09-27 16:01:06.729709+00:00, run_duration=0.523281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:03.331651+00:00, queued_by_job_id=1230, pid=321071
[2024-09-27T18:01:07.181+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:07.207+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:40:00+00:00: scheduled__2023-09-27T16:40:00+00:00, state:running, queued_at: 2024-09-27 16:00:55.116762+00:00. externally triggered: False> successful
[2024-09-27T18:01:07.207+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:40:00+00:00, run_id=scheduled__2023-09-27T16:40:00+00:00, run_start_date=2024-09-27 16:00:55.126133+00:00, run_end_date=2024-09-27 16:01:07.207457+00:00, run_duration=12.081324, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:40:00+00:00, data_interval_end=2023-09-27 16:41:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:07.209+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:41:00+00:00, run_after=2023-09-27 16:42:00+00:00
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:07.216+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:07.217+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.218+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:07.218+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:07.221+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:08.160+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:08.245+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:09.169+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:10.115+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:10.205+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:11.416+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.417+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:10.242243+00:00, run_end_date=2024-09-27 16:01:11.033357+00:00, run_duration=0.791114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1246, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321085
[2024-09-27T18:01:11.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:08.281207+00:00, run_end_date=2024-09-27 16:01:08.747214+00:00, run_duration=0.466007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1245, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:07.217363+00:00, queued_by_job_id=1230, pid=321078
[2024-09-27T18:01:11.684+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:11.715+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:11.716+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:11.717+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.718+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:11.718+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:11.721+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:12.641+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:12.726+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:14.093+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:15.028+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:15.116+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:16.371+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:17.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:17.423+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:18.279+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.280+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:18.284+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:17.459928+00:00, run_end_date=2024-09-27 16:01:17.889774+00:00, run_duration=0.429846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1249, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321112
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:15.152411+00:00, run_end_date=2024-09-27 16:01:15.950537+00:00, run_duration=0.798126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1248, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321105
[2024-09-27T18:01:18.285+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:12.763874+00:00, run_end_date=2024-09-27 16:01:13.715515+00:00, run_duration=0.951641, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1247, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:11.716705+00:00, queued_by_job_id=1230, pid=321094
[2024-09-27T18:01:18.324+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:18.353+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:18.354+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:18.356+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.356+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.357+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:18.357+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:18.360+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:19.296+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:19.380+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:20.331+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:21.271+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:21.356+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:22.287+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:23.219+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:23.307+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:24.317+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:41:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:25.247+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:25.332+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:41:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.168+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:41:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:41:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:25.368857+00:00, run_end_date=2024-09-27 16:01:25.798744+00:00, run_duration=0.429887, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1253, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321142
[2024-09-27T18:01:26.173+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:23.343595+00:00, run_end_date=2024-09-27 16:01:23.949111+00:00, run_duration=0.605516, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1252, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321135
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:21.388362+00:00, run_end_date=2024-09-27 16:01:21.845540+00:00, run_duration=0.457178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1251, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321127
[2024-09-27T18:01:26.174+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:19.416874+00:00, run_end_date=2024-09-27 16:01:19.929931+00:00, run_duration=0.513057, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1250, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:18.355023+00:00, queued_by_job_id=1230, pid=321120
[2024-09-27T18:01:26.210+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:26.236+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:41:00+00:00: scheduled__2023-09-27T16:41:00+00:00, state:running, queued_at: 2024-09-27 16:01:03.269464+00:00. externally triggered: False> successful
[2024-09-27T18:01:26.236+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:41:00+00:00, run_id=scheduled__2023-09-27T16:41:00+00:00, run_start_date=2024-09-27 16:01:03.293633+00:00, run_end_date=2024-09-27 16:01:26.236543+00:00, run_duration=22.94291, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:41:00+00:00, data_interval_end=2023-09-27 16:42:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:26.238+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:42:00+00:00, run_after=2023-09-27 16:43:00+00:00
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:01:26.246+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:26.248+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.248+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.249+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:26.249+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:26.252+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:27.191+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:27.276+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:28.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:29.004+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:29.091+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:30.474+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:31.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:31.488+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:32.947+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:42:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:33.880+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:33.964+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:42:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:35.500+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.501+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.502+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:42:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:35.508+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:42:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:34.000142+00:00, run_end_date=2024-09-27 16:01:35.112254+00:00, run_duration=1.112112, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321171
[2024-09-27T18:01:35.509+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:31.524617+00:00, run_end_date=2024-09-27 16:01:32.552106+00:00, run_duration=1.027489, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1256, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321163
[2024-09-27T18:01:35.510+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:29.129724+00:00, run_end_date=2024-09-27 16:01:30.091220+00:00, run_duration=0.961496, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1255, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321156
[2024-09-27T18:01:35.511+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:27.312630+00:00, run_end_date=2024-09-27 16:01:27.667440+00:00, run_duration=0.35481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1254, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:26.247315+00:00, queued_by_job_id=1230, pid=321149
[2024-09-27T18:01:35.558+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.596+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:42:00+00:00: scheduled__2023-09-27T16:42:00+00:00, state:running, queued_at: 2024-09-27 16:01:07.174802+00:00. externally triggered: False> successful
[2024-09-27T18:01:35.596+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:42:00+00:00, run_id=scheduled__2023-09-27T16:42:00+00:00, run_start_date=2024-09-27 16:01:07.192486+00:00, run_end_date=2024-09-27 16:01:35.596636+00:00, run_duration=28.40415, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:42:00+00:00, data_interval_end=2023-09-27 16:43:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:35.601+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:43:00+00:00, run_after=2023-09-27 16:44:00+00:00
[2024-09-27T18:01:35.615+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:35.616+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>
[2024-09-27T18:01:35.619+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:35.620+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.620+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.621+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:35.621+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:35.625+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:36.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:36.660+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:38.191+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:39.130+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:39.216+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:40.227+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:43:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:41.146+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:41.232+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:43:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:42.150+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.151+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:43:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:43:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:41.270050+00:00, run_end_date=2024-09-27 16:01:41.768499+00:00, run_duration=0.498449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321193
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:39.252792+00:00, run_end_date=2024-09-27 16:01:39.790672+00:00, run_duration=0.53788, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1259, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321186
[2024-09-27T18:01:42.154+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:36.696688+00:00, run_end_date=2024-09-27 16:01:37.776911+00:00, run_duration=1.080223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1258, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:35.617818+00:00, queued_by_job_id=1230, pid=321179
[2024-09-27T18:01:42.409+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:42.433+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:43:00+00:00: scheduled__2023-09-27T16:43:00+00:00, state:running, queued_at: 2024-09-27 16:01:11.678717+00:00. externally triggered: False> successful
[2024-09-27T18:01:42.434+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:43:00+00:00, run_id=scheduled__2023-09-27T16:43:00+00:00, run_start_date=2024-09-27 16:01:11.692882+00:00, run_end_date=2024-09-27 16:01:42.434151+00:00, run_duration=30.741269, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:43:00+00:00, data_interval_end=2023-09-27 16:44:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:42.436+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:44:00+00:00, run_after=2023-09-27 16:45:00+00:00
[2024-09-27T18:01:42.448+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:42.449+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:01:42.450+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:42.452+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.453+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:42.453+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.454+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:42.454+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:42.458+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:43.389+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:43.473+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:44.960+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:45.899+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:45.983+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:47.400+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:44:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:48.351+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:48.436+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:44:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:49.445+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.446+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:44:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:49.452+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:43.508593+00:00, run_end_date=2024-09-27 16:01:44.541181+00:00, run_duration=1.032588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1261, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321201
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:44:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:48.471694+00:00, run_end_date=2024-09-27 16:01:49.059436+00:00, run_duration=0.587742, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321218
[2024-09-27T18:01:49.453+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:46.019008+00:00, run_end_date=2024-09-27 16:01:46.997770+00:00, run_duration=0.978762, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1262, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:42.450967+00:00, queued_by_job_id=1230, pid=321208
[2024-09-27T18:01:49.500+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.530+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:44:00+00:00: scheduled__2023-09-27T16:44:00+00:00, state:running, queued_at: 2024-09-27 16:01:18.321308+00:00. externally triggered: False> successful
[2024-09-27T18:01:49.531+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:44:00+00:00, run_id=scheduled__2023-09-27T16:44:00+00:00, run_start_date=2024-09-27 16:01:18.330859+00:00, run_end_date=2024-09-27 16:01:49.531464+00:00, run_duration=31.200605, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:44:00+00:00, data_interval_end=2023-09-27 16:45:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:49.536+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:45:00+00:00, run_after=2023-09-27 16:46:00+00:00
[2024-09-27T18:01:49.548+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:49.549+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:01:49.550+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>
[2024-09-27T18:01:49.552+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:49.553+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:01:49.553+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.554+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:49.554+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:49.558+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:50.489+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:50.574+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:52.018+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:52.980+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:53.067+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:45:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:54.449+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.450+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:45:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:54.455+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:50.611511+00:00, run_end_date=2024-09-27 16:01:51.610045+00:00, run_duration=0.998534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1264, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321226
[2024-09-27T18:01:54.456+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:45:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:53.104035+00:00, run_end_date=2024-09-27 16:01:54.070098+00:00, run_duration=0.966063, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:49.551205+00:00, queued_by_job_id=1230, pid=321233
[2024-09-27T18:01:54.481+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.500+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:45:00+00:00: scheduled__2023-09-27T16:45:00+00:00, state:running, queued_at: 2024-09-27 16:01:26.207749+00:00. externally triggered: False> successful
[2024-09-27T18:01:54.500+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:45:00+00:00, run_id=scheduled__2023-09-27T16:45:00+00:00, run_start_date=2024-09-27 16:01:26.217400+00:00, run_end_date=2024-09-27 16:01:54.500299+00:00, run_duration=28.282899, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:45:00+00:00, data_interval_end=2023-09-27 16:46:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:54.502+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:46:00+00:00, run_after=2023-09-27 16:47:00+00:00
[2024-09-27T18:01:54.508+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:54.509+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:54.510+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:01:54.510+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:54.513+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:55.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:55.536+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:56.939+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:56.944+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:55.573830+00:00, run_end_date=2024-09-27 16:01:56.527711+00:00, run_duration=0.953881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1266, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:01:54.509734+00:00, queued_by_job_id=1230, pid=321240
[2024-09-27T18:01:56.988+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:57.022+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:57.023+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>
[2024-09-27T18:01:57.025+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:57.026+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:01:57.026+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.030+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:46:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:57.974+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:01:58.060+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:46:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:01:58.984+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:46:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:01:58.986+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:46:00+00:00, map_index=-1, run_start_date=2024-09-27 16:01:58.096844+00:00, run_end_date=2024-09-27 16:01:58.620934+00:00, run_duration=0.52409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1267, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:01:57.024486+00:00, queued_by_job_id=1230, pid=321248
[2024-09-27T18:01:59.009+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:01:59.031+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:46:00+00:00: scheduled__2023-09-27T16:46:00+00:00, state:running, queued_at: 2024-09-27 16:01:42.403863+00:00. externally triggered: False> successful
[2024-09-27T18:01:59.032+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:46:00+00:00, run_id=scheduled__2023-09-27T16:46:00+00:00, run_start_date=2024-09-27 16:01:42.418716+00:00, run_end_date=2024-09-27 16:01:59.032147+00:00, run_duration=16.613431, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:46:00+00:00, data_interval_end=2023-09-27 16:47:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:01:59.034+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:47:00+00:00, run_after=2023-09-27 16:48:00+00:00
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:01:59.041+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:01:59.042+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:01:59.043+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:01:59.045+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:00.001+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:00.088+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:00.973+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:00.976+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:00.127374+00:00, run_end_date=2024-09-27 16:02:00.574092+00:00, run_duration=0.446718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1268, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:01:59.041965+00:00, queued_by_job_id=1230, pid=321255
[2024-09-27T18:02:00.997+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:01.036+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:01.037+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:01.039+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:01.040+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:01.040+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.044+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:01.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:02.063+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:03.024+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:03.026+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:02.099888+00:00, run_end_date=2024-09-27 16:02:02.600638+00:00, run_duration=0.50075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1269, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:01.038262+00:00, queued_by_job_id=1230, pid=321262
[2024-09-27T18:02:03.061+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:03.093+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:03.094+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:03.097+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.098+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:03.098+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:03.102+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:04.037+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:04.120+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:05.127+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:06.077+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:06.164+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:07.042+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.043+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:06.200887+00:00, run_end_date=2024-09-27 16:02:06.635161+00:00, run_duration=0.434274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321276
[2024-09-27T18:02:07.049+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:04.156748+00:00, run_end_date=2024-09-27 16:02:04.738813+00:00, run_duration=0.582065, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1270, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:03.095868+00:00, queued_by_job_id=1230, pid=321269
[2024-09-27T18:02:07.089+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:07.149+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:07.150+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:07.151+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:07.154+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:07.154+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.155+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:07.155+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.156+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:07.156+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:07.160+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:08.099+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:08.183+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:09.023+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:09.987+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:10.073+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:10.997+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:47:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:11.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:12.017+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:47:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.221+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.222+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:47:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:13.228+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:47:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:12.062263+00:00, run_end_date=2024-09-27 16:02:12.819921+00:00, run_duration=0.757658, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1274, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321311
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:08.219782+00:00, run_end_date=2024-09-27 16:02:08.603725+00:00, run_duration=0.383943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1272, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321283
[2024-09-27T18:02:13.229+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:10.110512+00:00, run_end_date=2024-09-27 16:02:10.589705+00:00, run_duration=0.479193, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1273, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:07.152337+00:00, queued_by_job_id=1230, pid=321304
[2024-09-27T18:02:13.507+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:13.555+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:47:00+00:00: scheduled__2023-09-27T16:47:00+00:00, state:running, queued_at: 2024-09-27 16:01:59.006507+00:00. externally triggered: False> successful
[2024-09-27T18:02:13.555+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:47:00+00:00, run_id=scheduled__2023-09-27T16:47:00+00:00, run_start_date=2024-09-27 16:01:59.020753+00:00, run_end_date=2024-09-27 16:02:13.555749+00:00, run_duration=14.534996, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:47:00+00:00, data_interval_end=2023-09-27 16:48:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:13.560+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:48:00+00:00, run_after=2023-09-27 16:49:00+00:00
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:13.569+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:13.570+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.571+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:13.571+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:13.574+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:14.507+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:14.592+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:15.711+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:16.671+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:16.758+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:17.734+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:18.650+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:18.735+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.213+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.214+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:20.219+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:16.796629+00:00, run_end_date=2024-09-27 16:02:17.337980+00:00, run_duration=0.541351, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1276, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321332
[2024-09-27T18:02:20.220+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:14.627720+00:00, run_end_date=2024-09-27 16:02:15.304761+00:00, run_duration=0.677041, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1275, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321324
[2024-09-27T18:02:20.221+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:18.771494+00:00, run_end_date=2024-09-27 16:02:19.860212+00:00, run_duration=1.088718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:13.570155+00:00, queued_by_job_id=1230, pid=321340
[2024-09-27T18:02:20.260+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:20.286+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:20.288+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.288+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:20.289+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:20.291+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:21.229+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:21.315+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:22.763+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:23.726+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:23.814+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:25.142+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:48:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:26.078+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:26.163+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:48:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.361+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.362+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:48:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:27.364+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:23.851804+00:00, run_end_date=2024-09-27 16:02:24.767089+00:00, run_duration=0.915285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1279, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321354
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:21.352057+00:00, run_end_date=2024-09-27 16:02:22.348460+00:00, run_duration=0.996403, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1278, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321347
[2024-09-27T18:02:27.365+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:48:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:26.198707+00:00, run_end_date=2024-09-27 16:02:26.953479+00:00, run_duration=0.754772, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1280, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:20.287396+00:00, queued_by_job_id=1230, pid=321361
[2024-09-27T18:02:27.398+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:27.412+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:48:00+00:00: scheduled__2023-09-27T16:48:00+00:00, state:running, queued_at: 2024-09-27 16:02:03.059191+00:00. externally triggered: False> successful
[2024-09-27T18:02:27.412+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:48:00+00:00, run_id=scheduled__2023-09-27T16:48:00+00:00, run_start_date=2024-09-27 16:02:03.069597+00:00, run_end_date=2024-09-27 16:02:27.412540+00:00, run_duration=24.342943, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:48:00+00:00, data_interval_end=2023-09-27 16:49:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:27.414+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:49:00+00:00, run_after=2023-09-27 16:50:00+00:00
[2024-09-27T18:02:27.421+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:27.422+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:27.423+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:27.423+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.424+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:27.424+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:27.427+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:28.363+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:28.452+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:29.508+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:49:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:30.464+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:30.547+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:49:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.420+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:49:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:31.423+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:49:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:30.584070+00:00, run_end_date=2024-09-27 16:02:31.021926+00:00, run_duration=0.437856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321375
[2024-09-27T18:02:31.424+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:28.490216+00:00, run_end_date=2024-09-27 16:02:29.118875+00:00, run_duration=0.628659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1281, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:27.422866+00:00, queued_by_job_id=1230, pid=321368
[2024-09-27T18:02:31.448+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.475+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:49:00+00:00: scheduled__2023-09-27T16:49:00+00:00, state:running, queued_at: 2024-09-27 16:02:07.082712+00:00. externally triggered: False> successful
[2024-09-27T18:02:31.476+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:49:00+00:00, run_id=scheduled__2023-09-27T16:49:00+00:00, run_start_date=2024-09-27 16:02:07.106532+00:00, run_end_date=2024-09-27 16:02:31.476405+00:00, run_duration=24.369873, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:49:00+00:00, data_interval_end=2023-09-27 16:50:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:31.480+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:50:00+00:00, run_after=2023-09-27 16:51:00+00:00
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.493+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:31.494+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:31.496+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:31.497+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:31.500+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:32.434+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:32.518+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:50:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:33.595+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:50:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:33.600+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:50:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:32.553934+00:00, run_end_date=2024-09-27 16:02:33.167498+00:00, run_duration=0.613564, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1283, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:31.494879+00:00, queued_by_job_id=1230, pid=321382
[2024-09-27T18:02:33.643+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:33.661+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:50:00+00:00: scheduled__2023-09-27T16:50:00+00:00, state:running, queued_at: 2024-09-27 16:02:13.501328+00:00. externally triggered: False> successful
[2024-09-27T18:02:33.662+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:50:00+00:00, run_id=scheduled__2023-09-27T16:50:00+00:00, run_start_date=2024-09-27 16:02:13.520492+00:00, run_end_date=2024-09-27 16:02:33.662059+00:00, run_duration=20.141567, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:50:00+00:00, data_interval_end=2023-09-27 16:51:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:33.666+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:51:00+00:00, run_after=2023-09-27 16:52:00+00:00
[2024-09-27T18:02:34.709+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:34.738+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:34.739+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:34.740+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:34.742+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:35.675+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:35.764+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:36.640+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:36.645+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:35.802059+00:00, run_end_date=2024-09-27 16:02:36.255413+00:00, run_duration=0.453354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1284, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:34.739061+00:00, queued_by_job_id=1230, pid=321391
[2024-09-27T18:02:36.678+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:02:36.727+0200] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:36.728+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:36.729+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:36.729+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.730+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:36.730+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:36.732+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:37.672+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:37.757+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:38.560+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:39.501+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:39.590+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.572+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:40.578+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:39.626476+00:00, run_end_date=2024-09-27 16:02:40.176226+00:00, run_duration=0.54975, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1286, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321406
[2024-09-27T18:02:40.579+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:37.793102+00:00, run_end_date=2024-09-27 16:02:38.146000+00:00, run_duration=0.352898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1285, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:36.728799+00:00, queued_by_job_id=1230, pid=321398
[2024-09-27T18:02:40.616+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:54:00+00:00, run_after=2023-09-27 16:55:00+00:00
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:40.645+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:40.647+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.647+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:40.648+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:40.650+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:41.591+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:41.677+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:42.921+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:43.875+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:43.961+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:45.208+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:46.147+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:46.231+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.351+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.352+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:47.359+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:46.267060+00:00, run_end_date=2024-09-27 16:02:46.939523+00:00, run_duration=0.672463, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1289, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321427
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:41.713006+00:00, run_end_date=2024-09-27 16:02:42.503726+00:00, run_duration=0.79072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1287, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321413
[2024-09-27T18:02:47.360+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:43.997504+00:00, run_end_date=2024-09-27 16:02:44.789012+00:00, run_duration=0.791508, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1288, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:40.646269+00:00, queued_by_job_id=1230, pid=321420
[2024-09-27T18:02:47.618+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:55:00+00:00, run_after=2023-09-27 16:56:00+00:00
[2024-09-27T18:02:47.680+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:47.681+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:47.682+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>
[2024-09-27T18:02:47.685+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:47.686+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:47.686+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:47.687+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.687+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.688+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:47.688+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:47.692+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:48.631+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:48.715+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:50.123+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:51.068+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:51.152+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:52.561+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:53.502+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:53.588+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:55.148+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:51:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:56.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:56.169+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:51:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:57.094+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.095+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.096+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:51:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:02:57.102+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:51:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:56.206081+00:00, run_end_date=2024-09-27 16:02:56.671887+00:00, run_duration=0.465806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1293, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321464
[2024-09-27T18:02:57.103+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:51.190075+00:00, run_end_date=2024-09-27 16:02:52.129239+00:00, run_duration=0.939164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1291, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321444
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:48.751318+00:00, run_end_date=2024-09-27 16:02:49.704840+00:00, run_duration=0.953522, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1290, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321437
[2024-09-27T18:02:57.104+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:53.624750+00:00, run_end_date=2024-09-27 16:02:54.724797+00:00, run_duration=1.100047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1292, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:47.683992+00:00, queued_by_job_id=1230, pid=321457
[2024-09-27T18:02:57.150+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:56:00+00:00, run_after=2023-09-27 16:57:00+00:00
[2024-09-27T18:02:57.202+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:51:00+00:00: scheduled__2023-09-27T16:51:00+00:00, state:running, queued_at: 2024-09-27 16:02:34.703538+00:00. externally triggered: False> successful
[2024-09-27T18:02:57.203+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:51:00+00:00, run_id=scheduled__2023-09-27T16:51:00+00:00, run_start_date=2024-09-27 16:02:34.722773+00:00, run_end_date=2024-09-27 16:02:57.203321+00:00, run_duration=22.480548, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:51:00+00:00, data_interval_end=2023-09-27 16:52:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:02:57.206+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:52:00+00:00, run_after=2023-09-27 16:53:00+00:00
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:02:57.213+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 3/16 running and queued tasks
[2024-09-27T18:02:57.214+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2024-09-27T18:02:57.215+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.215+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.216+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:02:57.216+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:57.219+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_exchange_rate', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:02:58.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:02:58.235+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_exchange_rate scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:02:59.235+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:00.180+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:00.264+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:01.510+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:02.451+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:02.535+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:53:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:03.536+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:52:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:04.468+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:04.553+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:52:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:05.665+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_exchange_rate', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.666+0200] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:52:00+00:00', try_number=1, map_index=-1)
[2024-09-27T18:03:05.673+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_trades, run_id=scheduled__2023-09-27T16:54:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:00.300429+00:00, run_end_date=2024-09-27 16:03:01.077587+00:00, run_duration=0.777158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1295, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321484
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_ohlcv, run_id=scheduled__2023-09-27T16:53:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:02.571693+00:00, run_end_date=2024-09-27 16:03:03.127994+00:00, run_duration=0.556301, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1296, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321496
[2024-09-27T18:03:05.674+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_exchange_rate, run_id=scheduled__2023-09-27T16:55:00+00:00, map_index=-1, run_start_date=2024-09-27 16:02:58.270824+00:00, run_end_date=2024-09-27 16:02:58.823393+00:00, run_duration=0.552569, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1294, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321472
[2024-09-27T18:03:05.675+0200] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=crypto_data_pipeline_dag, task_id=fetch_order_book, run_id=scheduled__2023-09-27T16:52:00+00:00, map_index=-1, run_start_date=2024-09-27 16:03:04.591123+00:00, run_end_date=2024-09-27 16:03:05.281462+00:00, run_duration=0.690339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=1297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-09-27 16:02:57.214513+00:00, queued_by_job_id=1230, pid=321503
[2024-09-27T18:03:05.725+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.761+0200] {dagrun.py:854} INFO - Marking run <DagRun crypto_data_pipeline_dag @ 2023-09-27 16:52:00+00:00: scheduled__2023-09-27T16:52:00+00:00, state:running, queued_at: 2024-09-27 16:02:36.672415+00:00. externally triggered: False> successful
[2024-09-27T18:03:05.762+0200] {dagrun.py:905} INFO - DagRun Finished: dag_id=crypto_data_pipeline_dag, execution_date=2023-09-27 16:52:00+00:00, run_id=scheduled__2023-09-27T16:52:00+00:00, run_start_date=2024-09-27 16:02:36.695113+00:00, run_end_date=2024-09-27 16:03:05.762096+00:00, run_duration=29.066983, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-09-27 16:52:00+00:00, data_interval_end=2023-09-27 16:53:00+00:00, dag_hash=d8fc59bf74fef06979c096c5c58ce9bd
[2024-09-27T18:03:05.766+0200] {dag.py:4180} INFO - Setting next_dagrun for crypto_data_pipeline_dag to 2023-09-27 16:53:00+00:00, run_after=2023-09-27 16:54:00+00:00
[2024-09-27T18:03:05.780+0200] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 0/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 1/16 running and queued tasks
[2024-09-27T18:03:05.781+0200] {scheduler_job_runner.py:495} INFO - DAG crypto_data_pipeline_dag has 2/16 running and queued tasks
[2024-09-27T18:03:05.782+0200] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>
	<TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [scheduled]>, <TaskInstance: crypto_data_pipeline_dag.fetch_order_book scheduled__2023-09-27T16:53:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-27T18:03:05.785+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_trades', run_id='scheduled__2023-09-27T16:55:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.786+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_ohlcv', run_id='scheduled__2023-09-27T16:54:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2024-09-27T18:03:05.786+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.787+0200] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='crypto_data_pipeline_dag', task_id='fetch_order_book', run_id='scheduled__2023-09-27T16:53:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-27T18:03:05.787+0200] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_order_book', 'scheduled__2023-09-27T16:53:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:05.791+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_trades', 'scheduled__2023-09-27T16:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:06.729+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:06.813+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_trades scheduled__2023-09-27T16:55:00+00:00 [queued]> on host jf-hp
[2024-09-27T18:03:08.983+0200] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'crypto_data_pipeline_dag', 'fetch_ohlcv', 'scheduled__2023-09-27T16:54:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/airflow_scheduling.py']
[2024-09-27T18:03:09.925+0200] {dagbag.py:588} INFO - Filling up the DagBag from /home/julian/real-time-data-lake/real-time-data-lake/src/dags/airflow_scheduling.py
[2024-09-27T18:03:10.009+0200] {task_command.py:467} INFO - Running <TaskInstance: crypto_data_pipeline_dag.fetch_ohlcv scheduled__2023-09-27T16:54:00+00:00 [queued]> on host jf-hp
